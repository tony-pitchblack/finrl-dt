{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony-pitchblack/finrl-dt/blob/custom-backtesting/finrl_dt_replicate_sweep_rllib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-J5mD_PTar9"
      },
      "source": [
        "#Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RfYDJoTXo6-J"
      },
      "outputs": [],
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w6nvjUhJQPQw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/tony-pitchblack/FinRL.git@benchmarking --no-deps \\\n",
        "    # --force-reinstall --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1S3eA6pMHTxn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/tony-pitchblack/FinRL/benchmarking/requirements.txt -O requirements.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIU-vXqDRW3L"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "US_vB7hNSdeu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from stable_baselines3.common.logger import configure\n",
        "from finrl import config_tickers\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HJsl_3tVre6q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I9s6zvbUAsyq"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = \"aee284a72205e2d6787bd3ce266c5b9aefefa42c\"\n",
        "\n",
        "PROJECT = 'finrl-dt-replicate'\n",
        "ENTITY = \"overfit1010\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWn4ZCwkvtN3"
      },
      "source": [
        "# General funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "gbd4N4QLPXlL"
      },
      "outputs": [],
      "source": [
        "#@title YahooDownloader\n",
        "\n",
        "\"\"\"Contains methods and classes to collect data from\n",
        "Yahoo Finance API\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic, start=self.start_date, end=self.end_date, proxy=proxy\n",
        "            )\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures += 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "\n",
        "        try:\n",
        "            # Convert wide to long format\n",
        "            # print(f\"DATA COLS: {data_df.columns}\")\n",
        "            data_df = data_df.sort_index(axis=1).set_index(['Date']).drop(columns=['tic']).stack(level='Ticker', future_stack=True)\n",
        "            data_df.reset_index(inplace=True)\n",
        "            data_df.columns.name = ''\n",
        "\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(columns={'Ticker': 'Tic', 'Adj Close': 'Adjcp'}, inplace=True)\n",
        "            data_df.rename(columns={col: col.lower() for col in data_df.columns}, inplace=True)\n",
        "\n",
        "            columns = [\n",
        "                \"date\",\n",
        "                \"tic\",\n",
        "                \"open\",\n",
        "                \"high\",\n",
        "                \"low\",\n",
        "                \"close\",\n",
        "                \"adjcp\",\n",
        "                \"volume\",\n",
        "            ]\n",
        "\n",
        "            data_df = data_df[columns]\n",
        "            # use adjusted close price instead of close price\n",
        "            data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "            # drop the adjusted close price column\n",
        "            data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "l4vvbL7xvqYx"
      },
      "outputs": [],
      "source": [
        "#@title fix_daily_index\n",
        "\n",
        "def make_daily_index(data_df, date_col_name='date', new_index_name='date_index'):\n",
        "    # Get unique dates and create a mapping to daily indices\n",
        "    total_dates = data_df[date_col_name].unique()\n",
        "    date_to_index = {date: idx for idx, date in enumerate(sorted(total_dates))}\n",
        "    return data_df[date_col_name].map(date_to_index)\n",
        "\n",
        "def set_daily_index(data_df, date_col_name='date', new_index_name='date_index'):\n",
        "    \"\"\"\n",
        "    Constructs a daily index from unique dates in the specified column.\n",
        "\n",
        "    Parameters:\n",
        "        data_df (pd.DataFrame): The input DataFrame.\n",
        "        date_column (str): The name of the column containing dates.\n",
        "        new_index_name (str): The name for the new index.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with a daily index.\n",
        "    \"\"\"\n",
        "\n",
        "    # Map dates to daily indices and set as index\n",
        "    data_df[new_index_name] = make_daily_index(data_df, date_col_name=date_col_name, new_index_name='date_index')\n",
        "\n",
        "    data_df.set_index(new_index_name, inplace=True)\n",
        "    data_df.index.name = ''  # Remove the index name for simplicity\n",
        "\n",
        "    return data_df\n",
        "\n",
        "def fix_daily_index(df, date_col_name='date'):\n",
        "    if df.index.name == date_col_name:\n",
        "        df.reset_index(inplace=True)\n",
        "\n",
        "    daily_index = make_daily_index(df, date_col_name=date_col_name, new_index_name='date_index')\n",
        "    if (df.index.values != daily_index.values).any():\n",
        "\n",
        "        df.index = daily_index\n",
        "        df.index.name = ''\n",
        "\n",
        "    return df\n",
        "\n",
        "# trade = fix_daily_index(trade)\n",
        "# trade.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "GQ6BIJxbwuVh"
      },
      "outputs": [],
      "source": [
        "#@title get dataset name\n",
        "\n",
        "def get_quarterly_dataset_name(prefix, train_start_date, val_start_date, test_start_date):\n",
        "    get_quarter = lambda date: f'Q{(date.month - 1) // 3 + 1}'\n",
        "\n",
        "    val_quarter = get_quarter(val_start_date)\n",
        "    test_quarter = get_quarter(test_start_date)\n",
        "\n",
        "    # Extract year and month\n",
        "    train_start = f\"{train_start_date.year}-{train_start_date.month:02}\"\n",
        "    val_start = f\"{val_start_date.year}\"\n",
        "    test_start = f\"{test_start_date.year}\"\n",
        "\n",
        "    # Construct the dataset name\n",
        "    dataset_name = f\"{prefix} | {train_start} | {val_start} {val_quarter} | {test_start} {test_quarter}\"\n",
        "\n",
        "    return dataset_name\n",
        "\n",
        "def get_yearly_dataset_name(prefix, train_start, test_start, test_end):\n",
        "    # Extract year and month\n",
        "    train_start_str = f\"{train_start.year}-{train_start.month:02}\"\n",
        "    test_start_str = f\"{test_start.year}-{test_start.month:02}\"\n",
        "    test_end_str = f\"{test_end.year}-{test_end.month:02}\"\n",
        "\n",
        "    # Construct the dataset name\n",
        "    dataset_name = f\"{prefix} | {train_start_str} | {test_start_str} | {test_end_str}\"\n",
        "    return dataset_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "TOfz3JlX-oG5"
      },
      "outputs": [],
      "source": [
        "#@title add_dataset\n",
        "\n",
        "def add_dataset(stock_index_name, train_df, test_df):\n",
        "    if 'datasets' not in globals():\n",
        "        global datasets\n",
        "        datasets = {}\n",
        "\n",
        "    # Ensure datetime format\n",
        "    if 'date' in train_df.columns:\n",
        "        train_df.set_index('date', inplace=True)\n",
        "    train_df.index = pd.to_datetime(train_df.index)\n",
        "\n",
        "    if 'date' in test_df.columns:\n",
        "        test_df.set_index('date', inplace=True)\n",
        "    test_df.index = pd.to_datetime(test_df.index)\n",
        "\n",
        "    train_start_date = train_df.index[0]\n",
        "    test_start_date = test_df.index[0]\n",
        "    test_end_date = test_df.index[-1]\n",
        "\n",
        "    dataset_name = get_yearly_dataset_name(\n",
        "        stock_index_name,\n",
        "        train_start_date, test_start_date, test_end_date\n",
        "    )\n",
        "\n",
        "    train_df.reset_index(inplace=True)\n",
        "    test_df.reset_index(inplace=True)\n",
        "\n",
        "    train_df = set_daily_index(train_df)\n",
        "    test_df = set_daily_index(test_df)\n",
        "\n",
        "    ticker_list = train_df.tic.unique().tolist()\n",
        "\n",
        "    datasets[dataset_name] = {\n",
        "        'train': train_df,\n",
        "        'test': test_df,\n",
        "        'metadata': dict(\n",
        "            stock_index_name = stock_index_name,\n",
        "            train_start_date = train_start_date,\n",
        "            test_start_date = test_start_date,\n",
        "            test_end_date = test_end_date,\n",
        "            num_tickers = len(ticker_list),\n",
        "            ticker_list = ticker_list,\n",
        "        )\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWUph5lzrTUS"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHIfVohUTAsG"
      },
      "source": [
        "## DATA: DOW-30 (quarterly train/val/test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dTOtt7iQg7TU"
      },
      "outputs": [],
      "source": [
        "train_start_date = '2015-01-01'\n",
        "min_test_start_date = '2016-01-01'\n",
        "max_test_end_date = '2016-10-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "DGMvKo0wxwYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54774a85-9876-4304-d4d8-227fbaaa04e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_start_date': Timestamp('2015-01-01 00:00:00'), 'val_start_date': Timestamp('2015-10-01 00:00:00'), 'test_start_date': Timestamp('2016-01-01 00:00:00'), 'test_end_date': Timestamp('2016-04-01 00:00:00')}\n",
            "{'train_start_date': Timestamp('2015-10-01 00:00:00'), 'val_start_date': Timestamp('2016-01-01 00:00:00'), 'test_start_date': Timestamp('2016-04-01 00:00:00'), 'test_end_date': Timestamp('2016-07-01 00:00:00')}\n",
            "{'train_start_date': Timestamp('2016-01-01 00:00:00'), 'val_start_date': Timestamp('2016-04-01 00:00:00'), 'test_start_date': Timestamp('2016-07-01 00:00:00'), 'test_end_date': Timestamp('2016-10-01 00:00:00')}\n"
          ]
        }
      ],
      "source": [
        "#@title generate_quarterly_date_ranges\n",
        "\n",
        "def generate_quarterly_date_ranges(\n",
        "    train_start_date,\n",
        "    min_test_start_date,\n",
        "    max_test_end_date,\n",
        "    return_strings=False,\n",
        "    finetune_previous_val=False\n",
        "):\n",
        "    is_quarter_start = lambda date: date.month in [1, 4, 7, 10] and date.day == 1\n",
        "\n",
        "    min_test_start_date = pd.Timestamp(min_test_start_date)\n",
        "    train_start_date = pd.Timestamp(train_start_date)\n",
        "    max_test_end_date = pd.Timestamp(max_test_end_date)\n",
        "\n",
        "    assert is_quarter_start(train_start_date), f\"train_start_date {train_start_date} is not a quarter start date.\"\n",
        "    assert is_quarter_start(min_test_start_date), f\"min_test_start_date {min_test_start_date} is not a quarter start date.\"\n",
        "\n",
        "    test_start_date = min_test_start_date\n",
        "    date_ranges = []\n",
        "    full_train_start_date = train_start_date\n",
        "\n",
        "    while True:\n",
        "        val_start_date = test_start_date - pd.DateOffset(months=3)\n",
        "        test_end_date = test_start_date + pd.DateOffset(months=3)\n",
        "\n",
        "        if test_end_date > max_test_end_date:\n",
        "            break\n",
        "\n",
        "        if len(date_ranges) == 0:\n",
        "            # The first date_range contains the full training period\n",
        "            train_start_date = full_train_start_date\n",
        "        elif finetune_previous_val:\n",
        "            # Use the previous validation range as the training range\n",
        "            train_start_date = date_ranges[-1]['val_start_date']\n",
        "\n",
        "        date_range = dict(\n",
        "            train_start_date=train_start_date,\n",
        "            val_start_date=val_start_date,\n",
        "            test_start_date=test_start_date,\n",
        "            test_end_date=test_end_date,\n",
        "        )\n",
        "\n",
        "        if return_strings:\n",
        "            date_range = {k: str(v) for k, v in date_range.items()}\n",
        "\n",
        "        date_ranges.append(date_range)\n",
        "\n",
        "        test_start_date = test_end_date\n",
        "\n",
        "    return date_ranges\n",
        "\n",
        "date_ranges = generate_quarterly_date_ranges(\n",
        "    train_start_date,\n",
        "    min_test_start_date,\n",
        "    max_test_end_date,\n",
        "    finetune_previous_val=True\n",
        ")\n",
        "\n",
        "# print(*date_ranges[:2], sep='\\n')\n",
        "print(*date_ranges, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "pHEOvqsiu6Pq"
      },
      "outputs": [],
      "source": [
        "#@title split_data\n",
        "\n",
        "def split_data(data_df, date_range, date_col_name='date'):\n",
        "    def subset_date_range(df, start_date, end_date):\n",
        "        df = df[(df[date_col_name] >= start_date) & (df[date_col_name] < end_date)]\n",
        "        df = fix_daily_index(df, date_col_name)\n",
        "        return df\n",
        "\n",
        "    return {\n",
        "        'train': subset_date_range(data_df, date_range['train_start_date'], date_range['val_start_date']),\n",
        "        'val': subset_date_range(data_df, date_range['val_start_date'], date_range['test_start_date']),\n",
        "        'test': subset_date_range(data_df, date_range['test_start_date'], date_range['test_end_date']),\n",
        "    }\n",
        "\n",
        "# data_splits = split_data(preproc_df, date_ranges[0])\n",
        "# data_splits['train'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYSbz9QQ7pS8"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KemUy0OKg-wX"
      },
      "source": [
        "## Wandb utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Artifact management"
      ],
      "metadata": {
        "id": "mxNCQ5KN6pfU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "jF0Xbv9f631H"
      },
      "outputs": [],
      "source": [
        "#@title update_artifact\n",
        "\n",
        "def update_artifact(folder_path, name_prefix, type):\n",
        "    \"\"\"\n",
        "    Create or update a W&B artifact consisting of a folder.\n",
        "\n",
        "    Args:\n",
        "        run: The current W&B run.\n",
        "        folder_path (str): Path to the folder to upload.\n",
        "        artifact_name (str): Name of the artifact.\n",
        "        artifact_type (str): Type of the artifact.\n",
        "    \"\"\"\n",
        "    run = wandb.run\n",
        "    artifact_name = f'{name_prefix}-{wandb.run.id}'\n",
        "\n",
        "    # Create a new artifact\n",
        "    artifact = wandb.Artifact(name=artifact_name, type=type)\n",
        "\n",
        "    # Add the folder to the artifact\n",
        "    artifact.add_dir(folder_path)\n",
        "\n",
        "    # Log the artifact to W&B\n",
        "    run.log_artifact(artifact)\n",
        "    print(f\"Artifact '{artifact_name}' has been updated and uploaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "bCmdRFmDh-CI"
      },
      "outputs": [],
      "source": [
        "#@title update_model_artifacts\n",
        "\n",
        "def update_model_artifacts(log_results_folder=True):\n",
        "    if log_results_folder:\n",
        "        update_artifact(\n",
        "            folder_path = RESULTS_DIR,\n",
        "            name_prefix = 'results',\n",
        "            type = 'results'\n",
        "        )\n",
        "\n",
        "    update_artifact(\n",
        "        folder_path = TRAINED_MODEL_DIR,\n",
        "        name_prefix = 'trained_models',\n",
        "        type = 'trained_models'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "Prm8SfPo7CJY"
      },
      "outputs": [],
      "source": [
        "#@title update_dataset_artifact\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def update_dataset_artifact(config, train_df, val_df=None, test_df=None):\n",
        "    DATASET_DIR = Path('./dataset')\n",
        "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "    train_df.to_csv(DATASET_DIR / 'train_data.csv', index=False)\n",
        "\n",
        "    if test_df is not None:\n",
        "        test_df.to_csv(DATASET_DIR / 'test_data.csv', index=False)\n",
        "\n",
        "    if val_df is not None:\n",
        "        val_df.to_csv(DATASET_DIR / 'val_data.csv', index=False)\n",
        "\n",
        "    update_artifact(\n",
        "        folder_path = DATASET_DIR,\n",
        "        name_prefix = 'dataset',\n",
        "        type = 'dataset'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "x66rQn0TGEkM"
      },
      "outputs": [],
      "source": [
        "#@title update_env_state_artifact\n",
        "\n",
        "def update_env_state_artifact(val_env_end_state):\n",
        "    file_path = 'val_env_end_state.csv'\n",
        "\n",
        "    df_last_state = pd.DataFrame({\"last_state\": val_env_end_state})\n",
        "    df_last_state.to_csv(\n",
        "        file_path, index=False\n",
        "    )\n",
        "\n",
        "    artifact = wandb.Artifact(name=f'val_env_end_state-{wandb.run.id}', type='env_state')\n",
        "    artifact.add_file(file_path)\n",
        "    wandb.run.log_artifact(artifact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CMnFUx9gfaGH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download artifacts\n",
        "\n",
        "def download_artifacts(run_id, artifact_types):\n",
        "    # Retrieve the run\n",
        "    global WANDB_API\n",
        "\n",
        "    run = WANDB_API.run(f\"{ENTITY}/{PROJECT}/{run_id}\")\n",
        "\n",
        "    # Iterate over the artifacts used or logged by the run\n",
        "    for artifact in run.logged_artifacts():\n",
        "        if artifact.type in artifact_types:\n",
        "            artifact_folder = f'./{artifact.type}'\n",
        "            !rm -rf artifact_folder\n",
        "            artifact.download(artifact_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run management"
      ],
      "metadata": {
        "id": "09H8MxKH6nay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "WANDB_API = wandb.Api() # instantiate API once"
      ],
      "metadata": {
        "id": "5lQYhbCN6uR7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eOiQhAa15VQT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title get_config_hash\n",
        "\n",
        "import json\n",
        "from hashlib import sha256\n",
        "\n",
        "def dict_to_canonical_string(cfg_dict):\n",
        "    return json.dumps(cfg_dict, sort_keys=True)\n",
        "\n",
        "def get_config_hash(run_config):\n",
        "    config_seed = run_config['seed']\n",
        "    config_training_params = run_config['training_params']\n",
        "    config_canonical_str = dict_to_canonical_string({\n",
        "        'seed': config_seed,\n",
        "        'training_params': config_training_params\n",
        "    })\n",
        "    config_hash = sha256(config_canonical_str.encode()).hexdigest()\n",
        "    return config_hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2oe3jQ0_Zdv4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title group_by_hash_and_sort_by_date (for all runs in a sweep)\n",
        "\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime\n",
        "\n",
        "def group_by_hash_and_sort_by_date(\n",
        "        sweep_id,\n",
        "        return_inner_list=True\n",
        "    ):\n",
        "    global WANDB_API\n",
        "\n",
        "    sweep_runs = WANDB_API.sweep(f\"{ENTITY}/{PROJECT}/{sweep_id}\").runs\n",
        "\n",
        "    prev_run_id = None\n",
        "    prev_run_id_list = []\n",
        "\n",
        "    # Collect run IDs and their test_start_date, grouped by config_hash\n",
        "    config_hash_to_runs = {}\n",
        "    for run in sweep_runs:\n",
        "        config_hash = get_config_hash(run.config)\n",
        "        if config_hash not in config_hash_to_runs:\n",
        "            config_hash_to_runs[config_hash] = {}\n",
        "\n",
        "        config_hash_to_runs[config_hash][run.id] = run.config['date_range']['test_start_date']\n",
        "\n",
        "    # Sort runs for current config hash by test_start_date\n",
        "    for config_hash, runs_dict in config_hash_to_runs.items():\n",
        "        sorted_runs_dict = OrderedDict(\n",
        "            sorted(\n",
        "                runs_dict.items(),\n",
        "                key=lambda x: datetime.strptime(x[1], \"%Y-%m-%d %H:%M:%S\"),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if return_inner_list:\n",
        "            config_hash_to_runs[config_hash] = list(sorted_runs_dict.items())\n",
        "        else:\n",
        "            config_hash_to_runs[config_hash] = sorted_runs_dict\n",
        "\n",
        "    return config_hash_to_runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "omhOVfoMUh3x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title find_previous_run (sweep)\n",
        "\n",
        "def find_prev_run(sweep_id, curr_run_id):\n",
        "    global WANDB_API\n",
        "\n",
        "    sweep_runs = WANDB_API.sweep(f\"{ENTITY}/{PROJECT}/{sweep_id}\").runs\n",
        "    curr_run = WANDB_API.run(f\"{ENTITY}/{PROJECT}/{curr_run_id}\")\n",
        "\n",
        "    prev_run = None\n",
        "    for run in sweep_runs:\n",
        "        # find run with same `hash_config`\n",
        "        # and current previous `test_start_date == current `val_start_date`\n",
        "        run_hash = get_config_hash(run.config)\n",
        "        curr_run_hash = get_config_hash(curr_run.config)\n",
        "        if run_hash == curr_run_hash \\\n",
        "        and run.config['date_range']['test_start_date'] == curr_run.config['date_range']['val_start_date']:\n",
        "            prev_run = run\n",
        "            break\n",
        "\n",
        "    return prev_run\n",
        "\n",
        "# SWEEP_ID = 'yd7fz9as'\n",
        "# CURR_RUN_ID = 'rbug5oxn'\n",
        "# prev_run = find_prev_run(SWEEP_ID, CURR_RUN_ID)\n",
        "# prev_run.id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BZTsxX0tkDZ"
      },
      "source": [
        "## Build & helper funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "id": "SmzfG0qaVP93"
      },
      "outputs": [],
      "source": [
        "#@title build_yearly_train_test\n",
        "def build_yearly_train_test(config):\n",
        "    train_start_date, test_start_date, test_end_date = generate_yearly_train_test_dates(\n",
        "        config['train_years_count'],\n",
        "        config['test_years_count'],\n",
        "        config['test_start_year']\n",
        "    )\n",
        "\n",
        "    train_df = preproc_df[(preproc_df['date'] >= train_start_date) & (preproc_df['date'] < test_start_date)]\n",
        "    test_df = preproc_df[(preproc_df['date'] >= test_start_date) & (preproc_df['date'] < test_end_date)]\n",
        "\n",
        "    train_df = set_daily_index(train_df)\n",
        "    test_df = set_daily_index(test_df)\n",
        "\n",
        "    dataset_name = get_yearly_dataset_name(\n",
        "        config['stock_index_name'], train_start_date, test_start_date, test_end_date\n",
        "    )\n",
        "\n",
        "    config.update(dict(\n",
        "        train_start_date=train_start_date,\n",
        "        test_start_date=test_start_date,\n",
        "        test_end_date=test_end_date,\n",
        "        dataset_name=dataset_name\n",
        "    ))\n",
        "\n",
        "    update_dataset_artifact(\n",
        "        config,\n",
        "\n",
        "        train_df=train_df,\n",
        "        val_df=val_df,\n",
        "        test_df=test_df,\n",
        "    )\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "N2JCHB8ibDce",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title build_quarterly_train_val_test\n",
        "from finrl.meta.data_processors.processor_yahoofinance import YahooFinanceProcessor\n",
        "\n",
        "def build_quarterly_train_val_test(data, data_processor, date_range, config):\n",
        "    train_np_env_config = get_np_env_config(\n",
        "        data,\n",
        "        data_processor,\n",
        "        start_date=date_range['train_start_date'],\n",
        "        end_date=date_range['val_start_date'],\n",
        "        if_train=True\n",
        "    )\n",
        "\n",
        "    val_np_env_config = get_np_env_config(\n",
        "        data,\n",
        "        data_processor,\n",
        "        start_date=date_range['val_start_date'],\n",
        "        end_date=date_range['test_start_date'],\n",
        "        if_train=False\n",
        "    )\n",
        "\n",
        "    test_np_env_config = get_np_env_config(\n",
        "        data,\n",
        "        data_processor,\n",
        "        start_date=date_range['test_start_date'],\n",
        "        end_date=date_range['test_end_date'],\n",
        "        if_train=False\n",
        "    )\n",
        "\n",
        "    config.update({\n",
        "        \"train.num_datapoints\": len(train_np_env_config['price_array']),\n",
        "        \"val.num_datapoints\": len(val_np_env_config['price_array']),\n",
        "        \"test.num_datapoints\": len(test_np_env_config['price_array']),\n",
        "    })\n",
        "\n",
        "    return dict(\n",
        "        train_np_env_config = train_np_env_config,\n",
        "        val_np_env_config = val_np_env_config,\n",
        "        test_np_env_config = test_np_env_config\n",
        "    )\n",
        "\n",
        "# train_np_env_config, val_np_env_config, test_np_env_config = build_quarterly_train_val_test(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load_cached_data (w/ tech indicator padding)\n",
        "from pathlib import Path\n",
        "from bisect import bisect_left\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "\n",
        "NY = \"America/New_York\"\n",
        "\n",
        "CACHE_DIR = './cache'\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def stable_hash(data):\n",
        "    return hashlib.sha256(str(data).encode()).hexdigest()\n",
        "\n",
        "def load_cached_data(\n",
        "    start_date: str,\n",
        "    end_date: str,\n",
        "    ticker_list=DOW_30_TICKER,\n",
        "    technical_indicator_list=INDICATORS,\n",
        "    extra_indicator_list=None,\n",
        "    time_interval='1d',\n",
        "    if_vix=True,\n",
        "    ignore_cache=False,\n",
        "    tech_indicator_padding=60,\n",
        "):\n",
        "\n",
        "    \"\"\"\n",
        "    Load data with a buffer of N trading days before start_date, so that\n",
        "    rolling tech indicators can be computed properly within the environment.\n",
        "\n",
        "    tech_indicator_padding: how many extra timestamps to load for correct tech indicators calculation\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the DataProcessor first so we can use .get_trading_days(...)\n",
        "    dp = DataProcessor(\n",
        "        data_source='yahoofinance',\n",
        "        tech_indicator=technical_indicator_list,\n",
        "        extra_indicator=extra_indicator_list,\n",
        "        vix=if_vix,\n",
        "    )\n",
        "\n",
        "    # 1) Define a big offset (e.g. 6 months) before start_date to gather trading days\n",
        "    #    (We assume 6 months is enough to include all desired tech_indicator_padding.)\n",
        "    raw_buffer_start = pd.Timestamp(start_date) - pd.DateOffset(months=6)\n",
        "\n",
        "    # 2) Get *all* trading days from that offset up to the real end_date\n",
        "    all_trading_days = dp.processor.get_trading_days(\n",
        "        start=str(raw_buffer_start.date()),\n",
        "        end=str(pd.Timestamp(end_date).date())\n",
        "    )\n",
        "\n",
        "    # 3) Find the index of the first trading day >= start_date\n",
        "    #    We compare strings \"YYYY-MM-DD\", so make sure to align formats.\n",
        "    target_str = str(pd.Timestamp(start_date).date())\n",
        "    i = bisect_left(all_trading_days, target_str)\n",
        "\n",
        "    # 4) Subtract tech_indicator_padding from that index (clamp to zero)\n",
        "    earliest_idx = max(0, i - tech_indicator_padding)\n",
        "    actual_start_date = all_trading_days[earliest_idx]\n",
        "\n",
        "    # Build a stable hash for caching\n",
        "    data_hash = stable_hash(tuple(sorted(ticker_list)\n",
        "                                  + sorted(technical_indicator_list)\n",
        "                                  + sorted(extra_indicator_list) if extra_indicator_list else []\n",
        "                                  + [if_vix, time_interval]))\n",
        "\n",
        "    # File path includes the actual_start_date so we pick up correct caching\n",
        "    file_path = Path(CACHE_DIR) / (\n",
        "        f\"{actual_start_date}_{end_date}_{time_interval}_{data_hash}.csv\"\n",
        "    )\n",
        "\n",
        "    if file_path.is_file() and not ignore_cache:\n",
        "        print(f\"Using cached data: {file_path}\")\n",
        "        data = pd.read_csv(file_path, index_col=0)\n",
        "        data['timestamp'] = (\n",
        "            pd.to_datetime(data['timestamp'], utc=True)\n",
        "              .dt.tz_convert(NY)\n",
        "              .dt.tz_localize(None)\n",
        "        )\n",
        "        return data, dp\n",
        "    else:\n",
        "        print(\"Creating new data (no suitable cache).\")\n",
        "        # 5) Download from the earlier (buffered) start date\n",
        "        data = dp.download_data(\n",
        "            ticker_list=ticker_list,\n",
        "            start_date=actual_start_date,\n",
        "            end_date=end_date,\n",
        "            time_interval=time_interval\n",
        "        )\n",
        "\n",
        "        data = dp.clean_data(data)\n",
        "        # Add VIX or turbulence\n",
        "        if if_vix:\n",
        "            data = dp.add_vix(data)\n",
        "        else:\n",
        "            data = dp.add_turbulence(data)\n",
        "\n",
        "        data = dp.add_technical_indicator(data, technical_indicator_list, extra_indicator_list)\n",
        "\n",
        "        # -------------------------------------------\n",
        "        # (6) Trim out rows before the *original* start_date\n",
        "        # so that the final returned DataFrame is the \"original size\".\n",
        "        start_ts = pd.Timestamp(start_date).tz_localize(NY)\n",
        "        data = data[data[\"timestamp\"] >= start_ts]\n",
        "        data.reset_index(drop=True, inplace=True)\n",
        "        # -------------------------------------------\n",
        "\n",
        "        # Save to cache\n",
        "        data.to_csv(file_path)\n",
        "\n",
        "        # Convert timestamps\n",
        "        data['timestamp'] = (\n",
        "            pd.to_datetime(data['timestamp'], utc=True)\n",
        "              .dt.tz_convert(NY)\n",
        "              .dt.tz_localize(None)\n",
        "        )\n",
        "\n",
        "        return data, dp"
      ],
      "metadata": {
        "id": "jJWddDZf-Nl9",
        "cellView": "form"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "id": "Mp6Xv_K_eZ5Q"
      },
      "outputs": [],
      "source": [
        "#@title get_np_env_config\n",
        "\n",
        "def get_np_env_config(\n",
        "    data: pd.DataFrame,\n",
        "    data_processor: DataProcessor,\n",
        "    start_date,\n",
        "    end_date,\n",
        "    if_train,\n",
        "    use_extra_indicators=False,\n",
        "    if_extra_indicators_tech=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Uses data_processor to convert data to array.\n",
        "    WARNING: data_processor should be same as the one that was used to create the data.\n",
        "    \"\"\"\n",
        "\n",
        "    start_date = pd.Timestamp(start_date)\n",
        "    end_date = pd.Timestamp(end_date)\n",
        "\n",
        "    data = data[(data['timestamp'] >= start_date) & (data['timestamp'] < end_date)]\n",
        "\n",
        "    # print(f'use_extra_indicators: {use_extra_indicators}')\n",
        "    (\n",
        "        price_array,\n",
        "        tech_array,\n",
        "        turbulence_array,\n",
        "        timestamp_array,\n",
        "        *extra_arrays\n",
        "    ) = data_processor.df_to_array(\n",
        "        df=data,\n",
        "        return_timestamps=True,\n",
        "        use_extra_indicators=use_extra_indicators,\n",
        "        if_extra_indicators_tech=if_extra_indicators_tech,\n",
        "    )\n",
        "\n",
        "    env_config = {\n",
        "        \"price_array\": price_array,\n",
        "        \"tech_array\": tech_array,\n",
        "        \"turbulence_array\": turbulence_array,\n",
        "        \"timestamp_array\": timestamp_array,\n",
        "        \"if_train\": if_train\n",
        "    }\n",
        "\n",
        "    extra_cols = data_processor.extra_indicator_list\n",
        "    if extra_cols is not None:\n",
        "        env_config.update({\n",
        "            col: array for col, array in zip(extra_cols, extra_arrays)\n",
        "        })\n",
        "\n",
        "    return env_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mp0H06urpp53",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Init NUMPY StockTradingEnv\n",
        "\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.config import INDICATORS\n",
        "# from finrl.config import CACHE_DIR\n",
        "\n",
        "def init_np_env(\n",
        "    np_env_config,\n",
        "\n",
        "    initial_amount,\n",
        "    cost_pct,\n",
        "\n",
        "    mode,\n",
        "    turbulence_threshold=99,\n",
        "    initial_stocks=None\n",
        "):\n",
        "    assert mode in ['train', 'val', 'test']\n",
        "\n",
        "    print(f\"Initializing {'train' if np_env_config['if_train'] else 'eval'} env...\", end=' ')\n",
        "    env = StockTradingEnv(\n",
        "        config=np_env_config,\n",
        "        initial_capital=initial_amount,\n",
        "        buy_cost_pct=cost_pct,\n",
        "        sell_cost_pct=cost_pct,\n",
        "        turbulence_thresh=turbulence_threshold,\n",
        "        initial_stocks=np.array(initial_stocks) if isinstance(initial_stocks, list) else initial_stocks\n",
        "    )\n",
        "    print('Done.')\n",
        "\n",
        "    return env\n",
        "\n",
        "def create_np_stock_trading_env(env_config):\n",
        "    return init_np_env(**env_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Init STOPLOSS env\n",
        "\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_stoploss import StockTradingEnvStopLoss\n",
        "\n",
        "def create_stoploss_stock_trading_env(env_config):\n",
        "    min_date = env_config['df']['timestamp'].min()\n",
        "    max_date = env_config['df']['timestamp'].max()\n",
        "    print(f\"Creating Stop Loss env from {min_date} to {max_date}\")\n",
        "\n",
        "    env = StockTradingEnvStopLoss(\n",
        "        df = env_config['df'],\n",
        "        date_col_name = 'timestamp',\n",
        "\n",
        "        buy_cost_pct = env_config['cost_pct'],\n",
        "        sell_cost_pct = env_config['cost_pct'],\n",
        "        initial_amount = env_config['initial_amount'],\n",
        "        discrete_actions = env_config['discrete_actions'],\n",
        "        cache_indicator_data =  env_config['cache_indicator_data'],\n",
        "        patient = env_config['patient'],\n",
        "        print_verbosity = env_config['print_verbosity'],\n",
        "    )\n",
        "\n",
        "    return env"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-WbuVEEEoGrD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CREATE_ENV_FN = {\n",
        "    'np': create_np_stock_trading_env,\n",
        "    'stoploss': create_stoploss_stock_trading_env\n",
        "}"
      ],
      "metadata": {
        "id": "D191yVrzrpv0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cellView": "form",
        "id": "t0-3fjeCG_GJ"
      },
      "outputs": [],
      "source": [
        "#@title Define metric functions\n",
        "\n",
        "def calculate_mdd(asset_values):\n",
        "    \"\"\"\n",
        "    Calculate the Maximum Drawdown (MDD) of a portfolio.\n",
        "    \"\"\"\n",
        "    running_max = asset_values.cummax()\n",
        "    drawdown = (asset_values - running_max) / running_max\n",
        "    mdd = drawdown.min() * 100  # Convert to percentage\n",
        "    return mdd\n",
        "\n",
        "def calculate_sharpe_ratio(asset_values, risk_free_rate=0.0):\n",
        "    \"\"\"\n",
        "    Calculate the Sharpe Ratio of a portfolio.\n",
        "    \"\"\"\n",
        "    # Calculate daily returns\n",
        "    returns = asset_values.pct_change().dropna()\n",
        "    excess_returns = returns - risk_free_rate / 252  # Assuming 252 trading days\n",
        "\n",
        "    if excess_returns.std() == 0:\n",
        "        return 0.0\n",
        "    sharpe_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252)  # Annualized\n",
        "    return sharpe_ratio\n",
        "\n",
        "def calculate_annualized_return(asset_values):\n",
        "    \"\"\"\n",
        "    Calculate the annualized return of a portfolio.\n",
        "    \"\"\"\n",
        "    # Assume `asset_values` is indexed by date or trading day\n",
        "    total_return = (asset_values.iloc[-1] / asset_values.iloc[0] - 1) * 100\n",
        "    num_days = (asset_values.index[-1] - asset_values.index[0]).days\n",
        "    annualized_return = (1 + total_return) ** (365 / num_days) - 1\n",
        "    return annualized_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "cellView": "form",
        "id": "S4pwu5RcQz_F"
      },
      "outputs": [],
      "source": [
        "#@title compute metrics\n",
        "import wandb\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(account_values: List[pd.DataFrame, pd.Series, np.array], use_round=True):\n",
        "    \"\"\"\n",
        "    If DataFrame then should contain two columns - 'date' and name of algo, e.g. 'a2c'.\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(account_values, pd.DataFrame):\n",
        "        assert isinstance(account_values, pd.DataFrame)\n",
        "        if 'date' not in account_values.columns:\n",
        "            if account_values.index.name == 'date':\n",
        "                account_values.reset_index(inplace=True)\n",
        "            else:\n",
        "                raise ValueError(\"should contain 'date' column or index\")\n",
        "        account_values = account_values.dropna().set_index('date').iloc[:, 0]\n",
        "    elif isinstance(account_values, np.ndarray):\n",
        "        account_values = pd.Series(account_values)\n",
        "\n",
        "    sharpe = calculate_sharpe_ratio(account_values)\n",
        "    mdd = calculate_mdd(account_values)\n",
        "    cum_ret = (account_values.iloc[-1] - account_values.iloc[0]) / account_values.iloc[0] * 100\n",
        "    # num_days = (account_values.index.max() - account_values.index.min()).days\n",
        "    num_days = len(account_values)\n",
        "    ann_ret = ((1 + cum_ret / 100) ** (365 / num_days) - 1) * 100\n",
        "\n",
        "    metrics = {\n",
        "            f'sharpe_ratio': sharpe,\n",
        "            f'mdd': mdd,\n",
        "            f'ann_return': ann_ret,\n",
        "            f'cum_return': cum_ret,\n",
        "        }\n",
        "\n",
        "    if use_round:\n",
        "        metrics = {k: round(v, 2) for k, v in metrics.items()}\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def get_env_metrics(env):\n",
        "    end_total_asset = env.state[0] + sum(\n",
        "        np.array(env.state[1 : (env.stock_dim + 1)])\n",
        "        * np.array(env.state[(env.stock_dim + 1) : (env.stock_dim * 2 + 1)])\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'begin_total_asset': env.asset_memory[0],\n",
        "        'end_total_asset': end_total_asset,\n",
        "        'total_cost': env.cost,\n",
        "        'total_trades': env.trades,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "cellView": "form",
        "id": "SG9DR-fz9e-s"
      },
      "outputs": [],
      "source": [
        "#@title log_metrics\n",
        "\n",
        "def log_metrics(metrics, model_name, split_label, step=None):\n",
        "    print(f'log_metrics for {model_name}')\n",
        "\n",
        "    rename_metrics = lambda model_name: {\n",
        "        f\"{key}/{model_name}\": value for key, value in metrics.items()\n",
        "    }\n",
        "\n",
        "    renamed_metrics = rename_metrics(model_name)\n",
        "    wandb.log({split_label: renamed_metrics}, step=step)\n",
        "    # wandb.run.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "cellView": "form",
        "id": "78Xhl6wmmY9m"
      },
      "outputs": [],
      "source": [
        "#@title update_best_model_metrics\n",
        "\n",
        "def update_best_model_metrics(metrics, model_name, split_label):\n",
        "    if 'sharpe_ratios' not in wandb.run.config:\n",
        "        wandb.run.config['sharpe_ratios'] = {}\n",
        "\n",
        "    if split_label not in wandb.run.config['sharpe_ratios']:\n",
        "        wandb.run.config['sharpe_ratios'][split_label] = {}\n",
        "\n",
        "    sharpe_ratios = wandb.run.config['sharpe_ratios'][split_label]\n",
        "\n",
        "    print(f\"DEBUG ({split_label}): run.id = {wandb.run.id}\")\n",
        "    print(f\"DEBUG ({split_label}): sharpe_ratios = {sharpe_ratios}\")\n",
        "    print(f\"DEBUG ({split_label}): updating best model based on sharpe_ratios: {sharpe_ratios}\")\n",
        "    if len(sharpe_ratios) > 0:\n",
        "        best_model_name = max(sharpe_ratios, key=sharpe_ratios.get)\n",
        "        if metrics['sharpe_ratio'] > sharpe_ratios[best_model_name]:\n",
        "            print(\n",
        "                f\"DEBUG ({split_label}): {round(metrics['sharpe_ratio'], 2)} ({model_name})\"\n",
        "                f\" > {round(sharpe_ratios[best_model_name], 2)} ({best_model_name})\"\n",
        "                f\". New best model: {model_name}.\"\n",
        "            )\n",
        "            log_metrics(metrics, 'best_model', split_label)\n",
        "            wandb.log({split_label: {'best_model_name': model_name}})\n",
        "        else:\n",
        "            print(\n",
        "                f\"DEBUG ({split_label}): {round(metrics['sharpe_ratio'], 2)} ({model_name})\"\n",
        "                f\" <= {round(sharpe_ratios[best_model_name], 2)} ({best_model_name})\"\n",
        "                \". Not updating best model.\"\n",
        "            )\n",
        "    else:\n",
        "        print(f\"DEBUG ({split_label}): no models logged yet, new best model is current one: {model_name}\")\n",
        "        print(f\"DEBUG ({split_label}): wandb.run.config['sharpe_ratios'] = {wandb.run.config['sharpe_ratios']}\")\n",
        "        log_metrics(metrics, 'best_model', split_label)\n",
        "\n",
        "    wandb.run.config['sharpe_ratios'][split_label][model_name] = metrics['sharpe_ratio']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znlXqpfQZkzU"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cellView": "form",
        "id": "kF6LboMHB2xZ"
      },
      "outputs": [],
      "source": [
        "#@title init config\n",
        "parameters_dict = {}\n",
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "        'name': 'test.sharpe_ratio/best_model'\n",
        "    },\n",
        "    'parameters': parameters_dict\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7RzkkJNiSkP7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG: create dataset - yearly_train_test\n",
        "\n",
        "min_test_start_year = 2020\n",
        "max_test_start_year = 2025\n",
        "\n",
        "########################################################\n",
        "\n",
        "yearly_dataset_params = dict(\n",
        "    # dataset_period = {'value': 'year'},\n",
        "    # dataset_splits = {'parameters': {\n",
        "    #     'train': {'value': True },\n",
        "    #     'val': {'value': False },\n",
        "    #     'test': {'value': True },\n",
        "    # }},\n",
        "\n",
        "    dataset_type = {'value':'yearly_train_test'},\n",
        "\n",
        "    stock_index_name = {'value': 'DOW-30'},\n",
        "\n",
        "    train_years_count = {'value': 10},\n",
        "    test_years_count = {'value': 1},\n",
        "    test_start_year = {\n",
        "        'values': list(range(min_test_start_year, max_test_start_year))\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "l-hEkHxAfYVv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG: create dataset - quarterly_train_test\n",
        "\n",
        "# Full date range (18 backtests)\n",
        "# train_start_date = '2009-01-01'\n",
        "# min_test_start_date = '2016-01-01'\n",
        "# max_test_end_date = '2020-08-05'\n",
        "\n",
        "# Single train/val/test split (9 months = 3 quarters) for smoke test\n",
        "# train_start_date = '2015-01-01'\n",
        "# min_test_start_date = '2016-01-01'\n",
        "# max_test_end_date = '2016-10-01'\n",
        "\n",
        "# Up to 2025\n",
        "train_start_date = '2009-01-01'\n",
        "min_test_start_date = '2016-01-01'\n",
        "max_test_end_date = '2025-01-01'\n",
        "\n",
        "NUM_DATE_RANGES = None\n",
        "# NUM_DATE_RANGES = 2\n",
        "\n",
        "# NUM_RUNS_PER_DATERANGE = 1\n",
        "NUM_RUNS_PER_DATERANGE = 1\n",
        "\n",
        "#################################################################\n",
        "\n",
        "date_ranges = generate_quarterly_date_ranges(\n",
        "    train_start_date,\n",
        "    min_test_start_date,\n",
        "    max_test_end_date,\n",
        "    return_strings=True,\n",
        "    finetune_previous_val=True\n",
        ")\n",
        "\n",
        "truncated_date_ranges = date_ranges[:NUM_DATE_RANGES]\n",
        "copied_or_truncated_date_ranges = [\n",
        "    date_range\n",
        "    for date_range in truncated_date_ranges\n",
        "    for _ in range(NUM_RUNS_PER_DATERANGE)\n",
        "]\n",
        "\n",
        "quarterly_dataset_params = dict(\n",
        "    dataset_type = {'value': 'quarterly_train_val_test'},\n",
        "    stock_index_name = {'value': 'DOW-30'},\n",
        "    train_start_date = {'value': train_start_date},\n",
        "    min_test_start_date = {'value': min_test_start_date},\n",
        "    max_test_end_date = {'value': max_test_end_date},\n",
        "    date_range = {\n",
        "        # 'values': copied_or_truncated_date_ranges\n",
        "        'values': truncated_date_ranges\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GJDvneoY00zo",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG: choose dataset\n",
        "parameters_dict.update(\n",
        "    # yearly_dataset_params,\n",
        "    quarterly_dataset_params\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "cellView": "form",
        "id": "EipLEV8h4L5Q"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG: number of seeds\n",
        "\n",
        "NUM_SEEDS = 1\n",
        "\n",
        "parameters_dict.update({\n",
        "    'seed': {'values': (np.random.randn(NUM_SEEDS) * 1e8).astype(int).tolist()}\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ILF379nrW4YK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG: env params\n",
        "\n",
        "# ENV_CLASS = 'np'\n",
        "ENV_CLASS = 'stoploss'\n",
        "\n",
        "###########################\n",
        "assert ENV_CLASS in ['np', 'stoploss']\n",
        "\n",
        "parameters_dict.update(dict(\n",
        "    env_class = {'value': ENV_CLASS},\n",
        "    cost_pct = {'value': 1e-3},\n",
        "    initial_amount = {'value': 50_000},\n",
        "    turbulence_threshold = {\n",
        "        'value': 99,\n",
        "        # 'values': [30, 40, 50, 60, 70]\n",
        "    },\n",
        "    # eval_turbulence_thresh = {'value': 25},\n",
        "    if_vix = {'value': True}\n",
        "))\n",
        "\n",
        "if ENV_CLASS == 'stoploss':\n",
        "    parameters_dict.update({\n",
        "        'discrete_actions': {'value': True},\n",
        "        'patient': {'value': True},\n",
        "        'cache_indicator_data': {'value': True},\n",
        "        'print_verbosity': {'value': 0}\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "cellView": "form",
        "id": "PzWRRS6Prorh"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG: models_used\n",
        "\n",
        "MODELS_USED = [\n",
        "    'ppo'\n",
        "]\n",
        "\n",
        "parameters_dict.update({\n",
        "    'models_used': {'value': MODELS_USED}\n",
        "})\n",
        "\n",
        "# TODO: remove legacy config used for backward compat\n",
        "parameters_dict.update({\n",
        "    'if_using_a2c': {'value': 'ppo' in MODELS_USED},\n",
        "    'if_using_ddpg': {'value': 'ddpg' in MODELS_USED},\n",
        "    'if_using_ppo': {'value': 'ppo' in MODELS_USED},\n",
        "    'if_using_td3': {'value': 'td3' in MODELS_USED},\n",
        "    'if_using_sac': {'value': 'sac' in MODELS_USED}\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "XaCu08TIKegP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG: model and training params\n",
        "\n",
        "training_params = {\n",
        "    \"parameters\": {\n",
        "        \"ppo\": {\n",
        "            \"parameters\": dict(\n",
        "                steps={\"value\": 1}, # smoke test\n",
        "                train_batch_size={\"value\": 128}, # smoke test\n",
        "\n",
        "                # steps={\"value\": 8_192},\n",
        "                # train_batch_size={\"value\": 2048},\n",
        "\n",
        "                minibatch_size={\"value\": 128},\n",
        "                num_epochs={\"value\": 10},\n",
        "                lr={\"value\": 5e-5},\n",
        "                gamma={\"value\": 0.99},\n",
        "            )\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "env_runners_params = {\n",
        "    'parameters': dict(\n",
        "        num_envs_per_env_runner = {'value': 1},\n",
        "        num_env_runners = {'value': 0},\n",
        "    )\n",
        "}\n",
        "\n",
        "parameters_dict.update({'env_runners_params': env_runners_params})\n",
        "parameters_dict.update({'training_params': training_params})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONFIG: quantile gridsearch\n",
        "\n",
        "# quantile_gridsearch_params = dict(\n",
        "#     lookback_window = {'value': 63}, # one quarter\n",
        "#     is_expanding_insample = {'value': True},\n",
        "#     is_sliding_window = {'value': True},\n",
        "\n",
        "#     # q_lower = {'value': 0.1},\n",
        "#     # q_upper = {'value': 0.9},\n",
        "#     # q_step = {'value': 0.1},\n",
        "\n",
        "#     q_lower = {'value': 0.5},\n",
        "#     q_upper = {'value': 0.5},\n",
        "#     q_step = {'value': 0.1},\n",
        "# )\n",
        "\n",
        "# parameters_dict.update(quantile_gridsearch_params)"
      ],
      "metadata": {
        "id": "A0964eYpamU2",
        "cellView": "form"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqc-9r54tuXG"
      },
      "source": [
        "# Train & eval funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "cellView": "form",
        "id": "bEKCwsuzPj51"
      },
      "outputs": [],
      "source": [
        "#@title MetricsLoggerCallback (class)\n",
        "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
        "from typing import Optional, Sequence\n",
        "import gymnasium as gym\n",
        "from gymnasium.vector import AsyncVectorEnv\n",
        "\n",
        "AVAILABLE_ENV_CLASSES = ['np', 'stoploss']\n",
        "\n",
        "class MetricsLoggerCallback(DefaultCallbacks):\n",
        "    def __init__(self, model_name, env_class, ema_coeff=0.2, ma_window=20, log_to_wandb=False):\n",
        "        assert env_class in AVAILABLE_ENV_CLASSES\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.env_class = env_class\n",
        "        self.ema_coeff = ema_coeff\n",
        "        self.ma_window = ma_window\n",
        "        self.metric_names = set()\n",
        "        self.log_to_wandb = log_to_wandb\n",
        "\n",
        "    def unwrap_env(self, env):\n",
        "        env = env.unwrapped\n",
        "        # print(type(env))\n",
        "        # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.vector.sync_vector_env.SyncVectorEnv'>\n",
        "\n",
        "        if isinstance(env, AsyncVectorEnv):\n",
        "            return env\n",
        "        else:\n",
        "            env = env.envs[0]\n",
        "            # print(type(env))\n",
        "            # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.wrappers.common.OrderEnforcing'>\n",
        "\n",
        "            env = env.env\n",
        "            # print(type(env))\n",
        "            # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.wrappers.common.PassiveEnvChecker'>\n",
        "\n",
        "            env = env.env\n",
        "            # print(type(env))\n",
        "            # (SingleAgentEnvRunner pid=127688) <class 'finrl.meta.env_stock_trading.env_stocktrading.StockTradingEnv'>\n",
        "        return env\n",
        "\n",
        "    def on_episode_step(\n",
        "            self,\n",
        "            *,\n",
        "            episode,\n",
        "            env_runner,\n",
        "            metrics_logger,\n",
        "            env,\n",
        "            env_index,\n",
        "            rl_module,\n",
        "            **kwargs,\n",
        "        ) -> None:\n",
        "\n",
        "        env = self.unwrap_env(env)\n",
        "\n",
        "        if isinstance(env, AsyncVectorEnv):\n",
        "            df_account_value = env.get_attr('asset_memory')\n",
        "            df_account_value = pd.concat([pd.Series(av) for av in df_account_value], axis=1).mean(axis=1)\n",
        "\n",
        "            # TODO: save_asset_memory\n",
        "            raise NotImplementedError\n",
        "        else:\n",
        "            # df_account_value = env.asset_memory\n",
        "            df_account_value = env.save_asset_memory()\n",
        "\n",
        "            if self.env_class == 'np':\n",
        "                df_account_value = df_account_value.rename(\n",
        "                    columns={'account_value': self.model_name.upper()}\n",
        "                )\n",
        "            elif self.env_class == 'stoploss':\n",
        "                df_account_value = df_account_value[['date', 'total_assets']].rename(\n",
        "                    columns={'total_assets': self.model_name.upper()}\n",
        "                )\n",
        "\n",
        "        # print(f\"Env {env_index} day: {env.day}\")\n",
        "        metrics = compute_metrics(df_account_value)\n",
        "\n",
        "        # mode = env.mode\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            # metric_name = f\"{mode}/{metric_name}\" if mode != \"\" else metric_name\n",
        "            episode.add_temporary_timestep_data(metric_name, metric_value)\n",
        "            self.metric_names.update([metric_name])\n",
        "\n",
        "    def on_episode_end(\n",
        "            self,\n",
        "            *,\n",
        "            episode,\n",
        "            env_runner,\n",
        "            metrics_logger,\n",
        "            env,\n",
        "            env_index,\n",
        "            rl_module,\n",
        "            **kwargs,\n",
        "        ) -> None:\n",
        "\n",
        "        for metric_name in self.metric_names:\n",
        "            metric_values = episode.get_temporary_timestep_data(metric_name)\n",
        "            metric_value = np.nanmean(np.array(metric_values))\n",
        "\n",
        "            metrics_logger.log_value(\n",
        "                metric_name,\n",
        "                metric_value,\n",
        "                reduce='mean',\n",
        "            )\n",
        "\n",
        "            metrics_logger.log_value(\n",
        "                f\"{metric_name}_EMA_{self.ema_coeff}\",\n",
        "                metric_value,\n",
        "                reduce='mean',\n",
        "                ema_coeff=self.ema_coeff\n",
        "            )\n",
        "\n",
        "            metrics_logger.log_value(\n",
        "                f\"{metric_name}_MA_{self.ma_window}\",\n",
        "                metric_value,\n",
        "                reduce='mean',\n",
        "                window=self.ma_window\n",
        "            )\n",
        "\n",
        "            # mode = 'val' if env_runner.config.in_evaluation else 'train'\n",
        "            # print(f\"Metrics for {mode} episode {episode}:\")\n",
        "            # print({\n",
        "            #     f\"{mode}.{metric_name}/{self.model_name}\": metric_value,\n",
        "            # }) # TODO: log on every episode step\n",
        "\n",
        "            if self.log_to_wandb:\n",
        "                mode = 'val' if env_runner.config.in_evaluation else 'train'\n",
        "                wandb.log({\n",
        "                    f\"{mode}.{metric_name}/{self.model_name}\": metric_value,\n",
        "                }) # TODO: log on every episode step\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "cellView": "form",
        "id": "UjgO7DBIDk7I"
      },
      "outputs": [],
      "source": [
        "#@title print_result\n",
        "\n",
        "RESULT_KEYS_TO_INCLUDE = [\n",
        "    'sharpe_ratio',\n",
        "    'ann_return',\n",
        "    'mdd',\n",
        "\n",
        "    # 'sharpe_ratio_MA',\n",
        "    # 'ann_return_MA',\n",
        "    # 'mdd_MA',\n",
        "\n",
        "    # 'sharpe_ratio_EMA',\n",
        "    # 'ann_return_EMA',\n",
        "    # 'mdd_EMA',\n",
        "]\n",
        "\n",
        "def print_result(result):\n",
        "    print()\n",
        "    print('-' * 40)\n",
        "\n",
        "    keys_to_print = [\n",
        "        key\n",
        "        for include_key in RESULT_KEYS_TO_INCLUDE\n",
        "        for key in result['env_runners'].keys()\n",
        "        if key.startswith(include_key)\n",
        "    ]\n",
        "\n",
        "    for key in sorted(keys_to_print):\n",
        "        print(f\"train/{key}: {round(result['env_runners'][key], 2)}\")\n",
        "\n",
        "    if 'evaluation' in result.keys():\n",
        "        print('*' * 40)\n",
        "        keys_to_print = [\n",
        "            key\n",
        "            for include_key in RESULT_KEYS_TO_INCLUDE\n",
        "            for key in result['evaluation']['env_runners'].keys()\n",
        "            if key.startswith(include_key)\n",
        "        ]\n",
        "\n",
        "        for key in sorted(keys_to_print):\n",
        "            print(f\"val/{key}: {round(result['evaluation']['env_runners'][key], 2)}\")\n",
        "\n",
        "        print('-' * 40)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "cellView": "form",
        "id": "V0iyYcwTOZYP"
      },
      "outputs": [],
      "source": [
        "#@title benchmark_exec_time\n",
        "import pandas as pd\n",
        "from time import perf_counter\n",
        "from functools import wraps\n",
        "\n",
        "def benchmark_exec_time(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "\n",
        "        start = perf_counter()\n",
        "        output = func(*args, **kwargs)\n",
        "        end = perf_counter()\n",
        "\n",
        "        exec_time_sec = end - start\n",
        "\n",
        "        data = {\n",
        "            \"func_name\": func.__name__,\n",
        "            \"exec_time_sec\": exec_time_sec,\n",
        "        }\n",
        "        # print(f'\\nBenchmark results: {data}')\n",
        "        return output, exec_time_sec\n",
        "\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "cellView": "form",
        "id": "TLDeH1lN2XAS"
      },
      "outputs": [],
      "source": [
        "#@title Train_eval_models\n",
        "\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "\n",
        "AVAILABLE_MODELS_CONFIGS = {\n",
        "    'ppo': PPOConfig\n",
        "}\n",
        "\n",
        "def train_eval_rllib_models(\n",
        "        run_config,\n",
        "        train_np_env_config,\n",
        "        val_np_env_config,\n",
        "        test_np_env_config,\n",
        "        model_list = ['ppo'], # TODO: discard in favor of 'if_using_{model_name}'\n",
        "        pretrained_models = {} # pretrained on previous train set (not validation set)\n",
        "    ):\n",
        "\n",
        "    assert set(model_list).issubset(AVAILABLE_MODELS_CONFIGS)\n",
        "    check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "\n",
        "    create_env_fn = CREATE_ENV_FN[run_config['env_class']]\n",
        "    register_env(\"stock_trading_env\", create_env_fn)\n",
        "\n",
        "    for model_name in model_list:\n",
        "        if run_config[f\"if_using_{model_name}\"]:\n",
        "            print(f\"Training {model_name.upper()} agent\")\n",
        "            model_config = AVAILABLE_MODELS_CONFIGS[model_name]\n",
        "            algo = train_rllib_model(\n",
        "                run_config,\n",
        "                model_name,\n",
        "                model_config,\n",
        "                train_np_env_config,\n",
        "                val_np_env_config,\n",
        "                pretrained_ckpt_path = pretrained_models.get(model_name, None)\n",
        "            )\n",
        "\n",
        "            print(f\"Evaluating {model_name.upper()} agent\")\n",
        "            val_result = evaluate_model(\n",
        "                algo,\n",
        "                model_name,\n",
        "                run_config=run_config,\n",
        "                np_env_config = val_np_env_config,\n",
        "                mode='val',\n",
        "            )\n",
        "            fig = plot_results(**val_result)\n",
        "            log_plot_as_artifact(fig, \"val_cumulative_return\", artifact_type=\"plot\")\n",
        "\n",
        "            test_result = evaluate_model(\n",
        "                algo,\n",
        "                model_name,\n",
        "                run_config=run_config,\n",
        "                np_env_config = test_np_env_config,\n",
        "                mode='test',\n",
        "            )\n",
        "            fig = plot_results(**test_result)\n",
        "            log_plot_as_artifact(fig, \"test_cumulative_return\", artifact_type=\"plot\")\n",
        "            pretrained_models[model_name] = algo\n",
        "        else:\n",
        "            print(f\"Skipping {model_name.upper()} agent\")\n",
        "\n",
        "    return pretrained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "cellView": "form",
        "id": "qH-OEXfqEaFR"
      },
      "outputs": [],
      "source": [
        "#@title Train_eval_models (w/ threshold gridsearch)\n",
        "\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "\n",
        "AVAILABLE_MODELS_CONFIGS = {\n",
        "    'ppo': PPOConfig\n",
        "}\n",
        "\n",
        "def train_eval_rllib_models(\n",
        "        run_config,\n",
        "\n",
        "        train_np_env_config,\n",
        "        val_np_env_config,\n",
        "        test_np_env_config,\n",
        "\n",
        "        model_list = ['ppo'], # TODO: discard in favor of 'if_using_{model_name}'\n",
        "        pretrained_val_models = {},\n",
        "    ):\n",
        "\n",
        "    assert set(model_list).issubset(AVAILABLE_MODELS_CONFIGS)\n",
        "    check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "\n",
        "    create_env_fn = CREATE_ENV_FN[run_config['env_class']]\n",
        "    register_env(\"stock_trading_env\", create_env_fn)\n",
        "\n",
        "    for model_name in model_list:\n",
        "        if run_config[f\"if_using_{model_name}\"]:\n",
        "            model_config = AVAILABLE_MODELS_CONFIGS[model_name]\n",
        "\n",
        "            # Skip training if a model pretrained on previous validation set is passed.\n",
        "            # The training should happen only for first run,\n",
        "            # further runs should reuse pretrained val models.\n",
        "            if model_name in pretrained_val_models:\n",
        "                algo_train = pretrained_val_models[model_name]\n",
        "            else:\n",
        "                algo_train = train_rllib_model(\n",
        "                    run_config,\n",
        "                    model_name,\n",
        "                    model_config,\n",
        "                    train_np_env_config,\n",
        "                    val_np_env_config,\n",
        "                    pretrained_ckpt_path = None # Train from scratch\n",
        "                )\n",
        "\n",
        "            wandb.run.summary['val.num_pretrain_iters'] = algo_train.training_iteration\n",
        "\n",
        "            # Evaluate on validation set\n",
        "            # using model trained on current train set (previous val set)\n",
        "            val_best_th = evaluate_threshold_grid(\n",
        "                algo_train,\n",
        "                model_name,\n",
        "                run_config,\n",
        "                val_np_env_config,\n",
        "                split_label='val',\n",
        "            )\n",
        "\n",
        "            # Finetune on current validation set (previous test set)\n",
        "            algo_val = train_rllib_model(\n",
        "                run_config,\n",
        "                model_name,\n",
        "                model_config,\n",
        "                train_np_env_config,\n",
        "                val_np_env_config,\n",
        "                pretrained_ckpt_path = algo_train\n",
        "            )\n",
        "\n",
        "            # Evaluate on test set\n",
        "            # using model finetuned on current validation set (previous test set)\n",
        "            _ = evaluate_threshold_grid(\n",
        "                algo_val,\n",
        "                model_name,\n",
        "                run_config,\n",
        "                test_np_env_config,\n",
        "                split_label='test',\n",
        "                chosen_th=val_best_th # chosen before fine-tuning\n",
        "            )\n",
        "\n",
        "            pretrained_val_models[model_name] = algo_val\n",
        "        else:\n",
        "            print(f\"Skipping {model_name.upper()} agent\")\n",
        "\n",
        "    return pretrained_val_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "cellView": "form",
        "id": "0mX2fB5OQ6s5"
      },
      "outputs": [],
      "source": [
        "#@title Train_eval_models (w/ quantile gridsearch)\n",
        "\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "\n",
        "AVAILABLE_MODELS_CONFIGS = {\n",
        "    'ppo': PPOConfig\n",
        "}\n",
        "\n",
        "def train_eval_rllib_models(\n",
        "        run_config,\n",
        "        train_np_env_config,\n",
        "        val_np_env_config,\n",
        "        test_np_env_config,\n",
        "\n",
        "        data,\n",
        "        data_processor,\n",
        "        current_run_id,\n",
        "        sweep_api,\n",
        "\n",
        "        model_list = ['ppo'], # TODO: discard in favor of 'if_using_{model_name}'\n",
        "        pretrained_val_models = {},\n",
        "    ):\n",
        "\n",
        "    assert set(model_list).issubset(AVAILABLE_MODELS_CONFIGS)\n",
        "    check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "\n",
        "    create_env_fn = CREATE_ENV_FN[run_config['env_class']]\n",
        "    register_env(\"stock_trading_env\", create_env_fn)\n",
        "\n",
        "    for model_name in model_list:\n",
        "        if run_config[f\"if_using_{model_name}\"]:\n",
        "            model_config = AVAILABLE_MODELS_CONFIGS[model_name]\n",
        "\n",
        "            # Skip training if a model pretrained on previous validation set is passed.\n",
        "            # The training should happen only for first run,\n",
        "            # further runs should reuse pretrained val models.\n",
        "            if model_name in pretrained_val_models:\n",
        "                algo_train = pretrained_val_models[model_name]\n",
        "            else:\n",
        "                algo_train = train_rllib_model(\n",
        "                    run_config,\n",
        "                    model_name,\n",
        "                    model_config,\n",
        "                    train_np_env_config,\n",
        "                    val_np_env_config,\n",
        "                    pretrained_ckpt_path = None # Train from scratch\n",
        "                )\n",
        "\n",
        "            wandb.run.summary['val.num_pretrain_iters'] = algo_train.training_iteration\n",
        "\n",
        "            # Evaluate on validation set\n",
        "\n",
        "            # Finetune on current validation set (previous test set)\n",
        "            algo_val = train_rllib_model(\n",
        "                run_config,\n",
        "                model_name,\n",
        "                model_config,\n",
        "                train_np_env_config,\n",
        "                val_np_env_config,\n",
        "                pretrained_ckpt_path = algo_train\n",
        "            )\n",
        "\n",
        "            val_rl_module = algo_val.env_runner.module\n",
        "\n",
        "            # eval_quantile_grid(\n",
        "            #     model_name,\n",
        "            #     val_rl_module,\n",
        "            #     data,\n",
        "            #     data_processor,\n",
        "            #     current_run_id,\n",
        "            #     sweep_api,\n",
        "\n",
        "            #     SILENT = True,\n",
        "\n",
        "            #     FILTER_HASH_LIST = None,\n",
        "\n",
        "            #     LOG_PLOTS = 'last_only',\n",
        "\n",
        "            #     LIMIT_RUNS = None,\n",
        "\n",
        "            #     #######################\n",
        "\n",
        "            #     lookback_window = run_config['lookback_window'],\n",
        "            #     is_expanding_insample = run_config['is_expanding_insample'],\n",
        "            #     is_sliding_window = run_config['is_sliding_window'],\n",
        "\n",
        "            #     q_lower = run_config['q_lower'],\n",
        "            #     q_upper = run_config['q_upper'],\n",
        "            #     q_step = run_config['q_step'],\n",
        "            # )\n",
        "\n",
        "            pretrained_val_models[model_name] = algo_val\n",
        "        else:\n",
        "            print(f\"Skipping {model_name.upper()} agent\")\n",
        "\n",
        "    return pretrained_val_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "cellView": "form",
        "id": "_9m6B_eWpLht"
      },
      "outputs": [],
      "source": [
        "#@title Train_eval_models (StopLossEnv)\n",
        "\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "\n",
        "AVAILABLE_MODELS_CONFIGS = {\n",
        "    'ppo': PPOConfig\n",
        "}\n",
        "\n",
        "def train_eval_rllib_models(\n",
        "        run,\n",
        "\n",
        "        data,\n",
        "        data_processor,\n",
        "        current_run_id,\n",
        "        sweep_api,\n",
        "\n",
        "        train_np_env_config=None,\n",
        "        val_np_env_config=None,\n",
        "        test_np_env_config=None,\n",
        "\n",
        "        train_stoploss_data_df = None,\n",
        "        val_stoploss_data_df = None,\n",
        "        test_stoploss_data_df = None,\n",
        "\n",
        "        model_list = ['ppo'], # TODO: discard in favor of 'if_using_{model_name}'\n",
        "        pretrained_ckpt_paths = {},\n",
        "    ):\n",
        "\n",
        "    run_config = run.config\n",
        "\n",
        "    assert set(model_list).issubset(AVAILABLE_MODELS_CONFIGS)\n",
        "    check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "\n",
        "    create_env_fn = CREATE_ENV_FN[run_config['env_class']]\n",
        "    register_env(\"stock_trading_env\", create_env_fn)\n",
        "\n",
        "    for model_name in model_list:\n",
        "        if run_config[f\"if_using_{model_name}\"]:\n",
        "            model_config = AVAILABLE_MODELS_CONFIGS[model_name]\n",
        "\n",
        "            # Skip training if a model pretrained on previous validation set is passed.\n",
        "            # The training should happen only for first run,\n",
        "            # further runs should reuse pretrained val models.\n",
        "            if model_name in pretrained_ckpt_paths:\n",
        "                train_ckpt_path = pretrained_ckpt_paths[model_name]\n",
        "            else:\n",
        "                algo_train, train_ckpt_path = train_rllib_model(\n",
        "                    run_config,\n",
        "                    model_name,\n",
        "                    model_config,\n",
        "\n",
        "                    train_np_env_config = train_np_env_config,\n",
        "                    val_np_env_config = val_np_env_config,\n",
        "\n",
        "                    train_stoploss_data_df = train_stoploss_data_df,\n",
        "                    val_stoploss_data_df = val_stoploss_data_df,\n",
        "\n",
        "                    split_name = 'train',\n",
        "\n",
        "                    pretrained_ckpt_path = None # Train from scratch\n",
        "                )\n",
        "\n",
        "            eval_run_config = run_config._as_dict().copy() # HACK: ideally contain settings in run_config['env_config']\n",
        "            eval_run_config.update({'random_start': False})\n",
        "\n",
        "            # Evaluate on val\n",
        "            val_result = evaluate_model(\n",
        "                algo_train,\n",
        "                model_name,\n",
        "\n",
        "                run=run,\n",
        "                run_config=eval_run_config,\n",
        "\n",
        "                np_env_config = val_np_env_config,\n",
        "                stoploss_data_df = val_stoploss_data_df,\n",
        "                split_label='val',\n",
        "\n",
        "                log_to_wandb=True,\n",
        "                return_metrics=False,\n",
        "            )\n",
        "\n",
        "            # Finetune on current validation set (previous test set)\n",
        "            algo_val, val_ckpt_path = train_rllib_model(\n",
        "                run_config,\n",
        "                model_name,\n",
        "                model_config,\n",
        "\n",
        "                train_np_env_config = val_np_env_config,\n",
        "                val_np_env_config = None,\n",
        "\n",
        "                train_stoploss_data_df = val_stoploss_data_df,\n",
        "                val_stoploss_data_df = None,\n",
        "\n",
        "                split_name = 'val',\n",
        "\n",
        "                pretrained_ckpt_path = train_ckpt_path\n",
        "            )\n",
        "\n",
        "            # Evaluate on test\n",
        "            val_result = evaluate_model(\n",
        "                algo_val,\n",
        "                model_name,\n",
        "\n",
        "                run=run,\n",
        "                run_config=eval_run_config,\n",
        "\n",
        "                np_env_config = test_np_env_config,\n",
        "                stoploss_data_df = test_stoploss_data_df,\n",
        "                split_label='test',\n",
        "\n",
        "                log_to_wandb=True,\n",
        "                return_metrics=False,\n",
        "            )\n",
        "\n",
        "\n",
        "            pretrained_ckpt_paths[model_name] = val_ckpt_path\n",
        "\n",
        "        else:\n",
        "            print(f\"Skipping {model_name.upper()} agent\")\n",
        "\n",
        "    return pretrained_ckpt_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "cellView": "form",
        "id": "2UZ8m5R2rOtn"
      },
      "outputs": [],
      "source": [
        "#@title YahooDownloader (compatible with original FinRL)\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic, start=self.start_date, end=self.end_date, proxy=proxy\n",
        "            )\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures += 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "\n",
        "        try:\n",
        "            # Convert wide to long format\n",
        "            # print(f\"DATA COLS: {data_df.columns}\")\n",
        "            data_df = data_df.sort_index(axis=1).set_index(['Date']).drop(columns=['tic']).stack(level='Ticker', future_stack=True)\n",
        "            data_df.reset_index(inplace=True)\n",
        "            data_df.columns.name = ''\n",
        "\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(columns={'Ticker': 'Tic', 'Adj Close': 'Adjcp'}, inplace=True)\n",
        "            data_df.rename(columns={col: col.lower() for col in data_df.columns}, inplace=True)\n",
        "\n",
        "            columns = [\n",
        "                \"date\",\n",
        "                \"tic\",\n",
        "                \"open\",\n",
        "                \"high\",\n",
        "                \"low\",\n",
        "                \"close\",\n",
        "                # \"adjcp\",\n",
        "                \"volume\",\n",
        "            ]\n",
        "\n",
        "            data_df = data_df[columns]\n",
        "            if 'adjcp' in data_df.columns:\n",
        "                # use adjusted close price instead of close price\n",
        "                data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "                # drop the adjusted close price column\n",
        "                data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "zEycEltOp0mq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title load DIJA\n",
        "\n",
        "def load_djia(\n",
        "        start_date,\n",
        "        end_date,\n",
        "        initial_amount\n",
        "    ):\n",
        "\n",
        "    \"\"\"\n",
        "    Load prices of index scaled by initial amount\n",
        "    \"\"\"\n",
        "\n",
        "    # Download DIJA\n",
        "    df_djia = YahooDownloader(\n",
        "        start_date = start_date,\n",
        "        end_date = end_date + pd.Timedelta(days=1), # include last day\n",
        "        ticker_list=['^DJI'] # `dji` is delisted, `DJIA` is an ETF, not an index\n",
        "    ).fetch_data()\n",
        "\n",
        "\n",
        "    # Scale DJIA data\n",
        "    df_djia = df_djia[['date','close']]\n",
        "    fst_day = df_djia['close'].iloc[0]\n",
        "    df_djia = pd.DataFrame({\n",
        "        'date': df_djia['date'],\n",
        "        'DJIA': df_djia['close'].div(fst_day).mul(initial_amount).values,\n",
        "    })\n",
        "\n",
        "    df_djia['date'] = pd.to_datetime(df_djia['date'])\n",
        "\n",
        "    return df_djia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title eval_agg_dija\n",
        "import wandb\n",
        "\n",
        "def eval_agg_dija(first_run_or_sweep, last_run, split_label='test', silent=False):\n",
        "    \"\"\"\n",
        "    Compute DJIA metrics aggregated over period\n",
        "        from first_run `test_start_date`\n",
        "        till last_run  `test_end_date`\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(first_run_or_sweep, wandb.apis.public.sweeps.Sweep):\n",
        "        # sweep\n",
        "        test_start_date = first_run_or_sweep.config['parameters']['min_test_start_date']['value']\n",
        "        initial_amount = first_run_or_sweep.config['parameters']['initial_amount']['value']\n",
        "    else:\n",
        "        # first_run\n",
        "        test_start_date = first_run_or_sweep.config['date_range']['test_start_date']\n",
        "        initial_amount = first_run_or_sweep.config['initial_amount']\n",
        "\n",
        "    df_djia = load_djia(\n",
        "        start_date=pd.Timestamp(test_start_date),\n",
        "        end_date=pd.Timestamp(last_run.config['date_range']['test_end_date']),\n",
        "        initial_amount=initial_amount\n",
        "    )\n",
        "\n",
        "    djia_metrics = compute_metrics(df_djia)\n",
        "    print(f'djia_metrics: {djia_metrics}')\n",
        "\n",
        "    # assert isinstance(last_run, wandb.sdk.wandb_run.Run), \"last_run should be activated\"\n",
        "\n",
        "    log_eval_results(\n",
        "        'djia',\n",
        "        djia_metrics,\n",
        "        split_label=split_label,\n",
        "        metric_prefix='agg',\n",
        "        run=last_run\n",
        "    )\n",
        "\n",
        "    # wandb.finish()\n",
        "\n",
        "    return df_djia, djia_metrics\n",
        "\n",
        "# FILTER_HASH = '1ea39a67636c8e66b0064c4cac304a880b02405eff96aa2bc82017e78cd8461f'\n",
        "\n",
        "# run_list = config_hash_to_runs[FILTER_HASH]\n",
        "# last_run = get_last_finished_run(run_list)\n",
        "# first_run = get_first_finished_run(run_list)\n",
        "# df_djia, djia_metrics = eval_agg_dija(first_run, last_run, silent=True)\n",
        "# df_djia.head()"
      ],
      "metadata": {
        "id": "OS5aJj-c71ku",
        "cellView": "form"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "CV40tLS8ZQ_M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download artifacts\n",
        "from pathlib import Path\n",
        "\n",
        "def load_artifacts(run_id, artifact_types, prepend_run_id=False, skip_cache=False):\n",
        "    assert isinstance(artifact_types, list)\n",
        "\n",
        "    # Initialize the W&B API\n",
        "    api = wandb.Api()\n",
        "\n",
        "    # Retrieve the run\n",
        "    run = api.run(f\"{ENTITY}/{PROJECT}/{run_id}\")\n",
        "\n",
        "    # Iterate over the artifacts used or logged by the run\n",
        "    artifacts_cnt = {_type: 0 for _type in artifact_types}\n",
        "    artifacts_folders_per_run = {_type: [] for _type in artifact_types}\n",
        "    print(len(run.logged_artifacts()))\n",
        "    for artifact in run.logged_artifacts():\n",
        "        # print(f'Considering artifact {artifact.name}')\n",
        "\n",
        "        if \"latest\" in artifact.aliases \\\n",
        "        and artifact.type in artifact_types:\n",
        "            artifacts_cnt[artifact.type] += 1\n",
        "\n",
        "            artifact_folder = Path(f'{artifact.name}')\n",
        "            if prepend_run_id:\n",
        "                artifact_folder = run_id / artifact_folder\n",
        "\n",
        "            artifacts_folders_per_run[artifact.type].append(artifact_folder)\n",
        "\n",
        "            if not os.path.exists(artifact_folder) or skip_cache:\n",
        "                !rm -rf {str(artifact_folder)}\n",
        "\n",
        "                print(f\"Downloading artifacts to {artifact_folder}\")\n",
        "                artifact.download(artifact_folder)\n",
        "            else:\n",
        "                print(f\"Using cached data at {artifact_folder}\")\n",
        "\n",
        "\n",
        "    print(f\"Run id: {run_id}\")\n",
        "    print(f'Artifacts downloaded cnt per type: {artifacts_cnt}')\n",
        "    print(f\"Artifacts folders per type: {artifacts_folders_per_run}\")\n",
        "    print()\n",
        "    return artifacts_folders_per_run\n",
        "\n",
        "# artifacts_folders_per_run = load_artifacts(\n",
        "#     run_id='rbug5oxn',\n",
        "#     artifact_types=['trained_models'],\n",
        "#     prepend_run_id=True\n",
        "# )\n",
        "\n",
        "# artifacts_folders_per_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LyO_r1jF8ecm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title get_env_end_state\n",
        "\n",
        "def get_env_end_state(\n",
        "    run,\n",
        "    model_name,\n",
        "    split_label,\n",
        "    **fmt_metric_name_kwargs\n",
        "):\n",
        "\n",
        "    end_amount_fmt_name = get_formatted_metric_name(\n",
        "        model_name = model_name,\n",
        "        metric_name = 'end_amount',\n",
        "        split_label = split_label,\n",
        "        **fmt_metric_name_kwargs\n",
        "    )\n",
        "\n",
        "    end_stocks_fmt_name = get_formatted_metric_name(\n",
        "        model_name = model_name,\n",
        "        metric_name = 'end_stocks',\n",
        "        split_label = split_label,\n",
        "        **fmt_metric_name_kwargs\n",
        "    )\n",
        "\n",
        "    end_amount = run.summary.get(end_amount_fmt_name, None)\n",
        "    end_stocks = run.summary.get(end_stocks_fmt_name, None)\n",
        "\n",
        "    print(f\"Env metrics for run {run.id} with test start date {run.config['date_range']['test_start_date']}\")\n",
        "    print(f\"Env {end_amount_fmt_name}: {end_amount}\")\n",
        "    print(f\"Env {end_stocks_fmt_name}: {end_stocks}\")\n",
        "\n",
        "    return end_amount, end_stocks\n",
        "\n",
        "# end_amount, end_stocks = get_env_end_state(\n",
        "#     wandb.run,\n",
        "#     model_name='ppo',\n",
        "#     split_label='val'\n",
        "# )\n",
        "# end_amount, end_stocks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (func) evaluate SLIDING WINDOW aggregated metrics for quantile GRID (w/plots & DJIA & caching) # TODO\n",
        "\n",
        "def eval_quantile_grid(\n",
        "    model_name,\n",
        "    rl_module,\n",
        "    data,\n",
        "    data_processor,\n",
        "    current_run_id,\n",
        "    sweep_api,\n",
        "\n",
        "    SILENT = True,\n",
        "\n",
        "    FILTER_HASH_LIST = None,\n",
        "    # FILTER_HASH_LIST = FILTER_HASH_LIST_DICT[SWEEP_ID],\n",
        "\n",
        "    # LOG_PLOTS = False,\n",
        "    # LOG_PLOTS = 'all',\n",
        "    LOG_PLOTS = 'last_only',\n",
        "\n",
        "    LIMIT_RUNS = None,\n",
        "    # LIMIT_RUNS = 1,\n",
        "\n",
        "    #######################\n",
        "\n",
        "    lookback_window = 63, # one quarter\n",
        "    is_expanding_insample = True,\n",
        "    is_sliding_window = True,\n",
        "\n",
        "    # q_lower = 0.1,\n",
        "    # q_upper = 0.9,\n",
        "    # q_step = 0.2,\n",
        "\n",
        "    q_lower = 0.5,\n",
        "    q_upper = 0.5,\n",
        "    q_step = 0.1,\n",
        "):\n",
        "    assert is_expanding_insample, \"Only expanding in-sample currently supported for on-line sweep\"\n",
        "    assert isinstance(LOG_PLOTS, bool) or LOG_PLOTS in ['last_only', 'all']\n",
        "\n",
        "    quantile_log_name = 'q'\n",
        "    quantile_log_name += 'e' if is_expanding_insample else ''\n",
        "    quantile_log_name += 's' if is_sliding_window else ''\n",
        "\n",
        "    quantile_grid = np.arange(q_lower, q_upper + q_step, q_step).round(2)\n",
        "\n",
        "    current_run_api = WANDB_API.run(f\"{PROJECT}/{current_run_id}\")\n",
        "    prev_run_id = find_prev_run(sweep_api.id, current_run_id)\n",
        "    prev_run_api = WANDB_API.run(f\"{PROJECT}/{current_run_id}\")\n",
        "\n",
        "    is_last_run = (current_run_api.config['date_range']['test_end_date'] == sweep_api.config['parameters']['max_test_end_date']['value'])\n",
        "\n",
        "    if_vix = current_run_api.config.get('if_vix', True)\n",
        "    if if_vix:\n",
        "        turbulence_log_name = 'vix'\n",
        "        turbulence_label = 'vix'\n",
        "    else:\n",
        "        turbulence_log_name = 'ti'\n",
        "        turbulence_label = 'turbulence'\n",
        "\n",
        "    # print(f\"\\n\\nConfig_hash: {config_hash}\")\n",
        "\n",
        "    turbulence_sma_col = f\"{turbulence_label}_{lookback_window}_sma\"\n",
        "\n",
        "    # Init collections for expanding results\n",
        "    agg_turbulence_thresh = {\n",
        "        'test': {\n",
        "            # quantile: pd.DataFrame()\n",
        "            quantile: []\n",
        "            for quantile in quantile_grid\n",
        "        }\n",
        "    }\n",
        "    agg_asset_values = {\n",
        "        'test': {\n",
        "            # quantile: pd.DataFrame()\n",
        "            quantile: []\n",
        "            for quantile in quantile_grid\n",
        "        }\n",
        "    }\n",
        "    agg_turbulence_series = {\n",
        "        'test': {\n",
        "            # quantile: pd.Series(name=turbulence_label)\n",
        "            quantile: []\n",
        "            for quantile in quantile_grid\n",
        "        }\n",
        "    }\n",
        "\n",
        "    prev_run_api = None\n",
        "\n",
        "    # load full train period for in-sample turbulence\n",
        "    current_train_np_env_config = get_env_config(\n",
        "        data,\n",
        "        data_processor,\n",
        "        use_extra_indicators=True if is_sliding_window else False, # TODO: actually dont need for train since for sliding window history only val/test turbulence is used\n",
        "        start_date = sweep_config['parameters']['train_start_date']['value'],\n",
        "        end_date = current_run_api.config['date_range']['val_start_date'],\n",
        "        if_train=True,\n",
        "    )\n",
        "\n",
        "    # load val & test periods\n",
        "    val_np_env_config = get_env_config(\n",
        "        data,\n",
        "        data_processor,\n",
        "        use_extra_indicators=True if is_sliding_window else False,\n",
        "        start_date=current_run_api.config['date_range']['val_start_date'],\n",
        "        end_date=current_run_api.config['date_range']['test_start_date'],\n",
        "        if_train=False\n",
        "    )\n",
        "\n",
        "    test_np_env_config = get_env_config(\n",
        "        data,\n",
        "        data_processor,\n",
        "        use_extra_indicators=True if is_sliding_window else False,\n",
        "        start_date=current_run_api.config['date_range']['test_start_date'],\n",
        "        end_date=current_run_api.config['date_range']['test_end_date'],\n",
        "        if_train=False,\n",
        "    )\n",
        "\n",
        "    # store figures and names, save later in a single artifact\n",
        "    fig_list = {\n",
        "        'val': [],\n",
        "        'test': []\n",
        "    }\n",
        "\n",
        "    fig_names = {\n",
        "        'val': [],\n",
        "        'test': []\n",
        "    }\n",
        "\n",
        "    agg_metrics_per_quantiles = []\n",
        "    for quantile in quantile_grid:\n",
        "        if is_expanding_insample:\n",
        "            insample_turbulence = current_train_np_env_config['turbulence_array']\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "            # insample_turbulence = first_train_np_env_config['turbulence_array']\n",
        "\n",
        "        insample_turbulence_threshold = np.quantile(\n",
        "            insample_turbulence, quantile\n",
        "        ).round(2)\n",
        "\n",
        "        # evaluate model for each split\n",
        "        for split_label, np_env_config in zip(\n",
        "            ['val', 'test'],\n",
        "            [val_np_env_config, test_np_env_config],\n",
        "        ):\n",
        "\n",
        "            if split_label not in agg_asset_values.keys():\n",
        "                # aggregated metrics are computed only for test\n",
        "                continue\n",
        "\n",
        "            # compute historical turbulence based on current split data inside lookback window\n",
        "            if is_sliding_window:\n",
        "                historical_turbulence_mean = np_env_config[turbulence_sma_col]\n",
        "            else:\n",
        "                historical_turbulence_mean = np_env_config['turbulence_array'][-lookback_window:].mean()\n",
        "\n",
        "            turbulence_thresh = np.where(\n",
        "                historical_turbulence_mean > insample_turbulence_threshold,\n",
        "                insample_turbulence_threshold, # high volatility -> limit by in-sample turbulence\n",
        "                np.quantile(insample_turbulence, 1) # low volatility -> allow all actions\n",
        "            ).round(2)\n",
        "\n",
        "            print(\n",
        "                f\"Thresholds for quantile={quantile}: \",\n",
        "                f\"\\thistorical_turbulence_mean: {historical_turbulence_mean}\",\n",
        "                f\"\\tinsample_turbulence_threshold: {insample_turbulence_threshold}\",\n",
        "                f\"\\tturbulence_threshold: {turbulence_thresh}\",\n",
        "                sep='\\n',\n",
        "                end='\\n'\n",
        "            )\n",
        "\n",
        "            print(\"[ASSET VALUES] Running inference to obtain asset values.\")\n",
        "\n",
        "            # perform state transfer if previous run exists\n",
        "            if split_label == 'test' and prev_run_api is not None:\n",
        "                assert isinstance(prev_run_api, wandb.apis.public.runs.Run)\n",
        "                prev_end_amount, prev_end_stocks = get_env_end_state(\n",
        "                    run=prev_run_api,\n",
        "                    model_name=model_name,\n",
        "                    split_label=split_label,\n",
        "                    quantile_log_name=quantile_log_name,\n",
        "                    quantile_thresh=quantile,\n",
        "                )\n",
        "                print(f\"Transfering previous run env state with amount: {prev_end_amount}\")\n",
        "            else:\n",
        "                print(\"Creating brand new env.\")\n",
        "                prev_end_amount, prev_end_stocks = None, None\n",
        "\n",
        "            # evaluate model under given quantile\n",
        "            result, metrics = evaluate_model(\n",
        "                turbulence_thresh=turbulence_thresh,\n",
        "                model_name=model_name,\n",
        "                algo_or_rl_module=rl_module,\n",
        "                run_config=current_run_api.config,\n",
        "                np_env_config=np_env_config,\n",
        "                split_label=split_label,\n",
        "                log_to_wandb=False,\n",
        "                return_metrics=True,\n",
        "                prev_end_amount=prev_end_amount,\n",
        "                prev_end_stocks=prev_end_stocks,\n",
        "            )\n",
        "\n",
        "            metrics.update({\n",
        "                f\"threshold\": turbulence_thresh,\n",
        "                f\"insample_threshold\": insample_turbulence_threshold,\n",
        "                f\"historical_mean\": historical_turbulence_mean,\n",
        "                f\"lookback_window\": lookback_window,\n",
        "            })\n",
        "\n",
        "            assert turbulence_log_name == 'vix', \"TODO: support other tubulence indices logging for quantiles\"\n",
        "            log_eval_results(\n",
        "                model_name,\n",
        "                metrics=metrics,\n",
        "                split_label=split_label,\n",
        "                turbulence_log_name=None,\n",
        "                turbulence_thresh=None,\n",
        "                run=current_run_api,\n",
        "                metric_prefix=None,\n",
        "                quantile_log_name=quantile_log_name,\n",
        "                quantile_thresh=quantile,\n",
        "            )\n",
        "\n",
        "            # asset values for current run\n",
        "            run_asset_values_per_split = result['account_value']\n",
        "\n",
        "            print('\\ntrain_start_date', current_run_api.config['date_range']['train_start_date'])\n",
        "            print('val_start_date', current_run_api.config['date_range']['val_start_date'])\n",
        "            print('test_start_date', current_run_api.config['date_range']['test_start_date'])\n",
        "            print('test_end_date', current_run_api.config['date_range']['test_end_date'])\n",
        "\n",
        "\n",
        "            # debug dates\n",
        "            print(\"\\nagg_asset_values dates:\")\n",
        "            if len(agg_asset_values[split_label][quantile]) > 0:\n",
        "                display(\n",
        "                    pd.concat(agg_asset_values[split_label][quantile])['date'].agg(['min', 'max'])\n",
        "                )\n",
        "            else:\n",
        "                print(\"No dates (empty df)\")\n",
        "            print(\"\\nrun_asset_values_per_split dates:\")\n",
        "            display(run_asset_values_per_split['date'].agg(['min', 'max']))\n",
        "\n",
        "\n",
        "            ######### EXPAND COLLECTIONS TO STORE RESULTS\n",
        "\n",
        "            agg_asset_values[split_label][quantile].append(\n",
        "                run_asset_values_per_split\n",
        "            )\n",
        "\n",
        "            assert pd.concat(agg_asset_values[split_label][quantile])['date'].is_monotonic_increasing\n",
        "\n",
        "            run_turbulence_series_per_split = result['turbulence_series']\n",
        "\n",
        "            agg_turbulence_series[split_label][quantile].append(\n",
        "                run_turbulence_series_per_split\n",
        "            )\n",
        "\n",
        "            agg_turbulence_thresh[split_label][quantile].append(\n",
        "                turbulence_thresh\n",
        "            )\n",
        "\n",
        "            ############# LOG AGGREGATED METRICS\n",
        "\n",
        "            agg_metrics_per_split = compute_metrics(pd.concat(agg_asset_values[split_label][quantile]))\n",
        "\n",
        "            log_eval_results(\n",
        "                model_name,\n",
        "                agg_metrics_per_split,\n",
        "                split_label=split_label,\n",
        "                turbulence_log_name=None,\n",
        "                turbulence_thresh=None,\n",
        "                run=current_run_api,\n",
        "                metric_prefix='agg',\n",
        "                quantile_log_name=quantile_log_name,\n",
        "                quantile_thresh=quantile,\n",
        "            )\n",
        "\n",
        "            agg_metrics_per_split.update({\n",
        "                f\"quantile\": quantile,\n",
        "            })\n",
        "            agg_metrics_per_quantiles.append(agg_metrics_per_split)\n",
        "\n",
        "            # compute DJIA metrics for split for dates from first run till current run\n",
        "            full_df_dija, agg_djia_metrics = eval_agg_dija(sweep_api, current_run_api, split_label, silent=SILENT)\n",
        "            current_df_djia = full_df_dija[\n",
        "                full_df_dija['date'] >= current_run_api.config['date_range']['test_start_date']\n",
        "            ]\n",
        "\n",
        "            # add DJIA metrics to current agg result df\n",
        "            agg_asset_values[split_label][quantile][-1] = pd.merge(\n",
        "                agg_asset_values[split_label][quantile][-1],\n",
        "                current_df_djia,\n",
        "                on='date'\n",
        "            )\n",
        "\n",
        "            if not LOG_PLOTS or LOG_PLOTS == 'last_only' and is_last_run:\n",
        "                fig = plot_results(\n",
        "                    account_value=agg_asset_values[split_label][quantile],\n",
        "                    turbulence_series=agg_turbulence_series[split_label][quantile],\n",
        "                    turbulence_thresh=agg_turbulence_thresh[split_label][quantile],\n",
        "                    turbulence_quantile=quantile,\n",
        "                    figsize='small',\n",
        "                    split_label='test',\n",
        "                    metrics=agg_metrics_per_split,\n",
        "                    index_metrics=agg_djia_metrics\n",
        "                )\n",
        "\n",
        "                # Create plot name\n",
        "                fig_collection_name = f\"agg_cum_return-{split_label}-{quantile_log_name}\"\n",
        "                fig_name = f\"{fig_collection_name}_{quantile}\"\n",
        "                fig_list[split_label].append(fig)\n",
        "                fig_names[split_label].append(fig_name)\n",
        "\n",
        "    current_run_sdk = wandb.init(\n",
        "        project=PROJECT, id=current_run_id, resume='must',\n",
        "        settings=wandb.Settings(silent=\"true\" if SILENT else \"false\")\n",
        "    )\n",
        "\n",
        "    agg_metrics_per_quantiles = pd.DataFrame(agg_metrics_per_quantiles)\n",
        "    table = wandb.Table(dataframe=agg_metrics_per_quantiles)\n",
        "    wandb.log({f'agg_metrics_per_quantiles-{split_label}-{quantile_log_name}': table})\n",
        "\n",
        "    if not LOG_PLOTS or LOG_PLOTS == 'last_only' and is_last_run:\n",
        "        for split_label in ['val', 'test']:\n",
        "            fig_collection_name = f\"agg_cum_return-{split_label}-{quantile_log_name}\"\n",
        "            batch_log_plots_as_artifact(\n",
        "                fig_list[split_label],\n",
        "                fig_names[split_label],\n",
        "                artifact_name_prefix=fig_collection_name,\n",
        "                run=current_run_sdk,\n",
        "            )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ibpHwu2jU3KN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "15pANCivoIru"
      },
      "outputs": [],
      "source": [
        "#@title Train RLlib model\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from ray.tune.registry import register_env\n",
        "from time import perf_counter\n",
        "from math import ceil\n",
        "import ray\n",
        "\n",
        "def train_rllib_model(\n",
        "    run_config,\n",
        "    algo_name,\n",
        "    algo_cls_config,\n",
        "    split_name,\n",
        "\n",
        "    train_np_env_config=None,\n",
        "    val_np_env_config=None,\n",
        "\n",
        "    train_stoploss_data_df = None,\n",
        "    val_stoploss_data_df = None,\n",
        "\n",
        "    pretrained_ckpt_path=None,\n",
        "    skip_training=False\n",
        "):\n",
        "    assert split_name in ['train', 'val']\n",
        "\n",
        "    num_envs_per_env_runner = run_config['env_runners_params']['num_envs_per_env_runner']\n",
        "    num_env_runners = run_config['env_runners_params']['num_env_runners']\n",
        "\n",
        "    if run_config['env_class'] == 'np':\n",
        "        train_env_config = {\n",
        "            \"np_env_config\": train_np_env_config,\n",
        "            \"initial_amount\": run_config['initial_amount'],\n",
        "            \"cost_pct\": run_config['cost_pct'],\n",
        "            \"mode\": 'train'\n",
        "        }\n",
        "\n",
        "        if val_np_env_config is None:\n",
        "            val_env_config = None\n",
        "        else:\n",
        "            val_env_config = {\n",
        "                \"np_env_config\": val_np_env_config,\n",
        "                \"initial_amount\": run_config['initial_amount'],\n",
        "                \"cost_pct\": run_config['cost_pct'],\n",
        "                \"mode\": 'val'\n",
        "            }\n",
        "    elif run_config['env_class'] == 'stoploss':\n",
        "        env_config_kwargs = dict(\n",
        "            cost_pct = run_config['cost_pct'],\n",
        "            initial_amount = run_config['initial_amount'],\n",
        "            discrete_actions = run_config['discrete_actions'],\n",
        "            cache_indicator_data =  run_config['cache_indicator_data'],\n",
        "            patient = run_config['patient'],\n",
        "            print_verbosity = run_config['print_verbosity'],\n",
        "        )\n",
        "        train_env_config = {\n",
        "            **env_config_kwargs,\n",
        "            \"df\": train_stoploss_data_df,\n",
        "        }\n",
        "        if val_stoploss_data_df is None:\n",
        "            val_env_config = None\n",
        "        else:\n",
        "            val_env_config = {\n",
        "                **env_config_kwargs,\n",
        "                \"df\": val_stoploss_data_df,\n",
        "            }\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    base_config = PPOConfig()\n",
        "\n",
        "    # if pretrained_ckpt_path is not None:\n",
        "    if pretrained_ckpt_path is not None:\n",
        "        def on_algorithm_init(algorithm, **kwargs):\n",
        "            # module_p0 = algorithm.get_module()\n",
        "            # weight_before = convert_to_numpy(next(iter(module_p0.parameters())))\n",
        "\n",
        "            algorithm.restore_from_path(pretrained_ckpt_path)\n",
        "            algorithm.metrics.reset()\n",
        "            print(f\"Using a pretrained algo with {algorithm.iteration} iterations\")\n",
        "\n",
        "            # # Make sure weights were restored (changed).\n",
        "            # weight_after = convert_to_numpy(next(iter(module_p0.parameters())))\n",
        "            # check(weight_before, weight_after, false=True)\n",
        "\n",
        "        config = (\n",
        "            base_config\n",
        "            .callbacks(on_algorithm_init=on_algorithm_init)\n",
        "        )\n",
        "    else:\n",
        "        config = base_config\n",
        "\n",
        "    training_params = run_config['training_params'][algo_name]\n",
        "    config = (\n",
        "        config\n",
        "        .environment(\n",
        "            env=\"stock_trading_env\",\n",
        "            env_config=train_env_config,\n",
        "        )\n",
        "        .env_runners(\n",
        "            batch_mode=\"complete_episodes\",\n",
        "            num_envs_per_env_runner=num_envs_per_env_runner,\n",
        "            num_env_runners=num_env_runners,\n",
        "            num_cpus_per_env_runner= (2/num_env_runners) if num_env_runners > 2 else None,\n",
        "\n",
        "            # gym_env_vectorize_mode=gym.envs.registration.VectorizeMode.ASYNC,\n",
        "        )\n",
        "        .training(\n",
        "            train_batch_size = training_params['train_batch_size'],\n",
        "            num_epochs = training_params['num_epochs'],\n",
        "            minibatch_size = training_params['minibatch_size'],\n",
        "        )\n",
        "        .callbacks(partial(\n",
        "                MetricsLoggerCallback,\n",
        "                model_name=algo_name,\n",
        "                env_class=run_config['env_class'],\n",
        "                log_to_wandb=True\n",
        "            )\n",
        "        )\n",
        "        .resources(\n",
        "            num_gpus=1 if torch.cuda.is_available() else None\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if val_env_config is not None:\n",
        "        config = (\n",
        "            config\n",
        "            .evaluation(\n",
        "                # Set up the validation environment\n",
        "                evaluation_interval=1,  # Specify evaluation frequency (1=after each training step)\n",
        "                evaluation_config={\n",
        "                    \"explore\": False,\n",
        "                    \"env\": \"stock_trading_env\",\n",
        "                    \"env_config\": val_env_config,\n",
        "                },\n",
        "            )\n",
        "        )\n",
        "\n",
        "    algo = config.build_algo()\n",
        "    wandb.run.summary[f'{split_name}.num_pretrain_iters'] = algo.training_iteration\n",
        "\n",
        "    if config.num_env_runners > 0:\n",
        "        ray.shutdown()\n",
        "        ray.init()\n",
        "        register_env(\"stock_trading_env\", create_np_stock_trading_env)\n",
        "\n",
        "    # 3. .. train it ..\n",
        "    @benchmark_exec_time\n",
        "    def _train_rllib(total_timesteps):\n",
        "        print('Started training.')\n",
        "        results = []\n",
        "        total_batches = ceil(total_timesteps / algo.config.train_batch_size)\n",
        "        print(f\"total_batches: {total_batches}\")\n",
        "        print(f\"total_timesteps: {total_timesteps}\")\n",
        "        for _ in range(total_batches):\n",
        "            result = algo.train()\n",
        "            results.append(result)\n",
        "\n",
        "        print_result(result)\n",
        "        print('Training complete.')\n",
        "        return results\n",
        "\n",
        "    results, exec_time_sec = _train_rllib(run_config['training_params'][algo_name]['steps'])\n",
        "    print(f\"TRAINING DURATION: {exec_time_sec}\")\n",
        "\n",
        "    # Log train duration\n",
        "    duration_minutes = round(exec_time_sec / 60, 1)\n",
        "    wandb.run.summary[f\"train.duration_minutes/{algo_name}\"] = duration_minutes\n",
        "    wandb.run.summary[f\"train.duration_minutes/{algo_name}\"] = duration_minutes\n",
        "\n",
        "    # Save model\n",
        "    ckpt_path = (Path(TRAINED_MODEL_DIR) / algo_name).resolve()\n",
        "    algo.save(ckpt_path)\n",
        "    update_model_artifacts(log_results_folder=False)\n",
        "\n",
        "    return algo, ckpt_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RLLib_prediction\n",
        "from ray.rllib.core.columns import Columns\n",
        "\n",
        "def RLLib_prediction(\n",
        "    model_name,\n",
        "    rl_module,\n",
        "    eval_env,\n",
        "    seed=None,\n",
        "):\n",
        "    state, info = eval_env.reset(seed=seed)\n",
        "    done = False\n",
        "\n",
        "    # i = 0\n",
        "    # while not done and i < 10:\n",
        "    #     i += 1\n",
        "\n",
        "    while not done:\n",
        "\n",
        "        # Compute action using the RLlib trained agent\n",
        "        input_dict = {Columns.OBS: torch.Tensor(state).unsqueeze(0)}\n",
        "\n",
        "        # print(\"input_dict:\")\n",
        "        # for k, v in input_dict.items():\n",
        "        #     print(k, v.shape)\n",
        "\n",
        "        rl_module_out = rl_module.forward_inference(input_dict)\n",
        "        logits = rl_module_out[Columns.ACTION_DIST_INPUTS]\n",
        "\n",
        "        # Take mean of multivariate Gaussian distribution\n",
        "        mean, log_std = logits.chunk(2, dim=-1)\n",
        "\n",
        "        # action_distribution = TorchDiagGaussian.from_logits(logits)\n",
        "        # action_distribution = action_distribution.to_deterministic()\n",
        "        # assert np.allclose(mean, action_distribution.loc)\n",
        "        # assert np.allclose(log_std.exp(), action_distribution._dist.scale)\n",
        "        # action = action_distribution.sample()\n",
        "\n",
        "        action = mean.detach().numpy().squeeze()\n",
        "\n",
        "        # Clip the action to ensure it's within the action space bounds\n",
        "        action = np.clip(action, eval_env.action_space.low, eval_env.action_space.high)\n",
        "\n",
        "        # Perform action\n",
        "        state, reward, terminated, truncated, _ = eval_env.step(action)\n",
        "\n",
        "        done = terminated or truncated\n",
        "        # break\n",
        "\n",
        "    df_account_values = eval_env.save_asset_memory()\n",
        "    # display(df_account_values)\n",
        "\n",
        "\n",
        "    # HACK: hardcoded timezone\n",
        "    # TODO: transfer timezone handling to FinRL\n",
        "    # df_account_value['date'] = pd.to_datetime(df_account_value['date'], utc=True).dt.tz_convert(NY)\n",
        "    return df_account_values\n",
        "\n",
        "# env_config = {\n",
        "#     \"np_env_config\": val_np_env_config,\n",
        "\n",
        "#     \"initial_amount\": run_config['initial_amount'],\n",
        "#     \"initial_stocks\": None,\n",
        "#     \"cost_pct\": run_config['cost_pct'],\n",
        "\n",
        "#     \"mode\": 'val',\n",
        "#     'turbulence_threshold': 99\n",
        "# }\n",
        "\n",
        "# eval_env = create_stock_trading_env(env_config)\n",
        "# rl_module = algo.env_runner.module\n",
        "# df_account_value = RLLib_prediction(\n",
        "#     model_name,\n",
        "#     rl_module,\n",
        "#     eval_env,\n",
        "# )\n",
        "\n",
        "# df_account_value.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xsC5dTzyfaH0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get_stoploss_env_metrics\n",
        "\n",
        "def get_stoploss_env_metrics(env, prefix=None):\n",
        "    state = env.state_memory[-1]\n",
        "\n",
        "    # Get the initial state (from reset) where:\n",
        "    # index 0 is cash and indices 1 to 1+N are stock amounts (for N assets)\n",
        "    cash = state[0]\n",
        "    stocks = state[1:1+len(env.assets)]\n",
        "\n",
        "    # Obtain the closing prices for the initial date.\n",
        "    # (Assuming get_date_vector() returns a vector of indicators when passed cols=[\"close\"])\n",
        "    initial_closings = np.array(env.get_date_vector(env.date_index, cols=[\"close\"]))\n",
        "\n",
        "    # Compute asset value: dot product of stock amounts and their closing prices.\n",
        "    asset_value = np.dot(stocks, initial_closings)\n",
        "\n",
        "    # Total asset is cash plus the asset value.\n",
        "    total_asset = cash + asset_value\n",
        "\n",
        "    # Assemble the metrics dictionary.\n",
        "    env_metrics = {\n",
        "        'cash': cash,\n",
        "        'stocks': stocks,\n",
        "        'asset_value': asset_value,\n",
        "        'total_asset': total_asset\n",
        "    }\n",
        "\n",
        "    if prefix is not None:\n",
        "        env_metrics = { f'{prefix}_{name}': value for name, value in env_metrics.items()}\n",
        "\n",
        "    return env_metrics"
      ],
      "metadata": {
        "id": "j8zE5OOsP2AY",
        "cellView": "form"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "cellView": "form",
        "id": "q9I_UeAwfTzq"
      },
      "outputs": [],
      "source": [
        "#@title evaluate_model\n",
        "from ray.rllib.algorithms.algorithm import Algorithm\n",
        "from ray.rllib.utils.numpy import convert_to_numpy, softmax\n",
        "from ray.rllib.models.torch.torch_distributions import TorchDiagGaussian\n",
        "from ray.rllib.core.rl_module.rl_module import RLModule\n",
        "import torch\n",
        "\n",
        "GLOBAL_SEED = 2025\n",
        "\n",
        "# Create the testing environment\n",
        "def evaluate_model(\n",
        "    algo_or_rl_module,\n",
        "    model_name,\n",
        "    split_label,\n",
        "\n",
        "    run,\n",
        "    run_config, # could be different from run.config\n",
        "\n",
        "    np_env_config=None,\n",
        "    stoploss_data_df=None,\n",
        "\n",
        "    turbulence_thresh=None,\n",
        "    log_to_wandb=False,\n",
        "    return_metrics=False,\n",
        "    seed=GLOBAL_SEED,\n",
        "\n",
        "    prev_end_amount=None,\n",
        "    prev_end_stocks=None,\n",
        "\n",
        "    # insample_threshold_quantile = None,\n",
        "    # is_expanding_insample = False\n",
        "):\n",
        "    \"\"\"\n",
        "        Use np_env_config for numpy env.\n",
        "        Use stoploss_data_df for stoploss env.\n",
        "    \"\"\"\n",
        "\n",
        "    assert (prev_end_amount is None) == (prev_end_stocks is None), (\n",
        "        \"Either both prev_end_amount and prev_end_stocks must be None, \"\n",
        "        \"or both must be non-None.\"\n",
        "    )\n",
        "\n",
        "    if turbulence_thresh is None:\n",
        "        turbulence_thresh = run_config.get('turbulence_thresh', 99)\n",
        "\n",
        "    turbulence_name = 'turbulence' if not run_config.get('if_vix', None) else 'vix'\n",
        "    print(f\"\\nEvaluating for `{split_label}` using `{turbulence_name}`: {turbulence_thresh}\")\n",
        "\n",
        "    if prev_end_stocks is not None:\n",
        "        initial_amount = prev_end_amount\n",
        "    else:\n",
        "        initial_amount = run_config['initial_amount']\n",
        "        initial_stocks = None\n",
        "        print(\"Init with NEW env state:\")\n",
        "\n",
        "    print(f\"\\t initial_amount: {initial_amount}\")\n",
        "    print(f\"\\t initial_stocks: {initial_stocks}\")\n",
        "\n",
        "    if np_env_config is not None:\n",
        "        assert stoploss_data_df is None, \"Use either `np_env_config` for numpy env, or `stoploss_data_df` for stop loss env\"\n",
        "        env_config = {\n",
        "            \"np_env_config\": np_env_config,\n",
        "\n",
        "            \"initial_amount\": initial_amount,\n",
        "            \"initial_stocks\": initial_stocks,\n",
        "            \"cost_pct\": run_config['cost_pct'],\n",
        "\n",
        "            \"mode\": split_label,\n",
        "            'turbulence_threshold': turbulence_thresh\n",
        "        }\n",
        "        eval_env = create_np_stock_trading_env(env_config)\n",
        "        _ = eval_env.reset(seed=seed)\n",
        "        env_metrics = {\n",
        "            'end_amount': eval_env.amount,\n",
        "            'end_stocks': eval_env.stocks,\n",
        "            'end_total_asset': eval_env.total_asset\n",
        "        }\n",
        "\n",
        "\n",
        "    elif stoploss_data_df is not None:\n",
        "        assert np_env_config is None, \"Use either `np_env_config` for numpy env, or `stoploss_data_df` for stop loss env\"\n",
        "        env_config = dict(\n",
        "            cost_pct = run_config['cost_pct'],\n",
        "            initial_amount = run_config['initial_amount'],\n",
        "            discrete_actions = run_config['discrete_actions'],\n",
        "            cache_indicator_data =  run_config['cache_indicator_data'],\n",
        "            patient = run_config['patient'],\n",
        "            print_verbosity = run_config['print_verbosity'],\n",
        "            df = stoploss_data_df,\n",
        "        )\n",
        "        print(\"Initializing StopLossEnv\")\n",
        "\n",
        "        eval_env = create_stoploss_stock_trading_env(env_config)\n",
        "        _ = eval_env.reset(seed=seed)\n",
        "        env_metrics = get_stoploss_env_metrics(eval_env, prefix='start')\n",
        "\n",
        "    assert eval_env is not None\n",
        "\n",
        "    # Extract rl_module if using Algorithm\n",
        "    if isinstance(algo_or_rl_module, Algorithm):\n",
        "        rl_module = algo_or_rl_module.env_runner.module\n",
        "    elif isinstance(algo_or_rl_module, RLModule):\n",
        "        rl_module = algo_or_rl_module\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    df_account_value = RLLib_prediction(\n",
        "        model_name,\n",
        "        rl_module,\n",
        "        eval_env,\n",
        "        seed=seed,\n",
        "    )\n",
        "\n",
        "    if np_env_config is not None:\n",
        "        df_account_value = df_account_value.rename(\n",
        "            columns={'account_value': model_name.upper()}\n",
        "        )\n",
        "        end_env_metrics = {\n",
        "            'start_amount': eval_env.amount,\n",
        "            'start_stocks': eval_env.stocks,\n",
        "            'start_total_asset': eval_env.total_asset\n",
        "        }\n",
        "    elif stoploss_data_df is not None:\n",
        "        df_account_value = df_account_value[['date', 'total_assets']].rename(\n",
        "            columns={'total_assets': model_name.upper()}\n",
        "        )\n",
        "        end_env_metrics = get_stoploss_env_metrics(eval_env, prefix='end')\n",
        "\n",
        "    metrics = compute_metrics(df_account_value)\n",
        "\n",
        "    env_metrics.update(end_env_metrics)\n",
        "\n",
        "    # print(\"\\nEnv metrics after evaluation:\")\n",
        "    # for k, v in env_metrics.items():\n",
        "    #     print(f\"{k}: {v}\")\n",
        "\n",
        "    metrics.update(env_metrics)\n",
        "\n",
        "    if np_env_config is not None:\n",
        "        turbulence_series = pd.Series(\n",
        "            np_env_config['turbulence_array'][:len(df_account_value)],\n",
        "            index=df_account_value['date'],\n",
        "            name=turbulence_name\n",
        "        )\n",
        "    elif stoploss_data_df is not None:\n",
        "        turbulence_series =\\\n",
        "            stoploss_data_df.set_index('timestamp') \\\n",
        "            .loc[stoploss_data_df['timestamp'].unique()]['vix']\n",
        "        turbulence_series.index.name = 'date'\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    eval_result = {\n",
        "        'account_value': df_account_value,\n",
        "        'turbulence_series': turbulence_series,\n",
        "        'turbulence_thresh': turbulence_thresh\n",
        "    }\n",
        "\n",
        "    # optionally log to wandb\n",
        "    if log_to_wandb:\n",
        "        # api = wandb.Api()\n",
        "        # run_api = api.run(f\"{PROJECT}/{wandb.run.id}\")\n",
        "        turbulence_log_name = 'ti' if not run_config.get('if_vix', None) else 'vix'\n",
        "        log_eval_results(\n",
        "            model_name,\n",
        "            metrics,\n",
        "            split_label,\n",
        "            turbulence_log_name,\n",
        "            turbulence_thresh,\n",
        "            run=run,\n",
        "        )\n",
        "\n",
        "    # print(\"Shutting down ray... \", end='')\n",
        "    # ray.shutdown()\n",
        "    # print(\"Done.\")\n",
        "\n",
        "    if return_metrics:\n",
        "        return eval_result, metrics\n",
        "    else:\n",
        "        return eval_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot_results (enchanced | list input | list of arrays for thresholds )\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "def plot_results(\n",
        "        account_value,\n",
        "        turbulence_series,\n",
        "        turbulence_thresh,\n",
        "        turbulence_quantile=None,\n",
        "        figsize='small',\n",
        "        split_label=None,\n",
        "        metrics=None,\n",
        "        index_metrics=None,\n",
        "        index_name='DJIA',\n",
        "        metrics_highlight_model_name='PPO',\n",
        "        allowed_metrics=['sharpe_ratio', 'mdd', 'cum_return', 'ann_return'],\n",
        "        ylim_padding=6_000,\n",
        "        ylim_bottom=None,\n",
        "        ylim_top=None\n",
        "    ):\n",
        "    \"\"\"\n",
        "    This function now supports two input modes:\n",
        "      1. Single DataFrame/Series/scalar for the three main inputs\n",
        "      2. Lists of DataFrames/Series/scalars for multiple periods\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1) Check inputs, possibly concatenate if they are lists ---\n",
        "    is_list_input = isinstance(account_value, list)\n",
        "    if is_list_input:\n",
        "        # If one is a list, all must be lists\n",
        "        assert isinstance(turbulence_series, list), \"If account_value is a list, turbulence_series must be a list.\"\n",
        "        assert isinstance(turbulence_thresh, list), \"If account_value is a list, turbulence_thresh must be a list.\"\n",
        "        assert len(account_value) == len(turbulence_series) == len(turbulence_thresh), \\\n",
        "            \"All three lists must have the same length.\"\n",
        "        assert turbulence_series[0].name in ['turbulence', 'vix']\n",
        "        assert metrics_highlight_model_name in account_value[0].columns\n",
        "        assert turbulence_quantile is not None\n",
        "        if index_metrics is not None:\n",
        "            assert index_name in account_value[0].columns\n",
        "\n",
        "        # Concatenate across periods\n",
        "        df_concat = []\n",
        "        ts_concat = []\n",
        "        thresh_concat = []\n",
        "        for df_period, ts_period, thr_period in zip(account_value, turbulence_series, turbulence_thresh):\n",
        "            # Ensure date is index for each period's DataFrame\n",
        "            if 'date' in df_period.columns:\n",
        "                df_period = df_period.set_index('date')\n",
        "            df_period.rename(columns={col: col.upper() for col in df_period.columns}, inplace=True)\n",
        "            df_concat.append(df_period)\n",
        "\n",
        "            # Make sure index matches or is alignable (assuming same index)\n",
        "            ts_concat.append(ts_period)\n",
        "\n",
        "            # Repeat threshold value for length of this period\n",
        "            # and store it as a Series to match the index\n",
        "            if isinstance(thr_period, (int, float)):\n",
        "                # Scalar threshold: repeat for all timestamps\n",
        "                thr_series = pd.Series([thr_period]*len(df_period), index=df_period.index)\n",
        "            elif isinstance(thr_period, (list, np.ndarray)) and len(thr_period) == len(df_period):\n",
        "                # Array threshold: create a Series from the array\n",
        "                thr_series = pd.Series(thr_period, index=df_period.index)\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    \"Each turbulence_thresh entry must be either a scalar or \"\n",
        "                    \"an array matching the period length.\"\n",
        "                )\n",
        "\n",
        "            thresh_concat.append(thr_series)\n",
        "\n",
        "        # # Final single DataFrame, Series, Series for plotting\n",
        "        # account_value = pd.concat(df_concat)\n",
        "        # turbulence_series = pd.concat(ts_concat)\n",
        "        # turbulence_thresh = pd.concat(thresh_concat)\n",
        "\n",
        "        # Final single DataFrame, Series, Series for plotting\n",
        "        account_value = pd.concat(df_concat).sort_index()\n",
        "        turbulence_series = pd.concat(ts_concat).sort_index()\n",
        "        turbulence_thresh = pd.concat(thresh_concat).sort_index()\n",
        "\n",
        "\n",
        "    else:\n",
        "        # Single input variant\n",
        "        assert not isinstance(turbulence_series, list), \"turbulence_series must not be a list if account_value is not a list.\"\n",
        "        assert not isinstance(turbulence_thresh, list), \"turbulence_thresh must not be a list if account_value is not a list.\"\n",
        "        assert turbulence_series.name in ['turbulence', 'vix']\n",
        "        assert metrics_highlight_model_name in account_value.columns\n",
        "        if index_metrics is not None:\n",
        "            assert index_name in account_value.columns\n",
        "\n",
        "        # Ensure date is index\n",
        "        if 'date' in account_value.columns:\n",
        "            account_value.set_index('date', inplace=True)\n",
        "        account_value.rename(columns={col: col.upper() for col in account_value.columns}, inplace=True)\n",
        "\n",
        "    # --- 2) Original asserts (unchanged) ---\n",
        "    assert split_label in ['val', 'test']\n",
        "    assert figsize in ['small', 'medium']\n",
        "\n",
        "    # --- 3) Prepare figure ---\n",
        "    figsizes = {\n",
        "        'medium': (14, 10),\n",
        "        'small': (8.3, 8)\n",
        "    }\n",
        "    fig, (ax1, ax2) = plt.subplots(\n",
        "        2, 1, figsize=figsizes[figsize], sharex=True, gridspec_kw={'height_ratios': [3, 1]}\n",
        "    )\n",
        "\n",
        "    # --- 4) Method styles ---\n",
        "    method_styles = {\n",
        "        'A2C': {'color': '#8c564b', 'linestyle': '--'},\n",
        "        'DDPG': {'color': '#e377c2', 'linestyle': '-'},\n",
        "        'PPO': {'color': 'blue', 'linestyle': '-'},\n",
        "        'TD3': {'color': '#bcbd22', 'linestyle': '--'},\n",
        "        'SAC': {'color': '#17becf', 'linestyle': '-'},\n",
        "        'DJIA': {'color': '#000000', 'linestyle': '-'},\n",
        "    }\n",
        "\n",
        "    # --- 5) Plot account values ---\n",
        "    for model_name in account_value.columns:\n",
        "        style = method_styles.get(model_name, {'color': 'blue', 'linestyle': '-'})  # fallback style\n",
        "        ax1.plot(account_value.index, account_value[model_name], label=model_name, **style)\n",
        "\n",
        "    # --- 6) Title and subtitle logic ---\n",
        "    turbulence_label = \"Turbulence Index\" if turbulence_series.name == 'turbulence' else \"VIX Coefficient\"\n",
        "    split_label_name = ('validation' if split_label == 'val' else split_label).capitalize()\n",
        "\n",
        "    # If threshold is still a single number, round it; if it's a Series, round all values\n",
        "    if isinstance(turbulence_thresh, (int, float)):\n",
        "        # single numeric\n",
        "        rounded_thresh_text = str(round(turbulence_thresh))\n",
        "        title = f\"{split_label_name} split | {turbulence_label} threshold: {rounded_thresh_text}\"\n",
        "    else:\n",
        "        # it's a Series, just mention \"multiple\" or no direct numeric\n",
        "        turbulence_thresh = turbulence_thresh.round()\n",
        "        title = f\"{split_label_name} split | {turbulence_label} insample quantile: {turbulence_quantile}\"\n",
        "\n",
        "    fig.suptitle(title, fontsize=20, fontweight='bold')\n",
        "\n",
        "    full_names = {\n",
        "        'mdd': 'MDD',\n",
        "        'ann_return': 'Annualized Return',\n",
        "        'cum_return': 'Cumulative Return',\n",
        "        'sharpe_ratio': 'Sharpe Ratio'\n",
        "    }\n",
        "    # Build subtitle lines\n",
        "    subtitle_lines = []\n",
        "\n",
        "    if metrics:\n",
        "        metric_text = f\"{metrics_highlight_model_name} | \"\n",
        "        metric_text += \", \".join(\n",
        "            f\"{full_names.get(name, name.replace('_', ' ').capitalize())}: {value:.2f}\"\n",
        "            for name, value in metrics.items()\n",
        "            if name in allowed_metrics\n",
        "        )\n",
        "        subtitle_lines.append(metric_text)\n",
        "\n",
        "    # NEW: optionally handle index_metrics in a similar way\n",
        "    if index_metrics:\n",
        "        index_metric_text = f\"{index_name} | \"\n",
        "        index_metric_text += \", \".join(\n",
        "            f\"{full_names.get(name, name.replace('_', ' ').capitalize())}: {value:.2f}\"\n",
        "            for name, value in index_metrics.items()\n",
        "            if name in allowed_metrics\n",
        "        )\n",
        "        subtitle_lines.append(index_metric_text)\n",
        "\n",
        "    # If we have any lines to show, join them with newline(s) and set as subtitle\n",
        "    if subtitle_lines:\n",
        "        ax1.set_title(\"\\n\".join(subtitle_lines), fontsize=12, color='gray', ha='center')\n",
        "\n",
        "    # --- 7) Y-axis (main) ---\n",
        "    ax1.yaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f\"{x:,.0f}\"))\n",
        "\n",
        "    # Horizontal line at initial asset value\n",
        "    initial_asset_value = account_value.iloc[0].mean()\n",
        "    min_account_value = account_value.min().min()\n",
        "    max_account_value = account_value.max().max()\n",
        "    ax1.axhline(y=initial_asset_value, color='gray', linestyle='-.', linewidth=1.5, label=\"Initial Asset Value\")\n",
        "\n",
        "    ax1.set_ylabel(\"Total Asset Value ($)\", fontsize=16, fontweight='bold')\n",
        "\n",
        "    if ylim_bottom is None:\n",
        "        ylim_bottom = min_account_value - ylim_padding\n",
        "    if ylim_top is None:\n",
        "        ylim_top = max_account_value + ylim_padding\n",
        "    ax1.set_ylim(bottom=ylim_bottom, top=ylim_top)\n",
        "\n",
        "    ax1.legend(loc='lower right')\n",
        "    ax1.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "    # --- 8) Second y-axis ticks ---\n",
        "    ax1_right = ax1.twinx()\n",
        "    ax1_right.set_ylim(ax1.get_ylim())\n",
        "    left_ticks = ax1.get_yticks().tolist()\n",
        "    ymin, ymax = ax1.get_ylim()\n",
        "\n",
        "    start_value = account_value.iloc[0].mean()\n",
        "    end_value = account_value.iloc[-1].mean()\n",
        "\n",
        "    extra_ticks = []\n",
        "    if ymin <= start_value <= ymax:\n",
        "        extra_ticks.append(start_value)\n",
        "    if ymin <= end_value <= ymax:\n",
        "        extra_ticks.append(end_value)\n",
        "\n",
        "    all_ticks = sorted(set(left_ticks + extra_ticks))\n",
        "    labels = []\n",
        "    for tick in all_ticks:\n",
        "        if np.isclose(tick, start_value):\n",
        "            labels.append(f\"{tick:,.0f}\")\n",
        "        elif np.isclose(tick, end_value):\n",
        "            labels.append(f\"{tick:,.0f}\")\n",
        "        else:\n",
        "            labels.append(\"\")\n",
        "    ax1_right.set_yticks(all_ticks)\n",
        "    ax1_right.set_yticklabels(labels)\n",
        "    ax1_right.set_ylabel('')\n",
        "    ax1_right.grid(False)\n",
        "\n",
        "    # --- 9) Turbulence plot ---\n",
        "    ax2.plot(turbulence_series.index, turbulence_series, label=turbulence_label,\n",
        "             color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "    # Plot threshold line or series\n",
        "    if isinstance(turbulence_thresh, (int, float)):\n",
        "        # single horizontal line\n",
        "        ax2.axhline(y=turbulence_thresh, color='red', linestyle=':', label=f'Threshold = {round(turbulence_thresh)}')\n",
        "        max_turbulence = max(turbulence_series.max(), turbulence_thresh)\n",
        "    else:\n",
        "        # threshold is a Series\n",
        "        ax2.plot(turbulence_thresh.index, turbulence_thresh, color='red', linestyle=':',\n",
        "                 label='Threshold')\n",
        "        max_turbulence = max(turbulence_series.max(), turbulence_thresh.max())\n",
        "\n",
        "    ax2.set_ylabel(turbulence_label, fontsize=16, fontweight='bold')\n",
        "    ax2.legend(loc='upper left')\n",
        "    ax2.grid(True, linestyle='--', alpha=0.3)\n",
        "    ax2.set_ylim(0, max_turbulence + 10)\n",
        "    ax2.set_xlabel(\"Date\", fontsize=16, fontweight='bold')\n",
        "\n",
        "    for ax in [ax1, ax2]:\n",
        "        # Major ticks (quarter boundaries)\n",
        "        ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=[1,4,7,10]))\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "\n",
        "        # Minor ticks (monthly)\n",
        "        ax.xaxis.set_minor_locator(mdates.MonthLocator(interval=1))\n",
        "\n",
        "        # Draw major grid lines (more pronounced)\n",
        "        ax.grid(which='major', axis='x', linestyle='-', linewidth=1.2, color='black', alpha=0.5)\n",
        "\n",
        "        # Draw minor grid lines (finer)\n",
        "        ax.grid(which='minor', axis='x', linestyle='--', linewidth=0.5, color='gray', alpha=0.3)\n",
        "\n",
        "    # # ------------------\n",
        "    # # On ax2, enable labeling of minor ticks\n",
        "    # ax2.xaxis.set_minor_formatter(mdates.DateFormatter('%Y-%m'))  # or '%m/%Y' etc.\n",
        "    # ax2.tick_params(axis='x', which='minor', labelsize=8, labelrotation=45)\n",
        "\n",
        "    ax2.tick_params(axis='x', which='major', labelsize=8, labelrotation=45)\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "cellView": "form",
        "id": "40NXpYI2iLYp"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "cellView": "form",
        "id": "cwtKHseSyz6O"
      },
      "outputs": [],
      "source": [
        "#@title batch_log_plots_as_artifact\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import shutil\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def batch_log_plots_as_artifact(\n",
        "        fig_list, fig_names, artifact_name_prefix, artifact_type=\"plot\",\n",
        "        run=None\n",
        "    ):\n",
        "\n",
        "    \"\"\"\n",
        "    Save a list of Matplotlib figures to a folder, log the folder as a W&B artifact,\n",
        "    and delete the folder after logging.\n",
        "\n",
        "    Parameters:\n",
        "        fig_list (list): List of Matplotlib figure objects.\n",
        "        folder_name (str): Name of the folder to store plots.\n",
        "        artifact_name_prefix (str): Prefix for the artifact name.\n",
        "        artifact_type (str): The type of the artifact (default is \"plot\").\n",
        "    \"\"\"\n",
        "    if run is None:\n",
        "        assert wandb.run is not None, \"If run is not provided, it should be active in the background\"\n",
        "\n",
        "    assert isinstance(run, wandb.sdk.wandb_run.Run)\n",
        "\n",
        "    # Ensure the folder exists\n",
        "    os.makedirs(artifact_name_prefix, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # Save all figures in the folder\n",
        "        for i, (fig, fig_name) in enumerate(zip(fig_list, fig_names)):\n",
        "            filename = os.path.join(artifact_name_prefix, f\"{fig_name}.png\")\n",
        "            fig.savefig(filename, bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
        "            plt.close(fig)  # Close the figure to free up memory\n",
        "        fig_list.clear()  # remove references\n",
        "        gc.collect()\n",
        "\n",
        "        # Create and log the W&B artifact\n",
        "        artifact_name = f\"{artifact_name_prefix}-{run.id}\"\n",
        "        artifact = wandb.Artifact(artifact_name, type=artifact_type)\n",
        "        artifact.add_dir(artifact_name_prefix, skip_cache=True)\n",
        "        run.log_artifact(artifact)\n",
        "    finally:\n",
        "        # Ensure the folder is deleted after use\n",
        "        if os.path.exists(artifact_name_prefix):\n",
        "            shutil.rmtree(artifact_name_prefix)\n",
        "\n",
        "        for fig in fig_list:\n",
        "            ax = fig.gca()  # Get the current axis of the figure\n",
        "\n",
        "            for txt in ax.texts:  # Remove all text objects\n",
        "                txt.remove()\n",
        "\n",
        "            for line in ax.lines:\n",
        "                line.remove()  # Remove previous plot lines\n",
        "\n",
        "            fig.clf()   # Clear the figure\n",
        "            plt.close(fig)  # Close the figure to free memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "cellView": "form",
        "id": "dIsB7XQwyz6O"
      },
      "outputs": [],
      "source": [
        "#@title log_plot_as_artifact\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "\n",
        "def log_plot_as_artifact(fig, artifact_name_prefix, artifact_type=\"plot\"):\n",
        "    \"\"\"\n",
        "    Save a Matplotlib figure without clipping and log it as a W&B artifact.\n",
        "\n",
        "    Parameters:\n",
        "        fig (matplotlib.figure.Figure): The Matplotlib figure to save and log.\n",
        "        artifact_name (str): The name of the W&B artifact.\n",
        "        artifact_type (str): The type of the artifact (default is \"plot\").\n",
        "        filename (str): The filename to save the plot as (default is \"plot.png\").\n",
        "    \"\"\"\n",
        "    assert wandb.run.id\n",
        "\n",
        "    # Get full artifact name\n",
        "    artifact_name = f'{artifact_name_prefix}-{wandb.run.id}'\n",
        "    filename = artifact_name + '.png'\n",
        "\n",
        "    try:\n",
        "        # Save the figure with tight layout and proper padding\n",
        "        fig.savefig(filename, bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
        "        plt.close(fig)  # Close the figure to free up memory\n",
        "\n",
        "        # Create and log the W&B artifact\n",
        "        artifact = wandb.Artifact(artifact_name, type=artifact_type)\n",
        "        artifact.add_file(filename, skip_cache=True, overwrite=True)\n",
        "        wandb.log_artifact(artifact)\n",
        "    finally:\n",
        "        # Ensure the file is deleted after use\n",
        "        if os.path.exists(filename):\n",
        "            os.remove(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title log_eval_results\n",
        "\n",
        "def log_eval_results(\n",
        "        model_name,\n",
        "        metrics,\n",
        "        split_label,\n",
        "        turbulence_log_name=None,\n",
        "        turbulence_thresh=None,\n",
        "        run=None,\n",
        "        turbulence_thresh_postfix=None,\n",
        "        metric_prefix=None,\n",
        "        quantile_log_name=None,\n",
        "        quantile_thresh = None\n",
        "    ):\n",
        "\n",
        "    # if run is None:\n",
        "    #     run = wandb.run\n",
        "    #     assert run is not None, \"If no run is provided, wandb should contain an active run\"\n",
        "\n",
        "    for metric_name, metric_value in metrics.items():\n",
        "        formatted_name = get_formatted_metric_name(\n",
        "            model_name,\n",
        "            metric_name,\n",
        "            split_label,\n",
        "            turbulence_log_name,\n",
        "            turbulence_thresh,\n",
        "            metric_prefix=metric_prefix,\n",
        "            quantile_log_name=quantile_log_name,\n",
        "            quantile_thresh = quantile_thresh\n",
        "        )\n",
        "\n",
        "        run.summary[formatted_name] = np.round(metric_value, decimals=2).tolist()  # Use formatted_name instead\n",
        "\n",
        "\n",
        "    if isinstance(run, wandb.apis.public.runs.Run):\n",
        "        run.summary.update() # for API only\n",
        "\n",
        "\n",
        "# log_eval_results(\n",
        "#     model_name,\n",
        "#     metrics={'sharpe_ratio': 1.5},\n",
        "#     split_label='val',\n",
        "#     # turbulence_log_name='vix',\n",
        "#     # turbulence_thresh=99,\n",
        "#     run=None,\n",
        "#     metric_prefix='agg',\n",
        "#     quantile_log_name='q',\n",
        "#     quantile_thresh = 0.25\n",
        "# )"
      ],
      "metadata": {
        "id": "b0YOZvHqkCVp",
        "cellView": "form"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "H-l9U3K9TnlB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title get_formatted_metric_name\n",
        "\n",
        "def get_formatted_metric_name(\n",
        "    model_name,\n",
        "    metric_name,\n",
        "    split_label,\n",
        "    turbulence_log_name=None,\n",
        "    turbulence_thresh=None,\n",
        "    turbulence_thresh_postfix=None,\n",
        "    metric_prefix=None,\n",
        "    quantile_log_name=None,\n",
        "    quantile_thresh = None\n",
        "):\n",
        "    assert turbulence_thresh_postfix in ['best', 'chosen', None]\n",
        "    # assert quantile_log_name in ['q', 'qe', None]\n",
        "\n",
        "    if turbulence_log_name is not None:\n",
        "        assert turbulence_thresh is not None\n",
        "\n",
        "    if quantile_log_name is not None:\n",
        "        assert turbulence_thresh is None and turbulence_log_name is None\n",
        "        assert quantile_thresh is not None and 0 <= quantile_thresh <= 1\n",
        "\n",
        "    formatted_name = (\n",
        "        f\"{split_label}\"\n",
        "\n",
        "        # Quantile name + thresh\n",
        "        f\"{'.' + quantile_log_name if quantile_log_name else ''}\"\n",
        "        f\"{'_' + str(round(quantile_thresh * 100)) if quantile_thresh else ''}\"\n",
        "\n",
        "        # Turbulence name + thresh\n",
        "        f\"{'.' + turbulence_log_name if turbulence_log_name else ''}\"\n",
        "        f\"{'_' + str(turbulence_thresh) if turbulence_thresh else ''}\"\n",
        "        f\"{'_' + turbulence_thresh_postfix if turbulence_thresh_postfix else ''}\"\n",
        "\n",
        "        f\".{metric_prefix + '_' if metric_prefix else ''}{metric_name}/\"\n",
        "        f\"{model_name}\"\n",
        "    )\n",
        "    return formatted_name\n",
        "\n",
        "\n",
        "# formatted_name = get_formatted_metric_name(\n",
        "#     model_name,\n",
        "#     metric_name='sharpe_ratio',\n",
        "#     split_label='val',\n",
        "#     # turbulence_log_name='vix',\n",
        "#     # turbulence_thresh=99,\n",
        "#     metric_prefix='agg',\n",
        "#     quantile_log_name='q',\n",
        "#     quantile_thresh = 0.25\n",
        "# )\n",
        "\n",
        "# formatted_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "cellView": "form",
        "id": "lyYbDansvhI8"
      },
      "outputs": [],
      "source": [
        "#@title evaluate_threshold_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wandb\n",
        "\n",
        "def evaluate_threshold_grid(\n",
        "    algo_or_rl_module,\n",
        "    model_name,\n",
        "    run_config,\n",
        "    np_env_config,\n",
        "    num_grid_points=10,\n",
        "    split_label='val',\n",
        "    chosen_th=None,\n",
        "    plot_padding=500\n",
        "):\n",
        "\n",
        "    if run_config.get('if_vix', True):\n",
        "        turbulence_log_name = 'vix'\n",
        "    else:\n",
        "        turbulence_log_name = 'ti'\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # Calculate threshold grid\n",
        "    turb_ary = np_env_config['turbulence_array']\n",
        "    threshold_grid = np.linspace(turb_ary.min(), turb_ary.max(), num_grid_points)\n",
        "    threshold_grid = np.ceil(threshold_grid).astype(int).tolist()\n",
        "    threshold_grid.append(max(threshold_grid) + 1)\n",
        "    if chosen_th is not None:\n",
        "        threshold_grid.append(chosen_th)\n",
        "\n",
        "    th_metrics = []  # List to store metrics for all thresholds\n",
        "    th_results = {}  # Dictionary to store results per threshold\n",
        "\n",
        "    for th in threshold_grid:\n",
        "        result, metrics = evaluate_model(\n",
        "            turbulence_thresh=th,\n",
        "            model_name=model_name,\n",
        "            algo_or_rl_module=algo_or_rl_module,\n",
        "            run_config=run_config,\n",
        "            np_env_config=np_env_config,\n",
        "            split_label=split_label,\n",
        "            log_to_wandb=True,\n",
        "            return_metrics=True\n",
        "        )\n",
        "\n",
        "        metrics = {turbulence_log_name: th, **metrics}\n",
        "        th_metrics.append(metrics)\n",
        "        th_results[th] = result\n",
        "\n",
        "    # Convert metrics to a DataFrame and log to WandB\n",
        "    df = pd.DataFrame(th_metrics).astype({turbulence_log_name: int})\n",
        "    metric_cols = df.drop(columns=[turbulence_log_name]).columns # take only true metric columns\n",
        "\n",
        "    # Identify the protected row where turbulence_log_name == chosen_th\n",
        "    protected_row = df[df[turbulence_log_name] == chosen_th].tail(1)  # Keep only the last occurrence\n",
        "\n",
        "    # Drop duplicate rows (except the protected one)\n",
        "    df = df.drop_duplicates(metric_cols, keep=\"last\")\n",
        "\n",
        "    # Drop rows where all metric columns are 0, excluding the protected row\n",
        "    df = df[~((df[metric_cols] == 0).all(axis=1) & ~df.index.isin(protected_row.index))]\n",
        "\n",
        "\n",
        "    wandb_table = wandb.Table(dataframe=df)\n",
        "    wandb.log({f\"threshold_grid_metrics-{split_label}\": wandb_table})\n",
        "\n",
        "    # Log metrics for best threshold\n",
        "    best_idx = df['sharpe_ratio'].idxmax()  # Use idxmax() instead of argmax()\n",
        "    best_metrics = df.loc[best_idx].to_dict()\n",
        "    best_metrics[turbulence_log_name] = int(best_metrics[turbulence_log_name])\n",
        "    log_eval_results(model_name, best_metrics, split_label, turbulence_log_name, 'best')\n",
        "\n",
        "    # Log metrics for chosen threshold (if any)\n",
        "    if chosen_th is not None:\n",
        "        chosen_metrics = df[df[turbulence_log_name] == chosen_th].iloc[0].to_dict()\n",
        "        log_eval_results(model_name, chosen_metrics, split_label, turbulence_log_name, 'chosen')\n",
        "\n",
        "    # Compute min_account_value and max_account_value\n",
        "    min_account_value = float('+inf')\n",
        "    max_account_value = float('-inf')\n",
        "    for th_value, result in th_results.items():\n",
        "        min_account_value = min(min_account_value, result['account_value'][model_name].min())\n",
        "        max_account_value = max(max_account_value, result['account_value'][model_name].max())\n",
        "\n",
        "    min_account_value -= plot_padding\n",
        "    max_account_value += plot_padding\n",
        "\n",
        "    # Plot returns\n",
        "    figs = []\n",
        "    fig_names = []\n",
        "    fig_collection_name = f\"cum_return-{split_label}-{turbulence_log_name}\"\n",
        "    best_th_value = best_metrics[turbulence_log_name]\n",
        "\n",
        "    for th_value in df[turbulence_log_name].values:\n",
        "        result = th_results[th_value]\n",
        "        metrics = df.drop(columns=[turbulence_log_name])[\n",
        "            df[turbulence_log_name] == th_value].iloc[0].to_dict()\n",
        "\n",
        "        fig = plot_results(\n",
        "            **result,\n",
        "            figsize='small',\n",
        "            split_label=split_label,\n",
        "            metrics=metrics,\n",
        "            ylim_bottom=min_account_value,\n",
        "            ylim_top=max_account_value\n",
        "        )\n",
        "        fig_name = f\"{fig_collection_name}_{th_value}\"\n",
        "        if th_value == best_th_value:\n",
        "            fig_name += \"_best\"\n",
        "        if chosen_th is not None and th_value == chosen_th:\n",
        "            fig_name += \"_chosen\"\n",
        "\n",
        "        figs.append(fig)\n",
        "        fig_names.append(fig_name)\n",
        "\n",
        "    batch_log_plots_as_artifact(\n",
        "        figs,\n",
        "        fig_names,\n",
        "        artifact_name_prefix=fig_collection_name\n",
        "    )\n",
        "\n",
        "    best_th = best_metrics[turbulence_log_name]\n",
        "    return best_th"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXntnmmhuSsR"
      },
      "source": [
        "# Sweep Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "cellView": "form",
        "id": "8CXECEemca6u"
      },
      "outputs": [],
      "source": [
        "#@title load_model\n",
        "\n",
        "import ray\n",
        "from ray.rllib.algorithms.ppo import PPO\n",
        "\n",
        "AVAILABLE_MODELS_CLASSES = {\n",
        "    'ppo': PPO\n",
        "}\n",
        "\n",
        "def load_model(model_name, trained_model_dir = TRAINED_MODEL_DIR):\n",
        "    model_class = AVAILABLE_MODELS_CLASSES[model_name]\n",
        "    checkpoint_path = os.path.abspath(f\"{trained_model_dir}/{model_name}\")\n",
        "    algo = model_class.from_checkpoint(checkpoint_path)\n",
        "    return algo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "cellView": "form",
        "id": "uSosu3u-YIIA"
      },
      "outputs": [],
      "source": [
        "#@title Sweep Runner\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "import random\n",
        "import string\n",
        "import json\n",
        "\n",
        "\n",
        "def dict_to_canonical_string(cfg_dict):\n",
        "    return json.dumps(cfg_dict, sort_keys=True)\n",
        "\n",
        "def set_run_name(prefix, n=5):\n",
        "    run_name = f\"{prefix} | {wandb.run.id}\"\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "\n",
        "class SweepRunner:\n",
        "    def __init__(self, sweep_id):\n",
        "        self.sweep_id = sweep_id\n",
        "        self.pretrained_val_models = {}\n",
        "\n",
        "    def main(self, run_config=None):\n",
        "        run_timer_start = perf_counter()\n",
        "\n",
        "        current_time = datetime.now()\n",
        "        print(\"START TIME:\", current_time)\n",
        "\n",
        "        with wandb.init(config=run_config):\n",
        "            run_config = wandb.config\n",
        "            # print('Debug copy run_config...', end=' ')\n",
        "            # _ = deepcopy(run_config)\n",
        "            # print(\"Done.\")\n",
        "\n",
        "            if run_config['dataset_type'] == 'yearly_train_test':\n",
        "                raise NotImplementedError\n",
        "            elif run_config['dataset_type'] == 'quarterly_train_val_test':\n",
        "                (\n",
        "                    train_np_env_config,\n",
        "                    val_np_env_config,\n",
        "                    test_np_env_config\n",
        "                ) = build_quarterly_train_val_test(run_config)\n",
        "                set_run_name(run_config['dataset_name'])\n",
        "\n",
        "                # Extract pretrained model from previous run\n",
        "                # for a given unique hyperparameter combination (e.g. (seed, steps) pair).\n",
        "                # Ignore `date_range` parameter since pretrained models should persist\n",
        "                # across the whole date range\n",
        "                config_seed = run_config['seed']\n",
        "                config_training_params = run_config['training_params']\n",
        "                # config_hash = hash(str(config_seed) + str(config_training_params))\n",
        "                config_hash = hash(dict_to_canonical_string({\n",
        "                    'seed': config_seed,\n",
        "                    'training_params': config_training_params\n",
        "                }))\n",
        "\n",
        "                # run_config_copy = run_config._as_dict().copy()\n",
        "                # run_config_copy.pop('date_range')\n",
        "                # config_hash = hash(str(run_config_copy))\n",
        "\n",
        "\n",
        "                # extract pretrained model from previous run for a given seed\n",
        "                pretrained_val_models = self.pretrained_val_models.get(config_hash, {})\n",
        "                wandb.run.summary['config_hash'] = config_hash\n",
        "\n",
        "                if pretrained_val_models:\n",
        "                    run_config.update({'finetune': True})\n",
        "                else:\n",
        "                    run_config.update({'finetune': False})\n",
        "\n",
        "                pretrained_val_models = train_eval_rllib_models(\n",
        "                    run_config,\n",
        "                    train_np_env_config,\n",
        "                    val_np_env_config,\n",
        "                    test_np_env_config,\n",
        "                    pretrained_val_models=pretrained_val_models\n",
        "                )\n",
        "\n",
        "                self.pretrained_val_models[config_hash] = pretrained_val_models\n",
        "\n",
        "            ray.shutdown()\n",
        "\n",
        "            run_timer_end = perf_counter()\n",
        "            run_duration_minutes = round( (run_timer_end - run_timer_start) / 60, 1)\n",
        "            wandb.run.summary[f\"run.duration_minutes\"] = run_duration_minutes\n",
        "            print(f\"RUN DURATION: {run_duration_minutes}\")\n",
        "\n",
        "        current_time = datetime.now()\n",
        "        print(\"END TIME:\", current_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "eszjIpg-TfkR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Sweep Runner (load model weights + continue = async agent)\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "from hashlib import sha256\n",
        "import random\n",
        "import string\n",
        "\n",
        "def set_run_name(prefix, n=5):\n",
        "    run_name = f\"{prefix} | {wandb.run.id}\"\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "\n",
        "TECH_INDICATOR_MAX_SLIDING_WINDOW = 60\n",
        "\n",
        "class SweepRunner:\n",
        "    def __init__(self, sweep_id):\n",
        "        self.sweep_id = sweep_id\n",
        "        self.pretrained_ckpt_paths = {}\n",
        "\n",
        "        sweep_api = WANDB_API.sweep(f\"{ENTITY}/{PROJECT}/{sweep_id}\")\n",
        "        self.sweep_api = sweep_api\n",
        "\n",
        "        # if_vix = sweep_api.config['parameters']['if_vix']['value'] # assume all runs with same config hash use same volatility index\n",
        "        # if if_vix:\n",
        "        #     turbulence_label = 'vix'\n",
        "        # else:\n",
        "        #     turbulence_label = 'turbulence'\n",
        "        # lookback_window = sweep_api.config['parameters']['lookback_window']['value']\n",
        "        # turbulence_sma_col = f\"{turbulence_label}_{lookback_window}_sma\"\n",
        "\n",
        "        self.data, self.data_processor = load_cached_data(\n",
        "            start_date = sweep_api.config['parameters']['train_start_date']['value'],\n",
        "            end_date = sweep_api.config['parameters']['max_test_end_date']['value'],\n",
        "            tech_indicator_padding = TECH_INDICATOR_MAX_SLIDING_WINDOW,\n",
        "            if_vix = sweep_api.config['parameters']['if_vix']['value'], # should be fixed for a particular hash during training\n",
        "            technical_indicator_list = INDICATORS,\n",
        "            # extra_indicator_list = [turbulence_sma_col]\n",
        "        )\n",
        "\n",
        "    def main(self, run_config=None):\n",
        "        run_timer_start = perf_counter()\n",
        "\n",
        "        current_time = datetime.now()\n",
        "        print(\"START TIME:\", current_time)\n",
        "\n",
        "        with wandb.init(config=run_config) as run:\n",
        "            run_config = wandb.config\n",
        "            # print('Debug copy run_config...', end=' ')\n",
        "            # _ = deepcopy(run_config)\n",
        "            # print(\"Done.\")\n",
        "\n",
        "            if run_config['dataset_type'] == 'yearly_train_test':\n",
        "                raise NotImplementedError\n",
        "            elif run_config['dataset_type'] == 'quarterly_train_val_test':\n",
        "                date_range = {\n",
        "                    key: pd.Timestamp(date)\n",
        "                    for key, date in run_config['date_range'].items()\n",
        "                }\n",
        "\n",
        "                dataset_name = get_quarterly_dataset_name(\n",
        "                    run_config['stock_index_name'],\n",
        "                    date_range['train_start_date'],\n",
        "                    date_range['val_start_date'],\n",
        "                    date_range['test_start_date'],\n",
        "                )\n",
        "                run_config.update({\"dataset_name\": dataset_name})\n",
        "\n",
        "                # get data splits based on env class\n",
        "                if run_config['env_class'] == 'np':\n",
        "                    env_config_kwargs = build_quarterly_train_val_test(\n",
        "                        self.data,\n",
        "                        self.data_processor,\n",
        "                        date_range,\n",
        "                        run_config,\n",
        "                    )\n",
        "                else:\n",
        "                    data_splits = split_data(self.data, date_range, date_col_name='timestamp')\n",
        "                    env_config_kwargs = dict(\n",
        "                        train_stoploss_data_df = data_splits['train'],\n",
        "                        val_stoploss_data_df = data_splits['val'],\n",
        "                        test_stoploss_data_df = data_splits['test'],\n",
        "                    )\n",
        "\n",
        "                set_run_name(run_config['dataset_name'])\n",
        "\n",
        "                # Extract pretrained model from previous run\n",
        "                # for a given unique hyperparameter combination (e.g. (seed, steps) pair).\n",
        "                # Ignore `date_range` parameter since pretrained models should persist\n",
        "                # across the whole date range\n",
        "\n",
        "                config_hash = get_config_hash(run_config)\n",
        "\n",
        "                # extract pretrained model from previous run for a given seed\n",
        "                pretrained_ckpt_paths = self.pretrained_ckpt_paths.get(config_hash, {})\n",
        "                wandb.run.summary['config_hash'] = config_hash\n",
        "\n",
        "                if not pretrained_ckpt_paths:\n",
        "                    print(\"Looking for models from previous run for this date range...\")\n",
        "                    prev_run = find_prev_run(self.sweep_id, wandb.run.id)\n",
        "                    if prev_run is not None:\n",
        "                        download_artifacts(prev_run.id, artifact_types=['trained_models'])\n",
        "\n",
        "                        create_env_fn = CREATE_ENV_FN[run_config['env_class']]\n",
        "                        register_env(\"stock_trading_env\", create_env_fn)\n",
        "\n",
        "                        pretrained_ckpt_paths = {\n",
        "                            model_name: load_model(model_name)\n",
        "                            for model_name in run_config['models_used']\n",
        "                        }\n",
        "                        print(\"Models downloaded.\")\n",
        "                    else:\n",
        "                        print(\"No models found.\")\n",
        "\n",
        "                if pretrained_ckpt_paths:\n",
        "                    run_config.update({'finetune': True})\n",
        "                else:\n",
        "                    run_config.update({'finetune': False})\n",
        "\n",
        "                pretrained_ckpt_paths = train_eval_rllib_models(\n",
        "                    run,\n",
        "\n",
        "                    self.data,\n",
        "                    self.data_processor,\n",
        "                    run.id,\n",
        "                    self.sweep_api,\n",
        "                    pretrained_ckpt_paths=pretrained_ckpt_paths,\n",
        "\n",
        "                    **env_config_kwargs,\n",
        "                )\n",
        "\n",
        "                self.pretrained_ckpt_paths[config_hash] = pretrained_ckpt_paths\n",
        "\n",
        "            ray.shutdown()\n",
        "\n",
        "            run_timer_end = perf_counter()\n",
        "            run_duration_minutes = round( (run_timer_end - run_timer_start) / 60, 1)\n",
        "            wandb.run.summary[f\"run.duration_minutes\"] = run_duration_minutes\n",
        "            print(f\"RUN DURATION: {run_duration_minutes}\")\n",
        "\n",
        "        current_time = datetime.now()\n",
        "        print(\"END TIME:\", current_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4_Tz9YgisuK"
      },
      "source": [
        "# Run sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "_jqFSQXXM4Z0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "f35965da-efc4-4d9d-835b-764d6fe6852c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: od06puvz\n",
            "Sweep URL: https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/od06puvz\n",
            "Using cached data: cache/2014-10-07_2016-10-01_1d_c93df9314227db48fcf165579b5d9a62f68742c52cfedc23d2756e007b0fdd77.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ru9afj14 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcache_indicator_data: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcost_pct: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_type: quarterly_train_val_test\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdate_range: {'test_end_date': '2016-04-01 00:00:00', 'test_start_date': '2016-01-01 00:00:00', 'train_start_date': '2015-01-01 00:00:00', 'val_start_date': '2015-10-01 00:00:00'}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdiscrete_actions: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv_class: stoploss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv_runners_params: {'num_env_runners': 0, 'num_envs_per_env_runner': 1}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_turbulence_thresh: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_a2c: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_ddpg: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_ppo: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_sac: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_td3: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_vix: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_amount: 50000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_test_end_date: 2016-10-01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_test_start_date: 2016-01-01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels_used: ['ppo']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatient: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tprint_verbosity: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 149679692\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tstock_index_name: DOW-30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_start_date: 2015-01-01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_params: {'ppo': {'gamma': 0.99, 'lr': 5e-05, 'minibatch_size': 128, 'num_epochs': 10, 'steps': 1, 'train_batch_size': 128}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tturbulence_threshold: 99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START TIME: 2025-02-28 19:09:50.566619\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250228_190951-ru9afj14</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/overfit1010/finrl-dt-replicate/runs/ru9afj14' target=\"_blank\">balmy-sweep-1</a></strong> to <a href='https://wandb.ai/overfit1010/finrl-dt-replicate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/od06puvz' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/od06puvz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/od06puvz' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/od06puvz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/runs/ru9afj14' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/runs/ru9afj14</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for models from previous run for this date range...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-28 19:09:52,971\tWARNING worker.py:1504 -- SIGTERM handler is not set because current thread is not the main thread.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No models found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-28 19:09:56,220\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Stop Loss env from 2015-01-02 00:00:00 to 2015-09-30 00:00:00\n",
            "caching data\n",
            "data cached!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Stop Loss env from 2015-10-01 00:00:00 to 2015-12-31 00:00:00\n",
            "caching data\n",
            "data cached!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-28 19:10:12,950\tINFO trainable.py:160 -- Trainable.setup took 19.982 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:130: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:418: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
            "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started training.\n",
            "total_batches: 1\n",
            "total_timesteps: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:130: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:418: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
            "  gym.logger.warn(\"Casting input x to numpy array.\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained_models)... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "train/ann_return: -21.75\n",
            "train/ann_return_EMA_0.2: -19.84\n",
            "train/ann_return_MA_20: -15.14\n",
            "train/mdd: -6.28\n",
            "train/mdd_EMA_0.2: -6.08\n",
            "train/mdd_MA_20: -5.59\n",
            "train/sharpe_ratio: -1.46\n",
            "train/sharpe_ratio_EMA_0.2: -1.34\n",
            "train/sharpe_ratio_MA_20: -1.03\n",
            "****************************************\n",
            "val/ann_return: -3.01\n",
            "val/ann_return_EMA_0.2: 3.04\n",
            "val/ann_return_MA_20: 3.89\n",
            "val/mdd: -1.52\n",
            "val/mdd_EMA_0.2: -1.79\n",
            "val/mdd_MA_20: -1.78\n",
            "val/sharpe_ratio: -1.28\n",
            "val/sharpe_ratio_EMA_0.2: 1.07\n",
            "val/sharpe_ratio_MA_20: 1.32\n",
            "----------------------------------------\n",
            "\n",
            "Training complete.\n",
            "TRAINING DURATION: 30.267517697000585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done. 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifact 'trained_models-ru9afj14' has been updated and uploaded.\n",
            "\n",
            "Evaluating for `val` using `vix`: 99\n",
            "Init with NEW env state:\n",
            "\t initial_amount: 50000\n",
            "\t initial_stocks: None\n",
            "Initializing StopLossEnv\n",
            "Creating Stop Loss env from 2015-10-01 00:00:00 to 2015-12-31 00:00:00\n",
            "caching data\n",
            "data cached!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Stop Loss env from 2015-10-01 00:00:00 to 2015-12-31 00:00:00\n",
            "caching data\n",
            "data cached!\n",
            "Using a pretrained algo with 1 iterations\n",
            "Started training.\n",
            "total_batches: 1\n",
            "total_timesteps: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:130: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:418: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
            "  gym.logger.warn(\"Casting input x to numpy array.\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained_models)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "train/ann_return: 7.53\n",
            "train/ann_return_EMA_0.2: 8.24\n",
            "train/ann_return_MA_20: 9.48\n",
            "train/mdd: -2.34\n",
            "train/mdd_EMA_0.2: -2.32\n",
            "train/mdd_MA_20: -2.28\n",
            "train/sharpe_ratio: 1.19\n",
            "train/sharpe_ratio_EMA_0.2: 1.41\n",
            "train/sharpe_ratio_MA_20: 1.81\n",
            "Training complete.\n",
            "TRAINING DURATION: 6.604626036001719\n",
            "Artifact 'trained_models-ru9afj14' has been updated and uploaded.\n",
            "\n",
            "Evaluating for `test` using `vix`: 99\n",
            "Init with NEW env state:\n",
            "\t initial_amount: 50000\n",
            "\t initial_stocks: None\n",
            "Initializing StopLossEnv\n",
            "Creating Stop Loss env from 2016-01-04 00:00:00 to 2016-03-31 00:00:00\n",
            "caching data\n",
            "data cached!\n",
            "RUN DURATION: 1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train.ann_return/ppo</td><td></td></tr><tr><td>train.cum_return/ppo</td><td></td></tr><tr><td>train.mdd/ppo</td><td></td></tr><tr><td>train.sharpe_ratio/ppo</td><td></td></tr><tr><td>val.ann_return/ppo</td><td></td></tr><tr><td>val.cum_return/ppo</td><td></td></tr><tr><td>val.mdd/ppo</td><td></td></tr><tr><td>val.sharpe_ratio/ppo</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>config_hash</td><td>cab99dd9dde5ca0d6ee6...</td></tr><tr><td>run.duration_minutes</td><td>1.2</td></tr><tr><td>test.vix_99.ann_return/ppo</td><td>67.51</td></tr><tr><td>test.vix_99.cum_return/ppo</td><td>6.27</td></tr><tr><td>test.vix_99.end_asset_value/ppo</td><td>52510.37</td></tr><tr><td>test.vix_99.end_cash/ppo</td><td>562.53</td></tr><tr><td>test.vix_99.end_total_asset/ppo</td><td>53072.89</td></tr><tr><td>test.vix_99.mdd/ppo</td><td>-0.99</td></tr><tr><td>test.vix_99.sharpe_ratio/ppo</td><td>5.17</td></tr><tr><td>test.vix_99.start_asset_value/ppo</td><td>0</td></tr><tr><td>test.vix_99.start_cash/ppo</td><td>50000</td></tr><tr><td>test.vix_99.start_total_asset/ppo</td><td>50000</td></tr><tr><td>train.ann_return/ppo</td><td>11.23517</td></tr><tr><td>train.cum_return/ppo</td><td>0.38397</td></tr><tr><td>train.duration_minutes/ppo</td><td>0.1</td></tr><tr><td>train.mdd/ppo</td><td>-2.61017</td></tr><tr><td>train.num_pretrain_iters</td><td>0</td></tr><tr><td>train.sharpe_ratio/ppo</td><td>1.63929</td></tr><tr><td>val.ann_return/ppo</td><td>3.22679</td></tr><tr><td>val.cum_return/ppo</td><td>0.08038</td></tr><tr><td>val.mdd/ppo</td><td>-1.85358</td></tr><tr><td>val.num_pretrain_iters</td><td>1</td></tr><tr><td>val.sharpe_ratio/ppo</td><td>1.38745</td></tr><tr><td>val.vix_99.ann_return/ppo</td><td>8.91</td></tr><tr><td>val.vix_99.cum_return/ppo</td><td>1.37</td></tr><tr><td>val.vix_99.end_asset_value/ppo</td><td>49367.43</td></tr><tr><td>val.vix_99.end_cash/ppo</td><td>843.11</td></tr><tr><td>val.vix_99.end_total_asset/ppo</td><td>50210.54</td></tr><tr><td>val.vix_99.mdd/ppo</td><td>-3.7</td></tr><tr><td>val.vix_99.sharpe_ratio/ppo</td><td>0.53</td></tr><tr><td>val.vix_99.start_asset_value/ppo</td><td>0</td></tr><tr><td>val.vix_99.start_cash/ppo</td><td>50000</td></tr><tr><td>val.vix_99.start_total_asset/ppo</td><td>50000</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">DOW-30 | 2015-01 | 2015 Q4 | 2016 Q1 | ru9afj14</strong> at: <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/runs/ru9afj14' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/runs/ru9afj14</a><br> View project at: <a href='https://wandb.ai/overfit1010/finrl-dt-replicate' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate</a><br>Synced 5 W&B file(s), 0 media file(s), 47 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250228_190951-ru9afj14/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "END TIME: 2025-02-28 19:11:04.784102\n"
          ]
        }
      ],
      "source": [
        "#@title RUN SWEEP\n",
        "\n",
        "def run_sweep(n_runs, sweep_config=None, sweep_id=None):\n",
        "    wandb.finish()\n",
        "    if sweep_id is None:\n",
        "        assert sweep_config is not None\n",
        "        sweep_id = wandb.sweep(sweep_config, project=PROJECT)\n",
        "    else:\n",
        "        assert sweep_config is None\n",
        "\n",
        "    !rm -rf {TRAINED_MODEL_DIR}/*\n",
        "\n",
        "    sweep_runner = SweepRunner(sweep_id)\n",
        "    wandb.agent(sweep_id, sweep_runner.main, project=PROJECT, count=n_runs)\n",
        "\n",
        "run_sweep(\n",
        "    # sweep_id='yj19ygra',\n",
        "    sweep_config=sweep_config,\n",
        "\n",
        "    # n_runs=None,\n",
        "    n_runs=1,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y-J5mD_PTar9",
        "SIU-vXqDRW3L",
        "oWn4ZCwkvtN3",
        "hWUph5lzrTUS",
        "LHIfVohUTAsG",
        "NYSbz9QQ7pS8",
        "KemUy0OKg-wX",
        "mxNCQ5KN6pfU",
        "09H8MxKH6nay",
        "fXntnmmhuSsR"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMQOpnNDGb3UhhmH22NulNP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}