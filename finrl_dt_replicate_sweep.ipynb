{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony-pitchblack/finrl-dt/blob/custom-backtesting/finrl_dt_replicate_sweep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs"
      ],
      "metadata": {
        "id": "Y-J5mD_PTar9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q yfinance==0.2.50"
      ],
      "metadata": {
        "id": "Sg45avPpswui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjEBRlmyPp2a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stable-baselines3\n",
        "!pip install finrl\n",
        "!pip install alpaca_trade_api\n",
        "!pip install exchange_calendars\n",
        "!pip install stockstats\n",
        "!pip install wrds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "if np.__version__ != '1.26.4':\n",
        "    !pip install -q numpy==1.26.4 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_RTmg2pwpR2W",
        "outputId": "f10b1618-f98a-4523-b426-dd4f9ab984b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.26.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import pandas as pd\n",
        "\n",
        "if pd.__version__ != '2.2.2':\n",
        "    !pip install -q pandas==2.2.2 --force-reinstall"
      ],
      "metadata": {
        "id": "KjhXAcAws0Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ],
      "metadata": {
        "id": "RfYDJoTXo6-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIU-vXqDRW3L"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "US_vB7hNSdeu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from stable_baselines3.common.logger import configure\n",
        "from finrl import config_tickers\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HJsl_3tVre6q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ObUHWwfqnzyQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = \"aee284a72205e2d6787bd3ce266c5b9aefefa42c\"\n",
        "PROJECT_NAME = 'finrl-dt-replicate'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General funcs"
      ],
      "metadata": {
        "id": "oWn4ZCwkvtN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title YahooDownloader\n",
        "\n",
        "\"\"\"Contains methods and classes to collect data from\n",
        "Yahoo Finance API\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic, start=self.start_date, end=self.end_date, proxy=proxy\n",
        "            )\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures += 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "\n",
        "        try:\n",
        "            # Convert wide to long format\n",
        "            # print(f\"DATA COLS: {data_df.columns}\")\n",
        "            data_df = data_df.sort_index(axis=1).set_index(['Date']).drop(columns=['tic']).stack(level='Ticker', future_stack=True)\n",
        "            data_df.reset_index(inplace=True)\n",
        "            data_df.columns.name = ''\n",
        "\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(columns={'Ticker': 'Tic', 'Adj Close': 'Adjcp'}, inplace=True)\n",
        "            data_df.rename(columns={col: col.lower() for col in data_df.columns}, inplace=True)\n",
        "\n",
        "            columns = [\n",
        "                \"date\",\n",
        "                \"tic\",\n",
        "                \"open\",\n",
        "                \"high\",\n",
        "                \"low\",\n",
        "                \"close\",\n",
        "                \"adjcp\",\n",
        "                \"volume\",\n",
        "            ]\n",
        "\n",
        "            data_df = data_df[columns]\n",
        "            # use adjusted close price instead of close price\n",
        "            data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "            # drop the adjusted close price column\n",
        "            data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "gbd4N4QLPXlL",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BRInsCaFgH63",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title construct_daily_index\n",
        "def construct_daily_index(data_df, date_column='date', new_index_name='date_index'):\n",
        "    \"\"\"\n",
        "    Constructs a daily index from unique dates in the specified column.\n",
        "\n",
        "    Parameters:\n",
        "        data_df (pd.DataFrame): The input DataFrame.\n",
        "        date_column (str): The name of the column containing dates.\n",
        "        new_index_name (str): The name for the new index.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with a daily index.\n",
        "    \"\"\"\n",
        "    # Get unique dates and create a mapping to daily indices\n",
        "    total_dates = data_df[date_column].unique()\n",
        "    date_to_index = {date: idx for idx, date in enumerate(sorted(total_dates))}\n",
        "\n",
        "    # Map dates to daily indices and set as index\n",
        "    data_df[new_index_name] = data_df[date_column].map(date_to_index)\n",
        "    data_df.set_index(new_index_name, inplace=True)\n",
        "    data_df.index.name = ''  # Remove the index name for simplicity\n",
        "\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TOfz3JlX-oG5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title add_dataset\n",
        "\n",
        "def get_dataset_name(prefix, train_start, test_start, test_end):\n",
        "    # Extract year and month\n",
        "    train_start_str = f\"{train_start.year}-{train_start.month:02}\"\n",
        "    test_start_str = f\"{test_start.year}-{test_start.month:02}\"\n",
        "    test_end_str = f\"{test_end.year}-{test_end.month:02}\"\n",
        "\n",
        "    # Construct the dataset name\n",
        "    dataset_name = f\"{prefix} | {train_start_str} | {test_start_str} | {test_end_str}\"\n",
        "    return dataset_name\n",
        "\n",
        "def add_dataset(stock_index_name, train_df, test_df):\n",
        "    if 'datasets' not in globals():\n",
        "        global datasets\n",
        "        datasets = {}\n",
        "\n",
        "    # Ensure datetime format\n",
        "    if 'date' in train_df.columns:\n",
        "        train_df.set_index('date', inplace=True)\n",
        "    train_df.index = pd.to_datetime(train_df.index)\n",
        "\n",
        "    if 'date' in test_df.columns:\n",
        "        test_df.set_index('date', inplace=True)\n",
        "    test_df.index = pd.to_datetime(test_df.index)\n",
        "\n",
        "    train_start_date = train_df.index[0]\n",
        "    test_start_date = test_df.index[0]\n",
        "    test_end_date = test_df.index[-1]\n",
        "\n",
        "    dataset_name = get_dataset_name(\n",
        "        stock_index_name,\n",
        "        train_start_date, test_start_date, test_end_date\n",
        "    )\n",
        "\n",
        "    train_df.reset_index(inplace=True)\n",
        "    test_df.reset_index(inplace=True)\n",
        "\n",
        "    train_df = construct_daily_index(train_df)\n",
        "    test_df = construct_daily_index(test_df)\n",
        "\n",
        "    ticker_list = train_df.tic.unique().tolist()\n",
        "\n",
        "    datasets[dataset_name] = {\n",
        "        'train': train_df,\n",
        "        'test': test_df,\n",
        "        'metadata': dict(\n",
        "            stock_index_name = stock_index_name,\n",
        "            train_start_date = train_start_date,\n",
        "            test_start_date = test_start_date,\n",
        "            test_end_date = test_end_date,\n",
        "            num_tickers = len(ticker_list),\n",
        "            ticker_list = ticker_list,\n",
        "        )\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWUph5lzrTUS"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA: DOW-30 (rolling yearly windows)"
      ],
      "metadata": {
        "id": "Op7oS8Jw1pgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download full data\n",
        "# %%capture\n",
        "\n",
        "min_test_start_year = 2020\n",
        "max_test_start_year = 2025\n",
        "\n",
        "train_years_count = 10\n",
        "test_years_count = 1.5\n",
        "\n",
        "min_date = \\\n",
        "    pd.Timestamp(year=min_test_start_year, month=1, day=1) - \\\n",
        "    pd.Timedelta(days=int(train_years_count * 365.2425))\n",
        "\n",
        "max_date = \\\n",
        "    pd.Timestamp(year=max_test_start_year, month=1, day=1) + \\\n",
        "    pd.Timedelta(days=int(test_years_count * 365.2425))\n",
        "\n",
        "data_df = YahooDownloader(\n",
        "    start_date=min_date,\n",
        "    end_date=max_date,\n",
        "    ticker_list=config_tickers.DOW_30_TICKER\n",
        ").fetch_data()\n",
        "\n",
        "data_df['date'] = pd.to_datetime(data_df['date'])\n",
        "\n",
        "# clip max year w.r.t. to available data\n",
        "max_data_date = data_df['date'].max()\n",
        "max_test_start_year = min(max_test_start_year, max_data_date.year)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L9_FOjg-qLA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "092c8220-8cac-4e1d-986a-f2ae3334b1b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (110753, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add features\n",
        "\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
        "\n",
        "fe = FeatureEngineer(use_turbulence=True, use_vix=True)\n",
        "preprocessed_data_df = fe.preprocess_data(data_df.astype({'date': str}))\n",
        "preprocessed_data_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UKKGaOBO6XWM",
        "outputId": "7c838909-f3e7-428f-c5ad-ea463d7634fc",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (3768, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date   tic       open       high        low      close       volume  \\\n",
              "0  2010-01-04  AAPL   7.622500   7.660714   7.585000   6.447412  493729600.0   \n",
              "1  2010-01-04  AMGN  56.630001  57.869999  56.560001  40.915901    5277400.0   \n",
              "2  2010-01-04   AXP  40.810001  41.099998  40.389999  32.906174    6894300.0   \n",
              "3  2010-01-04    BA  55.720001  56.389999  54.799999  43.777550    6186700.0   \n",
              "4  2010-01-04   CAT  57.650002  59.189999  57.509998  39.883911    7325600.0   \n",
              "\n",
              "   day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
              "0    0   0.0  6.468749  6.437222   100.0  66.666667  100.0      6.447412   \n",
              "1    0   0.0  6.468749  6.437222   100.0  66.666667  100.0     40.915901   \n",
              "2    0   0.0  6.468749  6.437222   100.0  66.666667  100.0     32.906174   \n",
              "3    0   0.0  6.468749  6.437222   100.0  66.666667  100.0     43.777550   \n",
              "4    0   0.0  6.468749  6.437222   100.0  66.666667  100.0     39.883911   \n",
              "\n",
              "   close_60_sma    vix  turbulence  \n",
              "0      6.447412  21.68         0.0  \n",
              "1     40.915901  21.68         0.0  \n",
              "2     32.906174  21.68         0.0  \n",
              "3     43.777550  21.68         0.0  \n",
              "4     39.883911  21.68         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e017465b-04f0-4e28-8bce-07910753a1ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.447412</td>\n",
              "      <td>493729600.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468749</td>\n",
              "      <td>6.437222</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.447412</td>\n",
              "      <td>6.447412</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>40.915901</td>\n",
              "      <td>5277400.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468749</td>\n",
              "      <td>6.437222</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>40.915901</td>\n",
              "      <td>40.915901</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>AXP</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>32.906174</td>\n",
              "      <td>6894300.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468749</td>\n",
              "      <td>6.437222</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>32.906174</td>\n",
              "      <td>32.906174</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>BA</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.777550</td>\n",
              "      <td>6186700.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468749</td>\n",
              "      <td>6.437222</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>43.777550</td>\n",
              "      <td>43.777550</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>CAT</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>39.883911</td>\n",
              "      <td>7325600.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468749</td>\n",
              "      <td>6.437222</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.883911</td>\n",
              "      <td>39.883911</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e017465b-04f0-4e28-8bce-07910753a1ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e017465b-04f0-4e28-8bce-07910753a1ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e017465b-04f0-4e28-8bce-07910753a1ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3f88880-6e84-4da4-a5cf-a368d53a0571\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3f88880-6e84-4da4-a5cf-a368d53a0571')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3f88880-6e84-4da4-a5cf-a368d53a0571 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "preprocessed_data_df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get_train_test_dates\n",
        "def get_train_test_dates(train_years_count, test_years_count, test_start_year):\n",
        "    test_start_date = pd.Timestamp(year=test_start_year, month=1, day=1)\n",
        "\n",
        "    train_start_date = \\\n",
        "        test_start_date - \\\n",
        "        pd.Timedelta(days=int(train_years_count * 365.2425))\n",
        "\n",
        "    test_end_date = \\\n",
        "        test_start_date + \\\n",
        "        pd.Timedelta(days=int(test_years_count * 365.2425))\n",
        "\n",
        "    return train_start_date, test_start_date, test_end_date"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tg4lrFhWStNP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data_df['date'] = pd.to_datetime(preprocessed_data_df['date'])\n",
        "\n",
        "for test_start_year in range(min_test_start_year, max_test_start_year + 1):\n",
        "    train_start_date, test_start_date, test_end_date = get_train_test_dates(\n",
        "        train_years_count, test_years_count, test_start_year\n",
        "    )\n",
        "\n",
        "    # Filter using the 'date' column\n",
        "    train_df = preprocessed_data_df[(preprocessed_data_df['date'] >= train_start_date) & (preprocessed_data_df['date'] < test_start_date)]\n",
        "    test_df = preprocessed_data_df[(preprocessed_data_df['date'] >= test_start_date) & (preprocessed_data_df['date'] < test_end_date)]\n",
        "\n",
        "    # add_dataset('DOW_30', train_df, test_df)\n",
        "\n",
        "    print(f\"Train start: {train_df['date'].min()}, Train end: {train_df['date'].max()}\")\n",
        "    print(f\"Test start: {test_df['date'].min()}, Test end: {test_df['date'].max()}\")\n",
        "    print()\n",
        "\n",
        "# print(*list(datasets.keys()), sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBiw3TS56LfN",
        "outputId": "1b821d80-9ca0-4575-f862-ebf252853850"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train start: 2010-01-04 00:00:00, Train end: 2019-12-31 00:00:00\n",
            "Test start: 2020-01-02 00:00:00, Test end: 2021-06-30 00:00:00\n",
            "\n",
            "Train start: 2011-01-03 00:00:00, Train end: 2020-12-31 00:00:00\n",
            "Test start: 2021-01-04 00:00:00, Test end: 2022-07-01 00:00:00\n",
            "\n",
            "Train start: 2012-01-03 00:00:00, Train end: 2021-12-31 00:00:00\n",
            "Test start: 2022-01-03 00:00:00, Test end: 2023-06-30 00:00:00\n",
            "\n",
            "Train start: 2013-01-02 00:00:00, Train end: 2022-12-30 00:00:00\n",
            "Test start: 2023-01-03 00:00:00, Test end: 2024-06-28 00:00:00\n",
            "\n",
            "Train start: 2014-01-02 00:00:00, Train end: 2023-12-29 00:00:00\n",
            "Test start: 2024-01-02 00:00:00, Test end: 2024-12-20 00:00:00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "NYSbz9QQ7pS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "znlXqpfQZkzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title init\n",
        "parameters_dict = {}\n",
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "        'name': 'max_sharpe_ratio'\n",
        "    },\n",
        "    'parameters': parameters_dict\n",
        "}"
      ],
      "metadata": {
        "id": "kF6LboMHB2xZ",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title used models\n",
        "\n",
        "parameters_dict.update({\n",
        "    'if_using_a2c': {'value': True},\n",
        "    'if_using_ddpg': {'value': True},\n",
        "    'if_using_ppo': {'value': True},\n",
        "    'if_using_td3': {'value': True},\n",
        "    'if_using_sac': {'value': True}\n",
        "})"
      ],
      "metadata": {
        "id": "y8RxLtlsesZg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title date range\n",
        "parameters_dict.update(dict(\n",
        "    stock_index_name = {'value': 'DOW-30'},\n",
        "    train_years_count = {'value': 10},\n",
        "    test_years_count = {'value': 1},\n",
        "    test_start_year = {\n",
        "        # 'value': 2020,\n",
        "        'values': list(range(2020, 2025))\n",
        "    }\n",
        "))"
      ],
      "metadata": {
        "id": "7RzkkJNiSkP7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title env params\n",
        "parameters_dict.update(dict(\n",
        "    env_params = {\n",
        "        'parameters': dict(\n",
        "            cost_abs = {'value': 2.5},\n",
        "            initial_amount = {'value': 50_000},\n",
        "        )\n",
        "    },\n",
        "    REFERENCE_PRICE_END_DATE = {'value': '2024-12-21'},\n",
        "    REFERNCE_PRICE_WINDOW_DAYS = {'value': 30}\n",
        "))"
      ],
      "metadata": {
        "id": "ILF379nrW4YK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wandb artifacts"
      ],
      "metadata": {
        "id": "KemUy0OKg-wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title update_artifact\n",
        "\n",
        "def update_artifact(folder_path, name_prefix, type):\n",
        "    \"\"\"\n",
        "    Create or update a W&B artifact consisting of a folder.\n",
        "\n",
        "    Args:\n",
        "        run: The current W&B run.\n",
        "        folder_path (str): Path to the folder to upload.\n",
        "        artifact_name (str): Name of the artifact.\n",
        "        artifact_type (str): Type of the artifact.\n",
        "    \"\"\"\n",
        "    run = wandb.run\n",
        "    artifact_name = f'{name_prefix}-{wandb.run.id}'\n",
        "\n",
        "    # Create a new artifact\n",
        "    artifact = wandb.Artifact(name=artifact_name, type=type)\n",
        "\n",
        "    # Add the folder to the artifact\n",
        "    artifact.add_dir(folder_path)\n",
        "\n",
        "    # Log the artifact to W&B\n",
        "    run.log_artifact(artifact)\n",
        "    print(f\"Artifact '{artifact_name}' has been updated and uploaded.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jF0Xbv9f631H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B-a7jHoxrb3Q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title update_model_artifacts\n",
        "\n",
        "def update_model_artifacts():\n",
        "    update_artifact(\n",
        "        folder_path = RESULTS_DIR,\n",
        "        name_prefix = 'results',\n",
        "        type = 'results'\n",
        "    )\n",
        "\n",
        "    update_artifact(\n",
        "        folder_path = TRAINED_MODEL_DIR,\n",
        "        name_prefix = 'trained_models',\n",
        "        type = 'trained_models'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title update_dataset_artifact\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def update_dataset_artifact(train, test, config):\n",
        "    DATASET_DIR = Path('./dataset')\n",
        "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "    train.to_csv(DATASET_DIR / 'train_data.csv')\n",
        "    test.to_csv(DATASET_DIR / 'test_data.csv')\n",
        "\n",
        "    update_artifact(\n",
        "        folder_path = DATASET_DIR,\n",
        "        name_prefix = 'dataset',\n",
        "        type = 'dataset'\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Prm8SfPo7CJY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build funcs"
      ],
      "metadata": {
        "id": "_BZTsxX0tkDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title build_dataset\n",
        "def build_dataset(config):\n",
        "    # Assuming 'config' is a dictionary or a similar object that contains the necessary parameters\n",
        "\n",
        "    train_start_date, test_start_date, test_end_date = get_train_test_dates(\n",
        "        config['train_years_count'],\n",
        "        config['test_years_count'],\n",
        "        config['test_start_year']\n",
        "    )\n",
        "\n",
        "    train_df = preprocessed_data_df[(preprocessed_data_df['date'] >= train_start_date) & (preprocessed_data_df['date'] < test_start_date)]\n",
        "    test_df = preprocessed_data_df[(preprocessed_data_df['date'] >= test_start_date) & (preprocessed_data_df['date'] < test_end_date)]\n",
        "\n",
        "    train_df = construct_daily_index(train_df)\n",
        "    test_df = construct_daily_index(test_df)\n",
        "\n",
        "    dataset_name = get_dataset_name(\n",
        "        config['stock_index_name'], train_start_date, test_start_date, test_end_date\n",
        "    )\n",
        "\n",
        "    config.update(dict(\n",
        "        train_start_date=train_start_date,\n",
        "        test_start_date=test_start_date,\n",
        "        test_end_date=test_end_date,\n",
        "        dataset_name=dataset_name\n",
        "    ))\n",
        "\n",
        "    update_dataset_artifact(train_df, test_df, config)\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SmzfG0qaVP93"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "id": "hE7nHKrYos_t",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Calculate fee percent based on average price for past N days\n",
        "\n",
        "def cost_pct_from_avg_price(df, cost_abs, price_avg_days, verbose=False):\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    avg_price_dict = {}\n",
        "    for tic, _df in df.groupby('tic'):\n",
        "        last_date = _df['date'].max()\n",
        "        _df = _df[_df.date >= last_date - pd.Timedelta(days=price_avg_days)]\n",
        "        avg_price = ((_df.high + _df.low) / 2).mean()\n",
        "        avg_price_dict.update({tic: avg_price})\n",
        "\n",
        "    avg_price_df = pd.DataFrame(avg_price_dict, index=[f'cost_avg']).T\n",
        "    cost_pct_df = (cost_abs / avg_price_df).rename(columns={'cost_avg': 'cost_pct'})\n",
        "\n",
        "    if verbose:\n",
        "        display(avg_price_df.head())\n",
        "        print()\n",
        "        display(cost_pct_df.head())\n",
        "\n",
        "    return cost_pct_df.values.flatten().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title set_cost_pct\n",
        "\n",
        "def set_cost_pct(train, config):\n",
        "    # Calculate reference price interval\n",
        "    REFERENCE_PRICE_END_DATE = config['REFERENCE_PRICE_END_DATE']\n",
        "    REFERNCE_PRICE_WINDOW_DAYS = config['REFERNCE_PRICE_WINDOW_DAYS']\n",
        "\n",
        "    ref_price_start_date = \\\n",
        "        pd.Timestamp(REFERENCE_PRICE_END_DATE) \\\n",
        "        - pd.Timedelta(days=REFERNCE_PRICE_WINDOW_DAYS)\n",
        "\n",
        "    ref_price_df = YahooDownloader(\n",
        "            start_date=ref_price_start_date,\n",
        "            end_date=REFERENCE_PRICE_END_DATE,\n",
        "            ticker_list=train.tic.unique().tolist(),\n",
        "            # ticker_list=config_tickers.DOW_30_TICKER\n",
        "        ).fetch_data()\n",
        "\n",
        "    # Calculate cost\n",
        "    COST_PCT = cost_pct_from_avg_price(\n",
        "        df=ref_price_df,\n",
        "        cost_abs=config['env_params']['cost_abs'],\n",
        "        price_avg_days=config['REFERNCE_PRICE_WINDOW_DAYS'],\n",
        "        # verbose=False\n",
        "    )\n",
        "\n",
        "    config['env_params'].update({ 'cost_pct': COST_PCT })\n",
        "\n",
        "    # print(config)"
      ],
      "metadata": {
        "id": "BrmZizKHFZZE",
        "cellView": "form"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_DFUBgSZT5-a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Init env\n",
        "def init_env(train, config):\n",
        "    stock_dimension = len(train.tic.unique())\n",
        "    state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "\n",
        "    cost_pct = config['env_params']['cost_pct']\n",
        "    if isinstance(cost_pct, list):\n",
        "        assert len(cost_pct) == stock_dimension\n",
        "        buy_cost_pct = sell_cost_pct = cost_pct\n",
        "    elif isinstance(cost_pct, (int, float)):\n",
        "        buy_cost_pct = sell_cost_pct = [ config['COST_PCT'] ] * stock_dimension\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "    env_kwargs = {\n",
        "        \"hmax\": 100,\n",
        "        \"initial_amount\": config['env_params']['initial_amount'],\n",
        "        \"num_stock_shares\": num_stock_shares,\n",
        "        \"buy_cost_pct\": buy_cost_pct,\n",
        "        \"sell_cost_pct\": sell_cost_pct,\n",
        "        \"state_space\": state_space,\n",
        "        \"stock_dim\": stock_dimension,\n",
        "        \"tech_indicator_list\": INDICATORS,\n",
        "        \"action_space\": stock_dimension,\n",
        "        \"reward_scaling\": 1e-4,\n",
        "\n",
        "        \"print_verbosity\": 1,\n",
        "        # \"make_plots\": True\n",
        "    }\n",
        "\n",
        "    e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
        "    return e_train_gym"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train models"
      ],
      "metadata": {
        "id": "oqc-9r54tuXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SharpeRatioCallback\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class SharpeRatioCallback(BaseCallback):\n",
        "    def __init__(self, model_name, verbose=0):\n",
        "        self.model_name = model_name\n",
        "        super(SharpeRatioCallback, self).__init__(verbose)\n",
        "        self.sharpe_ratios = []\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # print(f\"LOGGING {self.model_name} sharpe ratio\")\n",
        "        # Access the environment\n",
        "        env = self.training_env.envs[0]\n",
        "\n",
        "        # Check if the episode is terminal\n",
        "        env.terminal = env.day >= len(env.df.index.unique()) - 1\n",
        "        if env.terminal:\n",
        "            # breakpoint()\n",
        "            df_total_value = pd.DataFrame(env.asset_memory, columns=[\"account_value\"])\n",
        "            df_total_value[\"date\"] = env.date_memory\n",
        "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
        "\n",
        "            # Calculate the Sharpe ratio if standard deviation is non-zero\n",
        "            if df_total_value[\"daily_return\"].std() != 0:\n",
        "                sharpe = (\n",
        "                    (252**0.5)\n",
        "                    * df_total_value[\"daily_return\"].mean()\n",
        "                    / df_total_value[\"daily_return\"].std()\n",
        "                )\n",
        "                self.sharpe_ratios.append(sharpe)\n",
        "\n",
        "                # Log the Sharpe ratio\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"Episode: {env.episode}, Sharpe Ratio: {sharpe:.3f}\")\n",
        "\n",
        "                # Update WandB config with distinct Sharpe ratios\n",
        "                wandb.log({\n",
        "                    f'sharpe_ratio/{self.model_name}': sharpe,\n",
        "                }, step=env.episode)\n",
        "\n",
        "                # Add to config for instant acess\n",
        "                if \"sharpe_ratios\" not in wandb.config:\n",
        "                    wandb.config.sharpe_ratios = {}\n",
        "\n",
        "                wandb.config.sharpe_ratios[self.model_name] = sharpe\n",
        "\n",
        "            print(wandb.run.summary.keys())\n",
        "        return True"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eZPK1476kLm_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MaxSharpeRatioCallback\n",
        "\n",
        "import re\n",
        "import wandb\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "class MaxSharpeRatioCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super(MaxSharpeRatioCallback, self).__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> None:\n",
        "        # Access the environment\n",
        "        env = self.training_env.envs[0]\n",
        "\n",
        "        # Check if the episode is terminal\n",
        "        env.terminal = env.day >= len(env.df.index.unique()) - 1\n",
        "        if env.terminal:\n",
        "            # print(\"LOGGING max sharpe ratio\")\n",
        "            # Get the summary from wandb run\n",
        "            # summary = wandb.run.summary\n",
        "\n",
        "            # # Create the sharpe_dict by extracting model names and Sharpe ratios\n",
        "            # sharpe_ratios = {\n",
        "            #     re.match('sharpe_ratio/(.*)', key).group(1): summary.get(key)\n",
        "            #     for key in summary.keys() if re.match('sharpe_ratio/(.*)', key)\n",
        "            # }\n",
        "\n",
        "            sharpe_ratios = wandb.config.get(\"sharpe_ratios\", {})\n",
        "            max_sharpe_ratio_model = max(sharpe_ratios, key=sharpe_ratios.get)\n",
        "            max_sharpe_ratio = sharpe_ratios[max_sharpe_ratio_model]\n",
        "\n",
        "            # Log the max Sharpe ratio and the corresponding model name\n",
        "            wandb.log({\n",
        "                'max_sharpe_ratio': max_sharpe_ratio,\n",
        "                'max_sharpe_ratio_model': max_sharpe_ratio_model\n",
        "            })\n",
        "\n",
        "            # # Optionally print if verbose is enabled\n",
        "            # if self.verbose > 0:\n",
        "            #     print(f\"Max Sharpe Ratio: {max_sharpe_ratio} from Model: {max_sharpe_ratio_model}\")\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PMDX8FvG_ipa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom DRLAgent (3 callbacks)\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent, TensorboardCallback\n",
        "from stable_baselines3.common.callbacks import CallbackList\n",
        "import wandb\n",
        "\n",
        "class DRLAgent(DRLAgent):\n",
        "    @staticmethod\n",
        "    def train_model(\n",
        "        model,\n",
        "        tb_log_name,\n",
        "        total_timesteps=5000,\n",
        "        callback=None,  # Allow custom callbacks to be passed\n",
        "    ):\n",
        "        # Ensure TensorboardCallback is always included\n",
        "        tensorboard_callback = TensorboardCallback()\n",
        "\n",
        "        # Initialize default callbacks\n",
        "        sharpe_ratio_callback = SharpeRatioCallback(model_name=tb_log_name, verbose=1)\n",
        "        max_sharpe_ratio_ratio_callback = MaxSharpeRatioCallback(verbose=1)\n",
        "\n",
        "        # Combine all callbacks (always include Tensorboard, SharpeRatio, and MaxSharpeRatio by default)\n",
        "        callbacks_to_use = [\n",
        "            tensorboard_callback,\n",
        "            sharpe_ratio_callback,\n",
        "            max_sharpe_ratio_ratio_callback\n",
        "        ]\n",
        "\n",
        "        # Add any custom callback passed by the user\n",
        "        if callback is not None:\n",
        "            if isinstance(callback, BaseCallback):\n",
        "                callbacks_to_use.append(callback)\n",
        "            elif isinstance(callback, list):\n",
        "                callbacks_to_use.extend(callback)\n",
        "            else:\n",
        "                raise ValueError(\"callback must be None, a BaseCallback, or a list of BaseCallback instances.\")\n",
        "\n",
        "        # Wrap all callbacks into a CallbackList\n",
        "        combined_callback = CallbackList(callbacks_to_use)\n",
        "\n",
        "        # Train the model with the combined callbacks\n",
        "        model = model.learn(\n",
        "            total_timesteps=total_timesteps,\n",
        "            tb_log_name=tb_log_name,\n",
        "            callback=combined_callback,\n",
        "        )\n",
        "        return model\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n_ztcCc4AgTl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "cellView": "form",
        "id": "dyvEieUxQvSA"
      },
      "outputs": [],
      "source": [
        "#@title train models\n",
        "\n",
        "def train_models(e_train_gym, config):\n",
        "    check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "\n",
        "    env_train, _ = e_train_gym.get_sb_env()\n",
        "    print(type(env_train))\n",
        "\n",
        "    # Set the corresponding values to 'True' for the algorithms that you want to use\n",
        "\n",
        "    # Load variables from the config\n",
        "    if_using_a2c = config[\"if_using_a2c\"]\n",
        "    if_using_ddpg = config[\"if_using_ddpg\"]\n",
        "    if_using_ppo = config[\"if_using_ppo\"]\n",
        "    if_using_td3 = config[\"if_using_td3\"]\n",
        "    if_using_sac = config[\"if_using_sac\"]\n",
        "\n",
        "    if if_using_a2c:\n",
        "        print(\"training A2C agent\")\n",
        "        agent = DRLAgent(env = env_train)\n",
        "        model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "        # set up logger\n",
        "        tmp_path = RESULTS_DIR + '/a2c'\n",
        "        !rm -rf {tmp_path}/*\n",
        "        new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "        # Set new logger\n",
        "        model_a2c.set_logger(new_logger_a2c)\n",
        "\n",
        "        trained_a2c = agent.train_model(model=model_a2c,\n",
        "                                        tb_log_name='a2c',\n",
        "                                        total_timesteps=50000) if if_using_a2c else None\n",
        "\n",
        "        trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n",
        "        update_model_artifacts()\n",
        "\n",
        "    if if_using_ddpg:\n",
        "        print(\"training DDPG agent\")\n",
        "        agent = DRLAgent(env = env_train)\n",
        "        model_ddpg = agent.get_model(\"ddpg\")\n",
        "\n",
        "        # set up logger\n",
        "        tmp_path = RESULTS_DIR + '/ddpg'\n",
        "        !rm -rf {tmp_path}/*\n",
        "        new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "        # Set new logger\n",
        "        model_ddpg.set_logger(new_logger_ddpg)\n",
        "\n",
        "        trained_ddpg = agent.train_model(model=model_ddpg,\n",
        "                                tb_log_name='ddpg',\n",
        "                                total_timesteps=50000) if if_using_ddpg else None\n",
        "\n",
        "        trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n",
        "        update_model_artifacts()\n",
        "\n",
        "    if if_using_td3:\n",
        "        print(\"training TD3 agent\")\n",
        "        agent = DRLAgent(env = env_train)\n",
        "        TD3_PARAMS = {\"batch_size\": 100,\n",
        "                    \"buffer_size\": 1000000,\n",
        "                    \"learning_rate\": 0.001}\n",
        "\n",
        "        model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
        "\n",
        "        # set up logger\n",
        "        tmp_path = RESULTS_DIR + '/td3'\n",
        "        !rm -rf {tmp_path}/*\n",
        "        new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "        # Set new logger\n",
        "        model_td3.set_logger(new_logger_td3)\n",
        "\n",
        "        trained_td3 = agent.train_model(model=model_td3,\n",
        "                                tb_log_name='td3',\n",
        "                                total_timesteps=50000) if if_using_td3 else None\n",
        "\n",
        "        trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n",
        "        update_model_artifacts()\n",
        "\n",
        "    if if_using_sac:\n",
        "        print(\"training SAC agent\")\n",
        "        agent = DRLAgent(env = env_train)\n",
        "        SAC_PARAMS = {\n",
        "            \"batch_size\": 128,\n",
        "            \"buffer_size\": 100000,\n",
        "            \"learning_rate\": 0.0001,\n",
        "            \"learning_starts\": 100,\n",
        "            \"ent_coef\": \"auto_0.1\",\n",
        "        }\n",
        "\n",
        "        model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
        "\n",
        "        # set up logger\n",
        "        tmp_path = RESULTS_DIR + '/sac'\n",
        "        !rm -rf {tmp_path}/*\n",
        "        new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "        # Set new logger\n",
        "        model_sac.set_logger(new_logger_sac)\n",
        "\n",
        "        trained_sac = agent.train_model(model=model_sac,\n",
        "                                tb_log_name='sac',\n",
        "                                total_timesteps=70000) if if_using_sac else None\n",
        "        trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None\n",
        "        update_model_artifacts()\n",
        "\n",
        "    if if_using_ppo:\n",
        "        agent = DRLAgent(env = env_train)\n",
        "        PPO_PARAMS = {\n",
        "            \"n_steps\": 2048,\n",
        "            \"ent_coef\": 0.01,\n",
        "            \"learning_rate\": 0.00025,\n",
        "            \"batch_size\": 128,\n",
        "        }\n",
        "        model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "        # set up logger\n",
        "        tmp_path = RESULTS_DIR + '/ppo'\n",
        "        !rm -rf {tmp_path}/*\n",
        "        new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "        # Set new logger\n",
        "        model_ppo.set_logger(new_logger_ppo)\n",
        "\n",
        "        trained_ppo = agent.train_model(model=model_ppo,\n",
        "                                tb_log_name='ppo',\n",
        "                                total_timesteps=200000) if if_using_ppo else None\n",
        "\n",
        "        trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n",
        "        update_model_artifacts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train\n",
        "from pprint import pprint\n",
        "import wandb\n",
        "\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_run_name(prefix, n=5):\n",
        "    random_str = ''.join(random.choices(string.ascii_letters + string.digits, k=n))\n",
        "    return f\"{prefix} | {random_str}\"\n",
        "\n",
        "def train(config=None):\n",
        "    # Initialize a new wandb run using the context manager\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        # Build the dataset\n",
        "        train_df, test_df = build_dataset(config)\n",
        "\n",
        "        wandb.run.name = generate_run_name(config['dataset_name'])\n",
        "        wandb.run.save()\n",
        "\n",
        "        # Set the cost percentage (or any other constants you need to set)\n",
        "        set_cost_pct(train_df, config)\n",
        "\n",
        "        # Initialize the training environment\n",
        "        e_train_gym = init_env(train_df, config)\n",
        "\n",
        "        # Train the models (assuming this function will handle the model training)\n",
        "        train_models(e_train_gym, config)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nhQvANbwxN5r"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uSosu3u-YIIA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abe571d2-6fc6-4c86-e28b-41ddbed6f12b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: pknx8zsp\n",
            "Sweep URL: https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/pknx8zsp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2qo4lebf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tREFERENCE_PRICE_END_DATE: 2024-12-21\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tREFERNCE_PRICE_WINDOW_DAYS: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv_params: {'cost_abs': 2.5, 'initial_amount': 50000}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_a2c: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_ddpg: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_ppo: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_sac: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tif_using_td3: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tstock_index_name: DOW-30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_start_year: 2020\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_years_count: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_years_count: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtony-pitchblack\u001b[0m (\u001b[33moverfit1010\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241223_192024-2qo4lebf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/overfit1010/finrl-dt-replicate/runs/2qo4lebf' target=\"_blank\">fluent-sweep-1</a></strong> to <a href='https://wandb.ai/overfit1010/finrl-dt-replicate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/pknx8zsp' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/pknx8zsp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/pknx8zsp' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/sweeps/pknx8zsp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/runs/2qo4lebf' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/runs/2qo4lebf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./dataset)... Done. 0.1s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifact 'dataset-2qo4lebf' has been updated and uploaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (609, 8)\n",
            "{'REFERENCE_PRICE_END_DATE': '2024-12-21', 'REFERNCE_PRICE_WINDOW_DAYS': 30, 'env_params': {'cost_abs': 2.5, 'initial_amount': 50000, 'cost_pct': [0.010314179718673032, 0.009076606561755468, 0.008307067100246136, 0.015516293581809113, 0.006395481989312903, 0.0072110283262062785, 0.04249566955190291, 0.015979716445954528, 0.021738725278835313, 0.004222453318177087, 0.005968143721526647, 0.010896151366589465, 0.01093735188446354, 0.11420864277075855, 0.01665255165637118, 0.010252194206940846, 0.03947813656400475, 0.008462643895002689, 0.019197296925249206, 0.024719550845968045, 0.005734449144229167, 0.03210832438433615, 0.014379031318205482, 0.009825802549097859, 0.0044498520553265045, 0.007984135151425499, 0.05881990501271046, 0.270946766931955, 0.026832260273111818]}, 'if_using_a2c': True, 'if_using_ddpg': True, 'if_using_ppo': True, 'if_using_sac': True, 'if_using_td3': True, 'stock_index_name': 'DOW-30', 'test_start_year': 2020, 'test_years_count': 1, 'train_years_count': 10, 'train_start_date': '2010-01-01T00:00:00', 'test_start_date': '2020-01-01T00:00:00', 'test_end_date': '2020-12-31T00:00:00', 'dataset_name': 'DOW-30 | 2010-01 | 2020-01 | 2020-12'}\n",
            "Stock Dimension: 29, State Space: 291\n",
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
            "training A2C agent\n",
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 66       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | -1.2e+03 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 5.23     |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0295   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.8    |\n",
            "|    explained_variance | -25.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -4.4     |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.0111   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.6    |\n",
            "|    explained_variance | -343     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 0.433    |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.000162 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -43.5    |\n",
            "|    explained_variance | -836     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -0.922   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.000617 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -44.9    |\n",
            "|    explained_variance | -47.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -0.635   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 0.00036  |\n",
            "------------------------------------\n",
            "Episode: 2, Sharpe Ratio: -3.341\n",
            "[]\n",
            "Max Sharpe Ratio: -3.3409478248451867 from Model: a2c\n",
            "day: 2515, episode: 2\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 10.98\n",
            "total_reward: -49989.02\n",
            "total_cost: 50891.91\n",
            "total_trades: 34954\n",
            "Sharpe: -3.341\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 77            |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -45.4         |\n",
            "|    explained_variance | -1.73e+03     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | 0.91          |\n",
            "|    reward             | -8.365005e-05 |\n",
            "|    std                | 1.16          |\n",
            "|    value_loss         | 0.0142        |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -46.3    |\n",
            "|    explained_variance | -0.124   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -1.91    |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.2      |\n",
            "|    value_loss         | 0.00149  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -47.5    |\n",
            "|    explained_variance | -10.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -0.0134  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 1.45e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 56       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -48.8    |\n",
            "|    explained_variance | -8.82    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.272    |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.3      |\n",
            "|    value_loss         | 3.65e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 63       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -50.3    |\n",
            "|    explained_variance | -6.32    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -0.48    |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.37     |\n",
            "|    value_loss         | 0.000113 |\n",
            "------------------------------------\n",
            "Episode: 3, Sharpe Ratio: -3.523\n",
            "['_timestamp', 'max_sharpe_ratio', 'max_sharpe_ratio_model', '_runtime', '_step', 'sharpe_ratio/a2c']\n",
            "Max Sharpe Ratio: -3.5226858240757113 from Model: a2c\n",
            "day: 2515, episode: 3\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 10.67\n",
            "total_reward: -49989.33\n",
            "total_cost: 54208.05\n",
            "total_trades: 36963\n",
            "Sharpe: -3.523\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 79            |\n",
            "|    iterations         | 1100          |\n",
            "|    time_elapsed       | 69            |\n",
            "|    total_timesteps    | 5500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -51.1         |\n",
            "|    explained_variance | -6.59         |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1099          |\n",
            "|    policy_loss        | 0.224         |\n",
            "|    reward             | -0.0015152976 |\n",
            "|    std                | 1.41          |\n",
            "|    value_loss         | 5.41e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 75       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -52.2    |\n",
            "|    explained_variance | -0.0152  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -0.0391  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.47     |\n",
            "|    value_loss         | 6.93e-07 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -53.7     |\n",
            "|    explained_variance | -1.49e+05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 0.547     |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 1.54      |\n",
            "|    value_loss         | 0.000134  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 87       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -55.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.00362  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.63     |\n",
            "|    value_loss         | 5.6e-09  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 94       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -57.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.00212 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.73     |\n",
            "|    value_loss         | 1.71e-09 |\n",
            "------------------------------------\n",
            "Episode: 4, Sharpe Ratio: -3.070\n",
            "['_runtime', '_step', 'sharpe_ratio/a2c', '_timestamp', 'max_sharpe_ratio', 'max_sharpe_ratio_model']\n",
            "Max Sharpe Ratio: -3.0698967268239272 from Model: a2c\n",
            "day: 2515, episode: 4\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 10.87\n",
            "total_reward: -49989.13\n",
            "total_cost: 51795.57\n",
            "total_trades: 41078\n",
            "Sharpe: -3.070\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 80           |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 99           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -58          |\n",
            "|    explained_variance | -306         |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | -1.79        |\n",
            "|    reward             | 8.219909e-06 |\n",
            "|    std                | 1.79         |\n",
            "|    value_loss         | 0.00183      |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -59.2    |\n",
            "|    explained_variance | -10.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.436   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.87     |\n",
            "|    value_loss         | 5.7e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 114      |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -60.7    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.00708 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.97     |\n",
            "|    value_loss         | 1.71e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 121      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -62.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.00339 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 2.09     |\n",
            "|    value_loss         | 3.17e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 126      |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -64.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 7.92e-06 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 2.23     |\n",
            "|    value_loss         | 3.96e-15 |\n",
            "------------------------------------\n",
            "Episode: 5, Sharpe Ratio: -3.274\n",
            "['_timestamp', 'max_sharpe_ratio', 'max_sharpe_ratio_model', '_runtime', '_step', 'sharpe_ratio/a2c']\n",
            "Max Sharpe Ratio: -3.27365480748605 from Model: a2c\n",
            "day: 2515, episode: 5\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 10.21\n",
            "total_reward: -49989.79\n",
            "total_cost: 52422.59\n",
            "total_trades: 42834\n",
            "Sharpe: -3.274\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 79            |\n",
            "|    iterations         | 2100          |\n",
            "|    time_elapsed       | 132           |\n",
            "|    total_timesteps    | 10500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -65.5         |\n",
            "|    explained_variance | -1.48         |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2099          |\n",
            "|    policy_loss        | 0.291         |\n",
            "|    reward             | -8.849171e-05 |\n",
            "|    std                | 2.31          |\n",
            "|    value_loss         | 2.57e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 139      |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -66.7    |\n",
            "|    explained_variance | -5.17    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.429    |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 2.41     |\n",
            "|    value_loss         | 7.34e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 144      |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -68.1    |\n",
            "|    explained_variance | -65.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.0647   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 2.54     |\n",
            "|    value_loss         | 4.25e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 152      |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -69.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.00029  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 2.69     |\n",
            "|    value_loss         | 2.09e-11 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 158      |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -71.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 4.93e-06 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 2.88     |\n",
            "|    value_loss         | 1.01e-15 |\n",
            "------------------------------------\n",
            "Episode: 6, Sharpe Ratio: -3.126\n",
            "['_step', 'sharpe_ratio/a2c', '_timestamp', 'max_sharpe_ratio', 'max_sharpe_ratio_model', '_runtime']\n",
            "Max Sharpe Ratio: -3.126200879769704 from Model: a2c\n",
            "day: 2515, episode: 6\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 10.92\n",
            "total_reward: -49989.08\n",
            "total_cost: 50174.88\n",
            "total_trades: 42933\n",
            "Sharpe: -3.126\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 78           |\n",
            "|    iterations         | 2600         |\n",
            "|    time_elapsed       | 165          |\n",
            "|    total_timesteps    | 13000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -73          |\n",
            "|    explained_variance | -238         |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2599         |\n",
            "|    policy_loss        | -0.949       |\n",
            "|    reward             | 8.065872e-05 |\n",
            "|    std                | 3            |\n",
            "|    value_loss         | 0.000262     |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 171      |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -74.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.0549   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 3.14     |\n",
            "|    value_loss         | 7.34e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 177      |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -75.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.000107 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 3.32     |\n",
            "|    value_loss         | 2.4e-12  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 183      |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -77.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -0.00018 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 3.54     |\n",
            "|    value_loss         | 6.39e-12 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 189       |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -79.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | -1.19e-06 |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 3.79      |\n",
            "|    value_loss         | 2.84e-16  |\n",
            "-------------------------------------\n",
            "Episode: 7, Sharpe Ratio: -3.661\n",
            "['_timestamp', 'max_sharpe_ratio', 'max_sharpe_ratio_model', '_runtime', '_step', 'sharpe_ratio/a2c']\n",
            "Max Sharpe Ratio: -3.661363180166453 from Model: a2c\n",
            "day: 2515, episode: 7\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 10.39\n",
            "total_reward: -49989.61\n",
            "total_cost: 51673.55\n",
            "total_trades: 42424\n",
            "Sharpe: -3.661\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 78            |\n",
            "|    iterations         | 3100          |\n",
            "|    time_elapsed       | 196           |\n",
            "|    total_timesteps    | 15500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -81           |\n",
            "|    explained_variance | -17.2         |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3099          |\n",
            "|    policy_loss        | -0.763        |\n",
            "|    reward             | -0.0028673704 |\n",
            "|    std                | 3.96          |\n",
            "|    value_loss         | 0.000125      |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 201      |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -82.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 0.00545  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 4.15     |\n",
            "|    value_loss         | 5.31e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 208      |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -84      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | -0.00249 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 4.39     |\n",
            "|    value_loss         | 1.01e-09 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
        "wandb.agent(sweep_id, train, count=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y-J5mD_PTar9",
        "SIU-vXqDRW3L",
        "oWn4ZCwkvtN3",
        "KemUy0OKg-wX"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMaALDNZdTZ1MSxHuYBUNA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}