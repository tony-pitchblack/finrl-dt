{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony-pitchblack/finrl-dt/blob/custom-backtesting/finrl_dt_replicate_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-J5mD_PTar9"
      },
      "source": [
        "#Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg45avPpswui",
        "outputId": "a4f33eda-e669-40fa-8417-aed97e0fdf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m92.2/102.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q yfinance==0.2.50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FjEBRlmyPp2a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stable-baselines3\n",
        "!pip install finrl\n",
        "!pip install alpaca_trade_api\n",
        "!pip install exchange_calendars\n",
        "!pip install stockstats\n",
        "!pip install wrds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_RTmg2pwpR2W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "if np.__version__ != '1.26.4':\n",
        "    !pip install -q numpy==1.26.4 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KjhXAcAws0Rx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import pandas as pd\n",
        "\n",
        "if pd.__version__ != '2.2.2':\n",
        "    !pip install -q pandas==2.2.2 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RfYDJoTXo6-J"
      },
      "outputs": [],
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIU-vXqDRW3L"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "US_vB7hNSdeu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from stable_baselines3.common.logger import configure\n",
        "from finrl import config_tickers\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HJsl_3tVre6q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I9s6zvbUAsyq"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = \"aee284a72205e2d6787bd3ce266c5b9aefefa42c\"\n",
        "\n",
        "PROJECT = 'finrl-dt-replicate'\n",
        "ENTITY = \"overfit1010\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWn4ZCwkvtN3"
      },
      "source": [
        "# General funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "gbd4N4QLPXlL"
      },
      "outputs": [],
      "source": [
        "#@title YahooDownloader\n",
        "\n",
        "\"\"\"Contains methods and classes to collect data from\n",
        "Yahoo Finance API\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic, start=self.start_date, end=self.end_date, proxy=proxy\n",
        "            )\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures += 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "\n",
        "        try:\n",
        "            # Convert wide to long format\n",
        "            # print(f\"DATA COLS: {data_df.columns}\")\n",
        "            data_df = data_df.sort_index(axis=1).set_index(['Date']).drop(columns=['tic']).stack(level='Ticker', future_stack=True)\n",
        "            data_df.reset_index(inplace=True)\n",
        "            data_df.columns.name = ''\n",
        "\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(columns={'Ticker': 'Tic', 'Adj Close': 'Adjcp'}, inplace=True)\n",
        "            data_df.rename(columns={col: col.lower() for col in data_df.columns}, inplace=True)\n",
        "\n",
        "            columns = [\n",
        "                \"date\",\n",
        "                \"tic\",\n",
        "                \"open\",\n",
        "                \"high\",\n",
        "                \"low\",\n",
        "                \"close\",\n",
        "                \"adjcp\",\n",
        "                \"volume\",\n",
        "            ]\n",
        "\n",
        "            data_df = data_df[columns]\n",
        "            # use adjusted close price instead of close price\n",
        "            data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "            # drop the adjusted close price column\n",
        "            data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "YhIyXmfQ8EAS"
      },
      "outputs": [],
      "source": [
        "#@title fix_daily_index\n",
        "\n",
        "def make_daily_index(data_df, date_column='date', new_index_name='date_index'):\n",
        "    # Get unique dates and create a mapping to daily indices\n",
        "    total_dates = data_df[date_column].unique()\n",
        "    date_to_index = {date: idx for idx, date in enumerate(sorted(total_dates))}\n",
        "    return data_df[date_column].map(date_to_index)\n",
        "\n",
        "def set_daily_index(data_df, date_column='date', new_index_name='date_index'):\n",
        "    \"\"\"\n",
        "    Constructs a daily index from unique dates in the specified column.\n",
        "\n",
        "    Parameters:\n",
        "        data_df (pd.DataFrame): The input DataFrame.\n",
        "        date_column (str): The name of the column containing dates.\n",
        "        new_index_name (str): The name for the new index.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with a daily index.\n",
        "    \"\"\"\n",
        "\n",
        "    # Map dates to daily indices and set as index\n",
        "    data_df[new_index_name] = make_daily_index(data_df, date_column='date', new_index_name='date_index')\n",
        "\n",
        "    data_df.set_index(new_index_name, inplace=True)\n",
        "    data_df.index.name = ''  # Remove the index name for simplicity\n",
        "\n",
        "    return data_df\n",
        "\n",
        "def fix_daily_index(df):\n",
        "    if df.index.name == 'date':\n",
        "        df.reset_index(inplace=True)\n",
        "\n",
        "    daily_index = make_daily_index(df, date_column='date', new_index_name='date_index')\n",
        "    if (df.index.values != daily_index.values).any():\n",
        "\n",
        "        df.index = daily_index\n",
        "        df.index.name = ''\n",
        "\n",
        "    return df\n",
        "\n",
        "# trade = fix_daily_index(trade)\n",
        "# trade.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "GQ6BIJxbwuVh"
      },
      "outputs": [],
      "source": [
        "#@title get dataset name\n",
        "\n",
        "def get_quarterly_dataset_name(prefix, train_start_date, val_start_date, test_start_date):\n",
        "    get_quarter = lambda date: f'Q{(date.month - 1) // 3 + 1}'\n",
        "\n",
        "    val_quarter = get_quarter(val_start_date)\n",
        "    test_quarter = get_quarter(test_start_date)\n",
        "\n",
        "    # Extract year and month\n",
        "    train_start = f\"{train_start_date.year}-{train_start_date.month:02}\"\n",
        "    val_start = f\"{val_start_date.year}\"\n",
        "    test_start = f\"{test_start_date.year}\"\n",
        "\n",
        "    # Construct the dataset name\n",
        "    dataset_name = f\"{prefix} | {train_start} | {val_start} {val_quarter} | {test_start} {test_quarter}\"\n",
        "\n",
        "    return dataset_name\n",
        "\n",
        "def get_yearly_dataset_name(prefix, train_start, test_start, test_end):\n",
        "    # Extract year and month\n",
        "    train_start_str = f\"{train_start.year}-{train_start.month:02}\"\n",
        "    test_start_str = f\"{test_start.year}-{test_start.month:02}\"\n",
        "    test_end_str = f\"{test_end.year}-{test_end.month:02}\"\n",
        "\n",
        "    # Construct the dataset name\n",
        "    dataset_name = f\"{prefix} | {train_start_str} | {test_start_str} | {test_end_str}\"\n",
        "    return dataset_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "TOfz3JlX-oG5"
      },
      "outputs": [],
      "source": [
        "#@title add_dataset\n",
        "\n",
        "def add_dataset(stock_index_name, train_df, test_df):\n",
        "    if 'datasets' not in globals():\n",
        "        global datasets\n",
        "        datasets = {}\n",
        "\n",
        "    # Ensure datetime format\n",
        "    if 'date' in train_df.columns:\n",
        "        train_df.set_index('date', inplace=True)\n",
        "    train_df.index = pd.to_datetime(train_df.index)\n",
        "\n",
        "    if 'date' in test_df.columns:\n",
        "        test_df.set_index('date', inplace=True)\n",
        "    test_df.index = pd.to_datetime(test_df.index)\n",
        "\n",
        "    train_start_date = train_df.index[0]\n",
        "    test_start_date = test_df.index[0]\n",
        "    test_end_date = test_df.index[-1]\n",
        "\n",
        "    dataset_name = get_yearly_dataset_name(\n",
        "        stock_index_name,\n",
        "        train_start_date, test_start_date, test_end_date\n",
        "    )\n",
        "\n",
        "    train_df.reset_index(inplace=True)\n",
        "    test_df.reset_index(inplace=True)\n",
        "\n",
        "    train_df = set_daily_index(train_df)\n",
        "    test_df = set_daily_index(test_df)\n",
        "\n",
        "    ticker_list = train_df.tic.unique().tolist()\n",
        "\n",
        "    datasets[dataset_name] = {\n",
        "        'train': train_df,\n",
        "        'test': test_df,\n",
        "        'metadata': dict(\n",
        "            stock_index_name = stock_index_name,\n",
        "            train_start_date = train_start_date,\n",
        "            test_start_date = test_start_date,\n",
        "            test_end_date = test_end_date,\n",
        "            num_tickers = len(ticker_list),\n",
        "            ticker_list = ticker_list,\n",
        "        )\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWUph5lzrTUS"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op7oS8Jw1pgx"
      },
      "source": [
        "## DATA: DOW-30 (rolling yearly windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "L9_FOjg-qLA1"
      },
      "outputs": [],
      "source": [
        "#@title download full data\n",
        "%%capture\n",
        "\n",
        "min_test_start_year = 2020\n",
        "max_test_start_year = 2025\n",
        "\n",
        "train_years_count = 10\n",
        "test_years_count = 1.5\n",
        "\n",
        "min_date = \\\n",
        "    pd.Timestamp(year=min_test_start_year, month=1, day=1) - \\\n",
        "    pd.Timedelta(days=int(train_years_count * 365.2425))\n",
        "\n",
        "max_date = \\\n",
        "    pd.Timestamp(year=max_test_start_year, month=1, day=1) + \\\n",
        "    pd.Timedelta(days=int(test_years_count * 365.2425))\n",
        "\n",
        "data_df = YahooDownloader(\n",
        "    start_date=min_date,\n",
        "    end_date=max_date,\n",
        "    ticker_list=config_tickers.DOW_30_TICKER\n",
        ").fetch_data()\n",
        "\n",
        "data_df['date'] = pd.to_datetime(data_df['date'])\n",
        "\n",
        "# clip max year w.r.t. to available data\n",
        "max_data_date = data_df['date'].max()\n",
        "max_test_start_year = min(max_test_start_year, max_data_date.year)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "UKKGaOBO6XWM",
        "outputId": "9effd4bc-6407-4faf-a411-c68070a56ac7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame:  (3767, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "preprocessed_data_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e54e3c4b-1730-484b-849d-0bd36a772202\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.447412</td>\n",
              "      <td>493729600.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.46875</td>\n",
              "      <td>6.43722</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.447412</td>\n",
              "      <td>6.447412</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>40.915905</td>\n",
              "      <td>5277400.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.46875</td>\n",
              "      <td>6.43722</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>40.915905</td>\n",
              "      <td>40.915905</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>AXP</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>32.906178</td>\n",
              "      <td>6894300.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.46875</td>\n",
              "      <td>6.43722</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>32.906178</td>\n",
              "      <td>32.906178</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>BA</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.777542</td>\n",
              "      <td>6186700.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.46875</td>\n",
              "      <td>6.43722</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>43.777542</td>\n",
              "      <td>43.777542</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>CAT</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>39.883915</td>\n",
              "      <td>7325600.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.46875</td>\n",
              "      <td>6.43722</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.883915</td>\n",
              "      <td>39.883915</td>\n",
              "      <td>21.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e54e3c4b-1730-484b-849d-0bd36a772202')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e54e3c4b-1730-484b-849d-0bd36a772202 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e54e3c4b-1730-484b-849d-0bd36a772202');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1fc30f80-7f76-470b-835a-b9d2ff9943ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fc30f80-7f76-470b-835a-b9d2ff9943ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1fc30f80-7f76-470b-835a-b9d2ff9943ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         date   tic       open       high        low      close       volume  \\\n",
              "0  2010-01-04  AAPL   7.622500   7.660714   7.585000   6.447412  493729600.0   \n",
              "1  2010-01-04  AMGN  56.630001  57.869999  56.560001  40.915905    5277400.0   \n",
              "2  2010-01-04   AXP  40.810001  41.099998  40.389999  32.906178    6894300.0   \n",
              "3  2010-01-04    BA  55.720001  56.389999  54.799999  43.777542    6186700.0   \n",
              "4  2010-01-04   CAT  57.650002  59.189999  57.509998  39.883915    7325600.0   \n",
              "\n",
              "   day  macd  boll_ub  boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
              "0    0   0.0  6.46875  6.43722   100.0  66.666667  100.0      6.447412   \n",
              "1    0   0.0  6.46875  6.43722   100.0  66.666667  100.0     40.915905   \n",
              "2    0   0.0  6.46875  6.43722   100.0  66.666667  100.0     32.906178   \n",
              "3    0   0.0  6.46875  6.43722   100.0  66.666667  100.0     43.777542   \n",
              "4    0   0.0  6.46875  6.43722   100.0  66.666667  100.0     39.883915   \n",
              "\n",
              "   close_60_sma    vix  turbulence  \n",
              "0      6.447412  21.68         0.0  \n",
              "1     40.915905  21.68         0.0  \n",
              "2     32.906178  21.68         0.0  \n",
              "3     43.777542  21.68         0.0  \n",
              "4     39.883915  21.68         0.0  "
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title add features\n",
        "\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
        "\n",
        "fe = FeatureEngineer(use_turbulence=True, use_vix=True)\n",
        "preprocessed_data_df = fe.preprocess_data(data_df.astype({'date': str}))\n",
        "preprocessed_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tg4lrFhWStNP"
      },
      "outputs": [],
      "source": [
        "#@title get_train_test_split\n",
        "def get_train_test_split(data_df, train_years_count, test_years_count, test_start_year):\n",
        "    test_start_date = pd.Timestamp(year=test_start_year, month=1, day=1)\n",
        "\n",
        "    train_start_date = \\\n",
        "        test_start_date - \\\n",
        "        pd.Timedelta(days=int(train_years_count * 365.2425))\n",
        "\n",
        "    test_end_date = \\\n",
        "        test_start_date + \\\n",
        "        pd.Timedelta(days=int(test_years_count * 365.2425))\n",
        "\n",
        "    # Filter using the 'date' column\n",
        "    train_df = data_df[(data_df['date'] >= train_start_date) & (data_df['date'] < test_start_date)]\n",
        "    test_df = data_df[(data_df['date'] >= test_start_date) & (data_df['date'] < test_end_date)]\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBiw3TS56LfN",
        "outputId": "f816d4f4-50e7-4d67-89d4-b314dd0251b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train start: 2010-01-04 00:00:00, Train end: 2019-12-31 00:00:00\n",
            "Test start: 2020-01-02 00:00:00, Test end: 2021-06-30 00:00:00\n",
            "\n",
            "Train start: 2011-01-03 00:00:00, Train end: 2020-12-31 00:00:00\n",
            "Test start: 2021-01-04 00:00:00, Test end: 2022-07-01 00:00:00\n",
            "\n",
            "Train start: 2012-01-03 00:00:00, Train end: 2021-12-31 00:00:00\n",
            "Test start: 2022-01-03 00:00:00, Test end: 2023-06-30 00:00:00\n",
            "\n",
            "Train start: 2013-01-02 00:00:00, Train end: 2022-12-30 00:00:00\n",
            "Test start: 2023-01-03 00:00:00, Test end: 2024-06-28 00:00:00\n",
            "\n",
            "Train start: 2014-01-02 00:00:00, Train end: 2023-12-29 00:00:00\n",
            "Test start: 2024-01-02 00:00:00, Test end: 2024-12-19 00:00:00\n",
            "\n",
            "DOW_30 | 2010-01 | 2020-01 | 2021-06\n",
            "DOW_30 | 2011-01 | 2021-01 | 2022-07\n",
            "DOW_30 | 2012-01 | 2022-01 | 2023-06\n",
            "DOW_30 | 2013-01 | 2023-01 | 2024-06\n",
            "DOW_30 | 2014-01 | 2024-01 | 2024-12\n"
          ]
        }
      ],
      "source": [
        "preprocessed_data_df['date'] = pd.to_datetime(preprocessed_data_df['date'])\n",
        "\n",
        "for test_start_year in range(min_test_start_year, max_test_start_year + 1):\n",
        "    train_df, test_df = get_train_test_split(\n",
        "        # data_df,\n",
        "        preprocessed_data_df,\n",
        "\n",
        "        train_years_count, test_years_count, test_start_year\n",
        "    )\n",
        "\n",
        "    add_dataset('DOW_30', train_df, test_df)\n",
        "\n",
        "    print(f\"Train start: {train_df['date'].min()}, Train end: {train_df['date'].max()}\")\n",
        "    print(f\"Test start: {test_df['date'].min()}, Test end: {test_df['date'].max()}\")\n",
        "    print()\n",
        "\n",
        "    # break\n",
        "\n",
        "print(*list(datasets.keys()), sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHIfVohUTAsG"
      },
      "source": [
        "## DATA: DOW-30 (quarterly train/val/test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y3m7Yc3rTILs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title download\n",
        "\n",
        "train_start_date = '2019-01-01'\n",
        "max_test_end_date = '2020-08-01'\n",
        "\n",
        "########################\n",
        "\n",
        "data_df = YahooDownloader(\n",
        "    start_date= pd.Timestamp(train_start_date),\n",
        "    end_date= pd.Timestamp(max_test_end_date),\n",
        "    ticker_list=config_tickers.DOW_30_TICKER\n",
        ").fetch_data()\n",
        "\n",
        "data_df['date'] = pd.to_datetime(data_df['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ9IFLWeTILs",
        "outputId": "021b4d70-b127-4f1c-ad08-7d646f5bae6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (398, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "#@title add features\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
        "\n",
        "fe = FeatureEngineer(use_turbulence=True, use_vix=True)\n",
        "preproc_df = fe.preprocess_data(data_df.astype({'date': str}))\n",
        "preproc_df['date'] = pd.to_datetime(preproc_df['date'])\n",
        "# preproc_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SSetOu0ejt2w"
      },
      "outputs": [],
      "source": [
        "#@title generate_quarterly_date_ranges\n",
        "from calendar import monthrange\n",
        "\n",
        "min_test_start_date = '2016-01-01'\n",
        "\n",
        "def generate_quarterly_date_ranges(train_start_date, min_test_start_date, max_test_end_date, preproc_df, return_strings=False):\n",
        "    is_quarter_start = lambda date: date.month in [1, 4, 7, 10] and date.day == 1\n",
        "\n",
        "    min_test_start_date = pd.Timestamp(min_test_start_date)\n",
        "    train_start_date = pd.Timestamp(train_start_date)\n",
        "    max_test_end_date = pd.Timestamp(max_test_end_date)\n",
        "\n",
        "    assert is_quarter_start(train_start_date), f\"train_start_date {train_start_date} is not a quarter start date.\"\n",
        "    assert is_quarter_start(min_test_start_date), f\"min_test_start_date {min_test_start_date} is not a quarter start date.\"\n",
        "\n",
        "    assert max_test_end_date + pd.DateOffset(month=3) <= preproc_df['date'].max()\n",
        "    assert train_start_date + pd.DateOffset(days=1) >= preproc_df['date'].min()\n",
        "\n",
        "    test_start_date = min_test_start_date\n",
        "    date_ranges = []\n",
        "    while True:\n",
        "        val_start_date = test_start_date - pd.DateOffset(months=3)\n",
        "        test_end_date = test_start_date + pd.DateOffset(months=3)\n",
        "\n",
        "        if test_end_date > max_test_end_date:\n",
        "            break\n",
        "\n",
        "        date_range = (dict(\n",
        "            train_start_date = train_start_date,\n",
        "            val_start_date = val_start_date,\n",
        "            test_start_date = test_start_date,\n",
        "            test_end_date = test_end_date,\n",
        "        ))\n",
        "\n",
        "        if return_strings:\n",
        "            date_range = {k: str(v) for k, v in date_range.items()}\n",
        "\n",
        "        date_ranges.append(date_range)\n",
        "\n",
        "        test_start_date = test_end_date\n",
        "\n",
        "\n",
        "    return date_ranges\n",
        "\n",
        "date_ranges = generate_quarterly_date_ranges(train_start_date, min_test_start_date, max_test_end_date, preproc_df)\n",
        "# date_ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "S8GdHjZWTcHu"
      },
      "outputs": [],
      "source": [
        "def subset_date_range(df, start_date, end_date):\n",
        "    df = df[(df['date'] >= start_date) & (df['date'] < end_date)]\n",
        "    df = fix_daily_index(df)\n",
        "    return df\n",
        "\n",
        "quarterly_dataset = []\n",
        "for date_range in date_ranges:\n",
        "    train_df, val_df, test_df = (\n",
        "        subset_date_range(preproc_df, date_range['train_start_date'], date_range['val_start_date']),\n",
        "        subset_date_range(preproc_df, date_range['val_start_date'], date_range['test_start_date']),\n",
        "        subset_date_range(preproc_df, date_range['test_start_date'], date_range['test_end_date']),\n",
        "    )\n",
        "    quarterly_dataset.append((train_df, val_df, test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiWaQLQ7rSs5"
      },
      "source": [
        "# Train SB3 models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BZTsxX0tkDZ"
      },
      "source": [
        "## Init config & dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knEaNgSKQ5rW"
      },
      "outputs": [],
      "source": [
        "period_idx = -1\n",
        "train, val, test = quarterly_dataset[period_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jpp0ZrVJryvM"
      },
      "outputs": [],
      "source": [
        "config = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "I0Tvb-qbbpGT"
      },
      "outputs": [],
      "source": [
        "#@title Config: dataset\n",
        "\n",
        "# config.update(dict(\n",
        "#     # dataset_name =  'DOW_30 | 2009-01 | 2020-07 | 2021-10',\n",
        "#     dataset_name =  'DOW-30 (FinRL 2021) | 2009-01 | 2020-07 | 2021-10',\n",
        "# ))\n",
        "\n",
        "# dataset = datasets[config['dataset_name']]\n",
        "# config.update(dataset['metadata'])\n",
        "# train = dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BrmZizKHFZZE"
      },
      "outputs": [],
      "source": [
        "#@title Get reference price interval\n",
        "\n",
        "# %%capture\n",
        "\n",
        "# REFERENCE_PRICE_END_DATE = '2024-12-21'\n",
        "# REFERNCE_PRICE_WINDOW_DAYS = 30\n",
        "\n",
        "# ref_price_start_date = pd.Timestamp(REFERENCE_PRICE_END_DATE) - pd.Timedelta(days=REFERNCE_PRICE_WINDOW_DAYS)\n",
        "# ref_price_df = YahooDownloader(\n",
        "#         start_date=ref_price_start_date,\n",
        "#         end_date=REFERENCE_PRICE_END_DATE,\n",
        "#         ticker_list=train.tic.unique().tolist(),\n",
        "#         # ticker_list=config_tickers.DOW_30_TICKER\n",
        "#     ).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "hE7nHKrYos_t"
      },
      "outputs": [],
      "source": [
        "#@title Calculate fee percent based on average price for past N days\n",
        "\n",
        "def cost_pct_from_avg_price(df, cost_abs, price_avg_days, verbose=False):\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    avg_price_dict = {}\n",
        "    for tic, _df in df.groupby('tic'):\n",
        "        last_date = _df['date'].max()\n",
        "        _df = _df[_df.date >= last_date - pd.Timedelta(days=price_avg_days)]\n",
        "        avg_price = ((_df.high + _df.low) / 2).mean()\n",
        "        avg_price_dict.update({tic: avg_price})\n",
        "\n",
        "    avg_price_df = pd.DataFrame(avg_price_dict, index=[f'cost_avg']).T\n",
        "    cost_pct_df = (cost_abs / avg_price_df).rename(columns={'cost_avg': 'cost_pct'})\n",
        "\n",
        "    if verbose:\n",
        "        display(avg_price_df.head())\n",
        "        print()\n",
        "        display(cost_pct_df.head())\n",
        "\n",
        "    return cost_pct_df.values.flatten().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wzshngk6xkwR"
      },
      "outputs": [],
      "source": [
        "# COST_ABS = 2.5\n",
        "# COST_PCT = cost_pct_from_avg_price(\n",
        "#     df=ref_price_df,\n",
        "#     cost_abs=COST_ABS,\n",
        "#     price_avg_days=REFERNCE_PRICE_WINDOW_DAYS,\n",
        "#     verbose=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1dBLCHvFYOU",
        "outputId": "e3a82ab7-55ae-4727-bf46-dae69c1f741a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['initial_amount', 'cost_abs', 'cost_pct'])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# config.update({\n",
        "#     'env_params': {\n",
        "#         'initial_amount': 50000,\n",
        "\n",
        "#         # 'cost_abs': COST_ABS,\n",
        "#         # 'cost_pct': COST_PCT\n",
        "\n",
        "#         'cost_abs': None,\n",
        "#         'cost_pct': 0.001\n",
        "#     }\n",
        "# })\n",
        "\n",
        "\n",
        "config.update({\n",
        "    'initial_amount': 50000,\n",
        "\n",
        "    # 'cost_abs': COST_ABS,\n",
        "    # 'cost_pct': COST_PCT\n",
        "\n",
        "    'cost_abs': None,\n",
        "    'cost_pct': 0.001\n",
        "})\n",
        "\n",
        "config.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DFUBgSZT5-a",
        "outputId": "0eefa3a5-8fb2-47f6-e5dc-5238be955cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 29, State Space: 291\n"
          ]
        }
      ],
      "source": [
        "#@title Init env\n",
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "\n",
        "cost_pct = config['cost_pct']\n",
        "if isinstance(cost_pct, list):\n",
        "    assert len(cost_pct) == stock_dimension\n",
        "    buy_cost_pct = sell_cost_pct = cost_pct\n",
        "elif isinstance(cost_pct, (int, float)):\n",
        "    buy_cost_pct = sell_cost_pct = [ config['cost_pct'] ] * stock_dimension\n",
        "else:\n",
        "    raise ValueError\n",
        "\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": config['initial_amount'],\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_pct,\n",
        "    \"sell_cost_pct\": sell_cost_pct,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "\n",
        "    \"print_verbosity\": 1,\n",
        "    \"make_plots\": True\n",
        "}\n",
        "\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgz76x4xsi2A"
      },
      "source": [
        "## Init wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H0-AyktELpI"
      },
      "outputs": [],
      "source": [
        "# !rm -rf ./*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp-ffs3gWpX1",
        "outputId": "996fe680-b363-4848-ab2d-cd7843d0967d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241223_155329-vtr6xfa3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/overfit1010/finrl-dt-replicate/runs/vtr6xfa3' target=\"_blank\">DOW-30 (FinRL 2021) | 2009-01 | 2020-07 | 2021-10 | uKSHX</a></strong> to <a href='https://wandb.ai/overfit1010/finrl-dt-replicate' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/overfit1010/finrl-dt-replicate/runs/vtr6xfa3' target=\"_blank\">https://wandb.ai/overfit1010/finrl-dt-replicate/runs/vtr6xfa3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title init run\n",
        "import wandb\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_run_name(prefix, n=5):\n",
        "    random_str = ''.join(random.choices(string.ascii_letters + string.digits, k=n))\n",
        "    return f\"{prefix} | {random_str}\"\n",
        "\n",
        "\n",
        "wandb.finish()\n",
        "wandb.init(\n",
        "    project=PROJECT,\n",
        "    name=generate_run_name(config['dataset_name'])\n",
        ")\n",
        "\n",
        "wandb.config.update(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jF0Xbv9f631H"
      },
      "outputs": [],
      "source": [
        "#@title update_artifact\n",
        "\n",
        "def update_artifact(folder_path, name_prefix, type):\n",
        "    \"\"\"\n",
        "    Create or update a W&B artifact consisting of a folder.\n",
        "\n",
        "    Args:\n",
        "        run: The current W&B run.\n",
        "        folder_path (str): Path to the folder to upload.\n",
        "        artifact_name (str): Name of the artifact.\n",
        "        artifact_type (str): Type of the artifact.\n",
        "    \"\"\"\n",
        "    run = wandb.run\n",
        "    artifact_name = f'{name_prefix}-{wandb.run.id}'\n",
        "\n",
        "    # Create a new artifact\n",
        "    artifact = wandb.Artifact(name=artifact_name, type=type)\n",
        "\n",
        "    # Add the folder to the artifact\n",
        "    artifact.add_dir(folder_path)\n",
        "\n",
        "    # Log the artifact to W&B\n",
        "    run.log_artifact(artifact)\n",
        "    print(f\"Artifact '{artifact_name}' has been updated and uploaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B-a7jHoxrb3Q"
      },
      "outputs": [],
      "source": [
        "#@title update_model_artifacts\n",
        "\n",
        "def update_model_artifacts():\n",
        "    update_artifact(\n",
        "        folder_path = RESULTS_DIR,\n",
        "        name_prefix = 'results',\n",
        "        type = 'results'\n",
        "    )\n",
        "\n",
        "    update_artifact(\n",
        "        folder_path = TRAINED_MODEL_DIR,\n",
        "        name_prefix = 'trained_models',\n",
        "        type = 'trained_models'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prm8SfPo7CJY",
        "outputId": "9eb3c05b-4a0b-4322-fc16-39e5e471ec23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./dataset)... Done. 0.1s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artifact 'dataset-vtr6xfa3' has been updated and uploaded.\n"
          ]
        }
      ],
      "source": [
        "#@title update_dataset_artifact\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "DATASET_DIR = Path('./dataset')\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "dataset = datasets[config['dataset_name']]\n",
        "dataset['train'].to_csv(DATASET_DIR / 'train_data.csv')\n",
        "dataset['test'].to_csv(DATASET_DIR / 'test_data.csv')\n",
        "\n",
        "update_artifact(\n",
        "    folder_path = DATASET_DIR,\n",
        "    name_prefix = 'dataset',\n",
        "    type = 'dataset'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqc-9r54tuXG"
      },
      "source": [
        "## Train FinRL models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4IS_7kYSEFo"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir ./results/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZNeIlnJKGza"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t0-3fjeCG_GJ"
      },
      "outputs": [],
      "source": [
        "#@title Define metric functions\n",
        "\n",
        "def calculate_mdd(asset_values):\n",
        "    \"\"\"\n",
        "    Calculate the Maximum Drawdown (MDD) of a portfolio.\n",
        "    \"\"\"\n",
        "    running_max = asset_values.cummax()\n",
        "    drawdown = (asset_values - running_max) / running_max\n",
        "    mdd = drawdown.min() * 100  # Convert to percentage\n",
        "    return mdd\n",
        "\n",
        "def calculate_sharpe_ratio(asset_values, risk_free_rate=0.0):\n",
        "    \"\"\"\n",
        "    Calculate the Sharpe Ratio of a portfolio.\n",
        "    \"\"\"\n",
        "    # Calculate daily returns\n",
        "    returns = asset_values.pct_change().dropna()\n",
        "    excess_returns = returns - risk_free_rate / 252  # Assuming 252 trading days\n",
        "\n",
        "    if excess_returns.std() == 0:\n",
        "        return 0.0\n",
        "    sharpe_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252)  # Annualized\n",
        "    return sharpe_ratio\n",
        "\n",
        "def calculate_annualized_return(asset_values):\n",
        "    \"\"\"\n",
        "    Calculate the annualized return of a portfolio.\n",
        "    \"\"\"\n",
        "    # Assume `asset_values` is indexed by date or trading day\n",
        "    total_return = (asset_values.iloc[-1] / asset_values.iloc[0] - 1) * 100\n",
        "    num_days = (asset_values.index[-1] - asset_values.index[0]).days\n",
        "    annualized_return = (1 + total_return) ** (365 / num_days) - 1\n",
        "    return annualized_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "frdIBaq0pqe2"
      },
      "outputs": [],
      "source": [
        "#@title get metrics\n",
        "import wandb\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "def get_account_value_metrics(account_values: List[pd.DataFrame, pd.Series, np.array]):\n",
        "    \"\"\"\n",
        "    If DataFrame then should contain two columns - 'date' and name of algo, e.g. 'a2c'.\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(account_values, pd.DataFrame):\n",
        "        assert isinstance(account_values, pd.DataFrame)\n",
        "        if 'date' not in account_values.columns:\n",
        "            if account_values.index.name == 'date':\n",
        "                account_values.reset_index(inplace=True)\n",
        "            else:\n",
        "                raise ValueError(\"should contain 'date' column or index\")\n",
        "        account_values = account_values.dropna().set_index('date').iloc[:, 0]\n",
        "    elif isinstance(account_values, np.ndarray):\n",
        "        account_values = pd.Series(account_values)\n",
        "\n",
        "    sharpe = calculate_sharpe_ratio(account_values)\n",
        "    mdd = calculate_mdd(account_values)\n",
        "    cum_ret = (account_values.iloc[-1] - account_values.iloc[0]) / account_values.iloc[0] * 100\n",
        "    # num_days = (account_values.index.max() - account_values.index.min()).days\n",
        "    num_days = len(account_values)\n",
        "    ann_ret = ((1 + cum_ret / 100) ** (365 / num_days) - 1) * 100\n",
        "\n",
        "    return {\n",
        "            f'sharpe_ratio': sharpe,\n",
        "            f'mdd': mdd,\n",
        "            f'ann_return': ann_ret,\n",
        "            f'cum_return': cum_ret,\n",
        "        }\n",
        "\n",
        "def get_env_metrics(env):\n",
        "    end_total_asset = env.state[0] + sum(\n",
        "        np.array(env.state[1 : (env.stock_dim + 1)])\n",
        "        * np.array(env.state[(env.stock_dim + 1) : (env.stock_dim * 2 + 1)])\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'begin_total_asset': env.asset_memory[0],\n",
        "        'end_total_asset': end_total_asset,\n",
        "        'total_cost': env.cost,\n",
        "        'total_trades': env.trades,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hldi--6OyGre"
      },
      "outputs": [],
      "source": [
        "#@title log_metrics\n",
        "\n",
        "def log_metrics_to_wandb(metrics, model_name, split_label, step=None):\n",
        "    print(f'log_metrics for {model_name}')\n",
        "    assert model_name in ['a2c', 'ddpg', 'sac', 'ppo', 'td3', 'best_model', 'chosen_model']\n",
        "\n",
        "    rename_metrics = lambda model_name: {\n",
        "        f\"{key}/{model_name}\": value for key, value in metrics.items()\n",
        "    }\n",
        "\n",
        "    renamed_metrics = rename_metrics(model_name)\n",
        "    wandb.log({split_label: renamed_metrics}, step=step)\n",
        "    # wandb.run.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ORwxkwBJkCyG"
      },
      "outputs": [],
      "source": [
        "#@title WandbLoggerCallback\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class WandbLoggerCallback(BaseCallback):\n",
        "    def __init__(self, model_name, split_label, verbose=0):\n",
        "        super(WandbLoggerCallback, self).__init__(verbose)\n",
        "\n",
        "        self.split_label = split_label\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        env = self.training_env.envs[0]\n",
        "\n",
        "        # Check if the episode is terminal\n",
        "        env.terminal = env.day >= len(env.df.index.unique()) - 1\n",
        "        if env.terminal:\n",
        "            df_account_value = pd.DataFrame({\n",
        "                self.model_name: env.asset_memory,\n",
        "                'date': env.date_memory\n",
        "            })\n",
        "\n",
        "            # Compute metrics\n",
        "            metrics = get_account_value_metrics(df_account_value)\n",
        "            # env_metrics = get_env_metrics(env)\n",
        "            # metrics.update(env_metrics)\n",
        "\n",
        "            # Log current model metrics\n",
        "            log_metrics_to_wandb(metrics, self.model_name, self.split_label)\n",
        "\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z-oWCpLLcqYJ"
      },
      "outputs": [],
      "source": [
        "#@title Custom DRLAgent (w/ wandb callback)\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent, TensorboardCallback\n",
        "from stable_baselines3.common.callbacks import CallbackList\n",
        "import wandb\n",
        "\n",
        "class DRLAgent(DRLAgent):\n",
        "    @staticmethod\n",
        "    def train_model(\n",
        "        model,\n",
        "        tb_log_name,\n",
        "        total_timesteps=5000,\n",
        "    ):\n",
        "        # Ensure TensorboardCallback is always included\n",
        "        tensorboard_callback = TensorboardCallback()\n",
        "\n",
        "        # Initialize default callbacks\n",
        "        wandb_logger_callback = WandbLoggerCallback(model_name=tb_log_name, split_label='train', verbose=1)\n",
        "\n",
        "        # Combine all callbacks (always include Tensorboard, SharpeRatio, and MaxSharpeRatio by default)\n",
        "        callbacks_to_use = [\n",
        "            tensorboard_callback,\n",
        "            wandb_logger_callback,\n",
        "        ]\n",
        "\n",
        "        # Wrap all callbacks into a CallbackList\n",
        "        combined_callback = CallbackList(callbacks_to_use)\n",
        "\n",
        "        # Train the model with the combined callbacks\n",
        "        model = model.learn(\n",
        "            total_timesteps=total_timesteps,\n",
        "            tb_log_name=tb_log_name,\n",
        "            callback=combined_callback,\n",
        "        )\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyvEieUxQvSA"
      },
      "outputs": [],
      "source": [
        "#@title train models\n",
        "\n",
        "check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "\n",
        "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
        "\n",
        "# if_using_a2c = True\n",
        "if_using_a2c = False\n",
        "\n",
        "# if_using_ddpg = True\n",
        "if_using_ddpg = False\n",
        "\n",
        "# if_using_ppo = True\n",
        "if_using_ppo = False\n",
        "\n",
        "# if_using_td3 = True\n",
        "if_using_td3 = False\n",
        "\n",
        "# if_using_sac = True\n",
        "if_using_sac = False\n",
        "\n",
        "if if_using_a2c:\n",
        "    print(\"training A2C agent\")\n",
        "    agent = DRLAgent(env = env_train)\n",
        "    model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "    # set up logger\n",
        "    tmp_path = RESULTS_DIR + '/a2c'\n",
        "    !rm -rf {tmp_path}/*\n",
        "    new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "    # Set new logger\n",
        "    model_a2c.set_logger(new_logger_a2c)\n",
        "\n",
        "    trained_a2c = agent.train_model(model=model_a2c,\n",
        "                                    tb_log_name='a2c',\n",
        "                                    # total_timesteps=50_000,\n",
        "                                    total_timesteps=3500,\n",
        "                                    ) if if_using_a2c else None\n",
        "\n",
        "    trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n",
        "    update_model_artifacts()\n",
        "\n",
        "if if_using_ddpg:\n",
        "    print(\"training DDPG agent\")\n",
        "    agent = DRLAgent(env = env_train)\n",
        "    model_ddpg = agent.get_model(\"ddpg\")\n",
        "\n",
        "    # set up logger\n",
        "    tmp_path = RESULTS_DIR + '/ddpg'\n",
        "    !rm -rf {tmp_path}/*\n",
        "    new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "    # Set new logger\n",
        "    model_ddpg.set_logger(new_logger_ddpg)\n",
        "\n",
        "    trained_ddpg = agent.train_model(model=model_ddpg,\n",
        "                             tb_log_name='ddpg',\n",
        "                            #  total_timesteps=50_000,\n",
        "                             total_timesteps=3500\n",
        "                            ) if if_using_ddpg else None\n",
        "\n",
        "    trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n",
        "    update_model_artifacts()\n",
        "\n",
        "if if_using_td3:\n",
        "    print(\"training TD3 agent\")\n",
        "    agent = DRLAgent(env = env_train)\n",
        "    TD3_PARAMS = {\"batch_size\": 100,\n",
        "                \"buffer_size\": 1000000,\n",
        "                \"learning_rate\": 0.001}\n",
        "\n",
        "    model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
        "\n",
        "    # set up logger\n",
        "    tmp_path = RESULTS_DIR + '/td3'\n",
        "    !rm -rf {tmp_path}/*\n",
        "    new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "    # Set new logger\n",
        "    model_td3.set_logger(new_logger_td3)\n",
        "\n",
        "    trained_td3 = agent.train_model(model=model_td3,\n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=50000) if if_using_td3 else None\n",
        "\n",
        "    trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n",
        "    update_model_artifacts()\n",
        "\n",
        "if if_using_sac:\n",
        "    print(\"training SAC agent\")\n",
        "    agent = DRLAgent(env = env_train)\n",
        "    SAC_PARAMS = {\n",
        "        \"batch_size\": 128,\n",
        "        \"buffer_size\": 100000,\n",
        "        \"learning_rate\": 0.0001,\n",
        "        \"learning_starts\": 100,\n",
        "        \"ent_coef\": \"auto_0.1\",\n",
        "    }\n",
        "\n",
        "    model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
        "\n",
        "    # set up logger\n",
        "    tmp_path = RESULTS_DIR + '/sac'\n",
        "    !rm -rf {tmp_path}/*\n",
        "    new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "    # Set new logger\n",
        "    model_sac.set_logger(new_logger_sac)\n",
        "\n",
        "    trained_sac = agent.train_model(model=model_sac,\n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=70000) if if_using_sac else None\n",
        "    trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None\n",
        "    update_model_artifacts()\n",
        "\n",
        "if if_using_ppo:\n",
        "    agent = DRLAgent(env = env_train)\n",
        "    PPO_PARAMS = {\n",
        "        \"n_steps\": 2048,\n",
        "        \"ent_coef\": 0.01,\n",
        "        \"learning_rate\": 0.00025,\n",
        "        \"batch_size\": 128,\n",
        "    }\n",
        "    model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "    # set up logger\n",
        "    tmp_path = RESULTS_DIR + '/ppo'\n",
        "    !rm -rf {tmp_path}/*\n",
        "    new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "    # Set new logger\n",
        "    model_ppo.set_logger(new_logger_ppo)\n",
        "\n",
        "    trained_ppo = agent.train_model(model=model_ppo,\n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=200000) if if_using_ppo else None\n",
        "\n",
        "    trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n",
        "    update_model_artifacts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSosu3u-YIIA"
      },
      "outputs": [],
      "source": [
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqkgvtqPR0y-"
      },
      "source": [
        "# Train RLLib models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HBuGuB06UJwT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install ray[rllib]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "B5HXgTrPXMkU",
        "outputId": "3ce308db-2215-4cc4-8430-1276b321b2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-24 16:51:24,602\tINFO worker.py:1841 -- Started a local Ray instance.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.11.11', ray_version='2.41.0', ray_commit='021baf7dd07db54c2dc23a7490f0604673f8d0d6')"
            ],
            "text/html": [
              "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
              "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
              "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
              "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
              "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
              "    </g>\n",
              "    <defs>\n",
              "        <clipPath id=\"clip0_4338_178347\">\n",
              "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
              "        </clipPath>\n",
              "    </defs>\n",
              "  </svg>\n",
              "</div>\n",
              "\n",
              "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
              "    <tr>\n",
              "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "        <td style=\"text-align: left\"><b>3.11.11</b></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "        <td style=\"text-align: left\"><b>2.41.0</b></td>\n",
              "    </tr>\n",
              "    \n",
              "</table>\n",
              "\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import ray\n",
        "\n",
        "ray.shutdown()\n",
        "ray.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMcMKn8dY-uU"
      },
      "source": [
        "## Train StockTradingEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "Y5AWgHwIR5Rx",
        "outputId": "69173258-185e-4618-d67e-ab8310688e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363 days 00:00:00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        date   tic        open        high         low       close  \\\n",
              "                                                                     \n",
              "0 2019-01-02  AAPL   38.722500   39.712502   38.557499   37.708599   \n",
              "0 2019-01-02  AMGN  192.520004  193.199997  188.949997  159.867599   \n",
              "0 2019-01-02   AXP   93.910004   96.269997   93.769997   87.825096   \n",
              "0 2019-01-02    BA  316.190002  323.950012  313.709991  314.645172   \n",
              "0 2019-01-02   CAT  124.029999  127.879997  123.000000  109.718445   \n",
              "\n",
              "        volume  day  macd    boll_ub    boll_lb  rsi_30     cci_30  dx_30  \\\n",
              "                                                                            \n",
              "0  148158800.0    2   0.0  41.142438  30.518702     0.0 -66.666667  100.0   \n",
              "0    3009100.0    2   0.0  41.142438  30.518702     0.0 -66.666667  100.0   \n",
              "0    4175400.0    2   0.0  41.142438  30.518702     0.0 -66.666667  100.0   \n",
              "0    3292200.0    2   0.0  41.142438  30.518702     0.0 -66.666667  100.0   \n",
              "0    4783200.0    2   0.0  41.142438  30.518702     0.0 -66.666667  100.0   \n",
              "\n",
              "   close_30_sma  close_60_sma        vix  turbulence  \n",
              "                                                      \n",
              "0     37.708599     37.708599  27.540001         0.0  \n",
              "0    159.867599    159.867599  27.540001         0.0  \n",
              "0     87.825096     87.825096  27.540001         0.0  \n",
              "0    314.645172    314.645172  27.540001         0.0  \n",
              "0    109.718445    109.718445  27.540001         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3398dbec-f866-49ee-bdbe-4b4e58e116a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>38.722500</td>\n",
              "      <td>39.712502</td>\n",
              "      <td>38.557499</td>\n",
              "      <td>37.708599</td>\n",
              "      <td>148158800.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.142438</td>\n",
              "      <td>30.518702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>37.708599</td>\n",
              "      <td>37.708599</td>\n",
              "      <td>27.540001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>192.520004</td>\n",
              "      <td>193.199997</td>\n",
              "      <td>188.949997</td>\n",
              "      <td>159.867599</td>\n",
              "      <td>3009100.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.142438</td>\n",
              "      <td>30.518702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>159.867599</td>\n",
              "      <td>159.867599</td>\n",
              "      <td>27.540001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>AXP</td>\n",
              "      <td>93.910004</td>\n",
              "      <td>96.269997</td>\n",
              "      <td>93.769997</td>\n",
              "      <td>87.825096</td>\n",
              "      <td>4175400.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.142438</td>\n",
              "      <td>30.518702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>87.825096</td>\n",
              "      <td>87.825096</td>\n",
              "      <td>27.540001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>BA</td>\n",
              "      <td>316.190002</td>\n",
              "      <td>323.950012</td>\n",
              "      <td>313.709991</td>\n",
              "      <td>314.645172</td>\n",
              "      <td>3292200.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.142438</td>\n",
              "      <td>30.518702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>314.645172</td>\n",
              "      <td>314.645172</td>\n",
              "      <td>27.540001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>CAT</td>\n",
              "      <td>124.029999</td>\n",
              "      <td>127.879997</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>109.718445</td>\n",
              "      <td>4783200.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.142438</td>\n",
              "      <td>30.518702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>109.718445</td>\n",
              "      <td>109.718445</td>\n",
              "      <td>27.540001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3398dbec-f866-49ee-bdbe-4b4e58e116a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3398dbec-f866-49ee-bdbe-4b4e58e116a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3398dbec-f866-49ee-bdbe-4b4e58e116a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a97ebd8-82f5-4d2c-a937-696d22741844\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a97ebd8-82f5-4d2c-a937-696d22741844')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a97ebd8-82f5-4d2c-a937-696d22741844 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 7308,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2019-01-02 00:00:00\",\n        \"max\": \"2019-12-31 00:00:00\",\n        \"num_unique_values\": 252,\n        \"samples\": [\n          \"2019-08-28 00:00:00\",\n          \"2019-01-10 00:00:00\",\n          \"2019-06-12 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"WBA\",\n          \"KO\",\n          \"IBM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.09103164454183,\n        \"min\": 30.546667098999023,\n        \"max\": 446.010009765625,\n        \"num_unique_values\": 6120,\n        \"samples\": [\n          180.13999938964844,\n          123.9800033569336,\n          134.6199951171875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.77646196132243,\n        \"min\": 31.21666717529297,\n        \"max\": 446.010009765625,\n        \"num_unique_values\": 6122,\n        \"samples\": [\n          162.49000549316406,\n          144.75143432617188,\n          55.220001220703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70.39237694909681,\n        \"min\": 30.546667098999023,\n        \"max\": 440.19000244140625,\n        \"num_unique_values\": 6135,\n        \"samples\": [\n          52.060001373291016,\n          35.016666412353516,\n          180.16722106933594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68.62084034380413,\n        \"min\": 28.147199630737305,\n        \"max\": 430.29998779296875,\n        \"num_unique_values\": 7108,\n        \"samples\": [\n          375.3235778808594,\n          148.0753173828125,\n          109.04456329345703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21921241.634458445,\n        \"min\": 467700.0,\n        \"max\": 365248800.0,\n        \"num_unique_values\": 7170,\n        \"samples\": [\n          2839500.0,\n          7416600.0,\n          7442185.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9412918342387717,\n        \"min\": -10.187676277450919,\n        \"max\": 14.47957742330766,\n        \"num_unique_values\": 7280,\n        \"samples\": [\n          1.9931780203043843,\n          0.37551003651151404,\n          -0.9937893818970736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"boll_ub\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72.61886254618858,\n        \"min\": 28.425707101347697,\n        \"max\": 450.8874629517707,\n        \"num_unique_values\": 7277,\n        \"samples\": [\n          37.22752513577848,\n          130.0247807887055,\n          199.36056089806544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"boll_lb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64.25905731045634,\n        \"min\": 27.871831865572183,\n        \"max\": 391.165398921028,\n        \"num_unique_values\": 7277,\n        \"samples\": [\n          35.936471751428556,\n          125.68139139147026,\n          171.1038983304502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rsi_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.872370201503234,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 7226,\n        \"samples\": [\n          40.27511043875444,\n          69.29957391420824,\n          59.763834547657616\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cci_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.676962584136,\n        \"min\": -452.8501249749333,\n        \"max\": 419.56294401708936,\n        \"num_unique_values\": 7264,\n        \"samples\": [\n          85.25709037096888,\n          -24.796696811705786,\n          105.69897887284854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.179743304167204,\n        \"min\": 0.004699907272818416,\n        \"max\": 100.0,\n        \"num_unique_values\": 7036,\n        \"samples\": [\n          30.850448718917207,\n          46.47390224000955,\n          6.598892654237551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_30_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68.11716781848342,\n        \"min\": 28.21994686126709,\n        \"max\": 402.4908701578776,\n        \"num_unique_values\": 7305,\n        \"samples\": [\n          172.61591491699218,\n          116.61165669759114,\n          156.06714680989583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_60_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67.86007024973395,\n        \"min\": 28.21994686126709,\n        \"max\": 385.4164067586263,\n        \"num_unique_values\": 7307,\n        \"samples\": [\n          176.8410675048828,\n          47.636877632141115,\n          203.8324317932129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vix\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.736504813485816,\n        \"min\": 11.550000190734863,\n        \"max\": 27.540000915527344,\n        \"num_unique_values\": 219,\n        \"samples\": [\n          18.229999542236328,\n          18.549999237060547,\n          12.739999771118164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turbulence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "period_idx = -1\n",
        "train, val, test = quarterly_dataset[period_idx]\n",
        "print(train['date'].max() - train['date'].min())\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MtlF8TNkXc-P"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'cost_pct': 0.001,\n",
        "    'initial_amount': 50_000,\n",
        "    # 'turbulence_threshold': 30\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dUvvkBzXarxr",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Init env\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "\n",
        "def init_env(df, sweep_config, previous_state=None):\n",
        "    stock_dimension = len(df.tic.unique())\n",
        "    state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "\n",
        "    cost_pct = sweep_config['cost_pct']\n",
        "    if isinstance(cost_pct, list):\n",
        "        assert len(cost_pct) == stock_dimension\n",
        "        buy_cost_pct = sell_cost_pct = cost_pct\n",
        "    elif isinstance(cost_pct, (int, float)):\n",
        "        buy_cost_pct = sell_cost_pct = [ sweep_config['cost_pct'] ] * stock_dimension\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "    print(f\"Initializing env with initial amount: {previous_state[0] if previous_state is not None else sweep_config['initial_amount']}\")\n",
        "    env_kwargs = {\n",
        "        \"hmax\": 100,\n",
        "        \"initial_amount\": previous_state[0] if previous_state is not None else sweep_config['initial_amount'],\n",
        "        \"num_stock_shares\": num_stock_shares,\n",
        "        \"buy_cost_pct\": buy_cost_pct,\n",
        "        \"sell_cost_pct\": sell_cost_pct,\n",
        "        \"state_space\": state_space,\n",
        "        \"stock_dim\": stock_dimension,\n",
        "        \"tech_indicator_list\": INDICATORS,\n",
        "        \"action_space\": stock_dimension,\n",
        "        \"reward_scaling\": 1e-4,\n",
        "        \"turbulence_threshold\": sweep_config['turbulence_threshold'] if 'turbulence_threshold' in sweep_config else None,\n",
        "        \"print_verbosity\": 1,\n",
        "\n",
        "        \"initial\": False if previous_state is not None else True,\n",
        "        \"previous_state\": previous_state if previous_state is not None else [],\n",
        "    }\n",
        "\n",
        "    e_train_gym = StockTradingEnv(df = df, **env_kwargs)\n",
        "    return e_train_gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cellView": "form",
        "id": "tDokmsQFoSPV"
      },
      "outputs": [],
      "source": [
        "#@title define metrics\n",
        "\n",
        "def calculate_mdd(asset_values):\n",
        "    \"\"\"\n",
        "    Calculate the Maximum Drawdown (MDD) of a portfolio.\n",
        "    \"\"\"\n",
        "    running_max = asset_values.cummax()\n",
        "    drawdown = (asset_values - running_max) / running_max\n",
        "    mdd = drawdown.min() * 100  # Convert to percentage\n",
        "    return mdd\n",
        "\n",
        "def calculate_sharpe_ratio(asset_values, risk_free_rate=0.0):\n",
        "    \"\"\"\n",
        "    Calculate the Sharpe Ratio of a portfolio.\n",
        "    \"\"\"\n",
        "    # Calculate daily returns\n",
        "    returns = asset_values.pct_change().dropna()\n",
        "    excess_returns = returns - risk_free_rate / 252  # Assuming 252 trading days\n",
        "\n",
        "    if excess_returns.std() == 0:\n",
        "        return 0.0\n",
        "    sharpe_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252)  # Annualized\n",
        "    return sharpe_ratio\n",
        "\n",
        "def calculate_annualized_return(asset_values):\n",
        "    \"\"\"\n",
        "    Calculate the annualized return of a portfolio.\n",
        "    \"\"\"\n",
        "    # Assume `asset_values` is indexed by date or trading day\n",
        "    total_return = (asset_values.iloc[-1] / asset_values.iloc[0] - 1) * 100\n",
        "    num_days = (asset_values.index[-1] - asset_values.index[0]).days\n",
        "    annualized_return = (1 + total_return) ** (365 / num_days) - 1\n",
        "    return annualized_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "cellView": "form",
        "id": "wnUToRzBoSPW"
      },
      "outputs": [],
      "source": [
        "#@title get metrics\n",
        "import wandb\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "def get_account_value_metrics(account_values: List[pd.DataFrame, pd.Series, np.array]):\n",
        "    \"\"\"\n",
        "    If DataFrame then should contain two columns - 'date' and name of algo, e.g. 'a2c'.\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(account_values, pd.DataFrame):\n",
        "        assert isinstance(account_values, pd.DataFrame)\n",
        "        if 'date' not in account_values.columns:\n",
        "            if account_values.index.name == 'date':\n",
        "                account_values.reset_index(inplace=True)\n",
        "            else:\n",
        "                raise ValueError(\"should contain 'date' column or index\")\n",
        "        account_values = account_values.dropna().set_index('date').iloc[:, 0]\n",
        "    elif isinstance(account_values, (np.ndarray, list)):\n",
        "        account_values = pd.Series(account_values)\n",
        "\n",
        "    sharpe = calculate_sharpe_ratio(account_values)\n",
        "    mdd = calculate_mdd(account_values)\n",
        "    cum_ret = (account_values.iloc[-1] - account_values.iloc[0]) / account_values.iloc[0] * 100\n",
        "    # num_days = (account_values.index.max() - account_values.index.min()).days\n",
        "    num_days = len(account_values)\n",
        "    ann_ret = ((1 + cum_ret / 100) ** (365 / num_days) - 1) * 100\n",
        "\n",
        "    return {\n",
        "            f'sharpe_ratio': sharpe,\n",
        "            f'mdd': mdd,\n",
        "            f'ann_return': ann_ret,\n",
        "            f'cum_return': cum_ret,\n",
        "        }\n",
        "\n",
        "def get_env_metrics(env):\n",
        "    end_total_asset = env.state[0] + sum(\n",
        "        np.array(env.state[1 : (env.stock_dim + 1)])\n",
        "        * np.array(env.state[(env.stock_dim + 1) : (env.stock_dim * 2 + 1)])\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'begin_total_asset': env.asset_memory[0],\n",
        "        'end_total_asset': end_total_asset,\n",
        "        'total_cost': env.cost,\n",
        "        'total_trades': env.trades,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "id": "o4LTYifqoSPW"
      },
      "outputs": [],
      "source": [
        "#@title log_metrics_to_wandb\n",
        "\n",
        "def log_metrics_to_wandb(metrics, model_name, split_label, step=None):\n",
        "    print(f'log_metrics for {model_name}')\n",
        "    assert model_name in ['a2c', 'ddpg', 'sac', 'ppo', 'td3', 'best_model', 'chosen_model']\n",
        "\n",
        "    rename_metrics = lambda model_name: {\n",
        "        f\"{key}/{model_name}\": value for key, value in metrics.items()\n",
        "    }\n",
        "\n",
        "    renamed_metrics = rename_metrics(model_name)\n",
        "    wandb.log({split_label: renamed_metrics}, step=step)\n",
        "    # wandb.run.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "cellView": "form",
        "id": "bEKCwsuzPj51"
      },
      "outputs": [],
      "source": [
        "#@title MetricsLoggerCallback (class)\n",
        "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
        "from typing import Optional, Sequence\n",
        "import gymnasium as gym\n",
        "\n",
        "class MetricsLoggerCallback(DefaultCallbacks):\n",
        "    def __init__(self, env_runner_indices: Optional[Sequence[int]] = None):\n",
        "        super().__init__()\n",
        "\n",
        "        self._env_runner_indices = env_runner_indices\n",
        "        self._episode_start_position = {}\n",
        "\n",
        "    def on_episode_end(\n",
        "            self,\n",
        "            *,\n",
        "            episode,\n",
        "            env_runner,\n",
        "            metrics_logger,\n",
        "            env,\n",
        "            env_index,\n",
        "            rl_module,\n",
        "            **kwargs,\n",
        "        ) -> None:\n",
        "\n",
        "        env = env.unwrapped\n",
        "        # print(type(env))\n",
        "        # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.vector.sync_vector_env.SyncVectorEnv'>\n",
        "\n",
        "        env = env.envs[0]\n",
        "        # print(type(env))\n",
        "        # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.wrappers.common.OrderEnforcing'>\n",
        "\n",
        "        env = env.env\n",
        "        # print(type(env))\n",
        "        # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.wrappers.common.PassiveEnvChecker'>\n",
        "\n",
        "        env = env.env\n",
        "        # print(type(env))\n",
        "        # (SingleAgentEnvRunner pid=127688) <class 'finrl.meta.env_stock_trading.env_stocktrading.StockTradingEnv'>\n",
        "\n",
        "        metrics = get_account_value_metrics(env.asset_memory)\n",
        "        for k, v in metrics.items():\n",
        "            metrics_logger.log_value(k, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "cellView": "form",
        "id": "SJnystm1wtN3"
      },
      "outputs": [],
      "source": [
        "#@title log_env_metrics\n",
        "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
        "import gymnasium as gym\n",
        "\n",
        "def log_env_metrics(episode, env, metrics_logger, model_name, split_label, log_to_wandb=False):\n",
        "    env = env.unwrapped\n",
        "    # print(type(env))\n",
        "    # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.vector.sync_vector_env.SyncVectorEnv'>\n",
        "\n",
        "    env = env.envs[0]\n",
        "    # print(type(env))\n",
        "    # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.wrappers.common.OrderEnforcing'>\n",
        "\n",
        "    env = env.env\n",
        "    # print(type(env))\n",
        "    # (SingleAgentEnvRunner pid=127688) <class 'gymnasium.wrappers.common.PassiveEnvChecker'>\n",
        "\n",
        "    env = env.env\n",
        "    # print(type(env))\n",
        "    # (SingleAgentEnvRunner pid=127688) <class 'finrl.meta.env_stock_trading.env_stocktrading.StockTradingEnv'>\n",
        "\n",
        "    metrics = get_account_value_metrics(env.asset_memory)\n",
        "    for k, v in metrics.items():\n",
        "        metrics_logger.log_value(k, v)\n",
        "\n",
        "    print(f\"Metrics for episode {episode}:\")\n",
        "    print(metrics)\n",
        "\n",
        "    if log_to_wandb:\n",
        "        log_metrics_to_wandb(metrics, model_name, split_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "cellView": "form",
        "id": "V0iyYcwTOZYP"
      },
      "outputs": [],
      "source": [
        "#@title benchmark_exec_time\n",
        "import pandas as pd\n",
        "from time import perf_counter\n",
        "from functools import wraps\n",
        "\n",
        "def benchmark_exec_time(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "\n",
        "        start = perf_counter()\n",
        "        output = func(*args, **kwargs)\n",
        "        end = perf_counter()\n",
        "\n",
        "        exec_time = pd.Timedelta(seconds=end - start)\n",
        "\n",
        "        data = {\n",
        "            \"func_name\": func.__name__,\n",
        "            \"exec_time\": exec_time,\n",
        "        }\n",
        "\n",
        "        print('\\nBenchmark results:')\n",
        "        series = pd.Series(data, name=\"benchmark_results\")\n",
        "        print(series)  # TODO: log in file\n",
        "\n",
        "        return output\n",
        "\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2TxopjuUvJX2"
      },
      "outputs": [],
      "source": [
        "from ray.tune.registry import register_env\n",
        "\n",
        "def create_stock_trading_env(env_config):\n",
        "    return init_env(**env_config)\n",
        "\n",
        "register_env(\"stock_trading_env\", create_stock_trading_env)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "s08khDxtFMur"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcyL3GxIPS09",
        "outputId": "cc2d6365-bab0-413a-8ed0-8bf66ee90b7e",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 291\n",
            "Initializing env with initial amount: 50000\n",
            "{'n_steps': 2048, 'n_epochs': 10, 'batch_size': 128, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'device': 'cuda'}\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Logging to results/ppo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#@title Train SB3 model\n",
        "import torch\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "\n",
        "train_env = create_stock_trading_env(dict(df=train, sweep_config=sweep_config))\n",
        "agent = DRLAgent(env = train_env)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048, # rllib batch_size\n",
        "    \"n_epochs\":10,\n",
        "    \"batch_size\": 128, # rllib minibatch_size\n",
        "\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"learning_rate\": 0.00025,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "}\n",
        "\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "new_logger_ppo = configure(RESULTS_DIR + '/ppo', [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "model_ppo.set_logger(new_logger_ppo)\n",
        "\n",
        "@benchmark_exec_time\n",
        "def _train_sb3(total_timesteps=200_000):\n",
        "    trained_ppo = agent.train_model(\n",
        "        model=model_ppo,\n",
        "        tb_log_name='ppo',\n",
        "        total_timesteps=total_timesteps\n",
        "    )\n",
        "\n",
        "# _train_sb3(4096)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFOoTEL-ZAiy",
        "outputId": "b5abe0fa-c629-405c-d4c7-48869a2f5fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day: 251, episode: 126\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57499.33\n",
            "total_reward: 7499.33\n",
            "total_cost: 6700.40\n",
            "total_trades: 4521\n",
            "Sharpe: 1.117\n",
            "=================================\n",
            "day: 251, episode: 127\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58076.33\n",
            "total_reward: 8076.33\n",
            "total_cost: 7313.41\n",
            "total_trades: 4639\n",
            "Sharpe: 1.300\n",
            "=================================\n",
            "day: 251, episode: 128\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55258.89\n",
            "total_reward: 5258.89\n",
            "total_cost: 7381.66\n",
            "total_trades: 4614\n",
            "Sharpe: 0.760\n",
            "=================================\n",
            "day: 251, episode: 129\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64462.14\n",
            "total_reward: 14462.14\n",
            "total_cost: 7958.42\n",
            "total_trades: 4681\n",
            "Sharpe: 1.783\n",
            "=================================\n",
            "day: 251, episode: 130\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58591.09\n",
            "total_reward: 8591.09\n",
            "total_cost: 7117.91\n",
            "total_trades: 4533\n",
            "Sharpe: 1.135\n",
            "=================================\n",
            "day: 251, episode: 131\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59625.27\n",
            "total_reward: 9625.27\n",
            "total_cost: 6852.84\n",
            "total_trades: 4660\n",
            "Sharpe: 1.291\n",
            "=================================\n",
            "day: 251, episode: 132\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63431.30\n",
            "total_reward: 13431.30\n",
            "total_cost: 6735.44\n",
            "total_trades: 4566\n",
            "Sharpe: 1.652\n",
            "=================================\n",
            "day: 251, episode: 133\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57720.35\n",
            "total_reward: 7720.35\n",
            "total_cost: 7419.63\n",
            "total_trades: 4577\n",
            "Sharpe: 1.061\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 252           |\n",
            "|    ep_rew_mean          | 0.937         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 218           |\n",
            "|    iterations           | 1             |\n",
            "|    time_elapsed         | 9             |\n",
            "|    total_timesteps      | 2048          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.03845106    |\n",
            "|    clip_fraction        | 0.339         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -42.1         |\n",
            "|    explained_variance   | 0.433         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.447        |\n",
            "|    n_updates            | 150           |\n",
            "|    policy_gradient_loss | -0.0225       |\n",
            "|    reward               | -0.0022040885 |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 0.00983       |\n",
            "-------------------------------------------\n",
            "day: 251, episode: 134\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62520.43\n",
            "total_reward: 12520.43\n",
            "total_cost: 7215.21\n",
            "total_trades: 4557\n",
            "Sharpe: 1.740\n",
            "=================================\n",
            "day: 251, episode: 135\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59626.18\n",
            "total_reward: 9626.18\n",
            "total_cost: 7599.45\n",
            "total_trades: 4605\n",
            "Sharpe: 1.338\n",
            "=================================\n",
            "day: 251, episode: 136\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58731.10\n",
            "total_reward: 8731.10\n",
            "total_cost: 7258.40\n",
            "total_trades: 4620\n",
            "Sharpe: 1.260\n",
            "=================================\n",
            "day: 251, episode: 137\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55135.39\n",
            "total_reward: 5135.39\n",
            "total_cost: 7255.66\n",
            "total_trades: 4561\n",
            "Sharpe: 0.804\n",
            "=================================\n",
            "day: 251, episode: 138\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62585.46\n",
            "total_reward: 12585.46\n",
            "total_cost: 7237.79\n",
            "total_trades: 4583\n",
            "Sharpe: 1.669\n",
            "=================================\n",
            "day: 251, episode: 139\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57467.84\n",
            "total_reward: 7467.84\n",
            "total_cost: 6646.81\n",
            "total_trades: 4574\n",
            "Sharpe: 1.115\n",
            "=================================\n",
            "day: 251, episode: 140\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 52391.38\n",
            "total_reward: 2391.38\n",
            "total_cost: 6896.83\n",
            "total_trades: 4668\n",
            "Sharpe: 0.424\n",
            "=================================\n",
            "day: 251, episode: 141\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57663.04\n",
            "total_reward: 7663.04\n",
            "total_cost: 7335.42\n",
            "total_trades: 4567\n",
            "Sharpe: 1.158\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 252           |\n",
            "|    ep_rew_mean          | 0.887         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 255           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0557307     |\n",
            "|    clip_fraction        | 0.41          |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -42.1         |\n",
            "|    explained_variance   | 0.523         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.415        |\n",
            "|    n_updates            | 160           |\n",
            "|    policy_gradient_loss | -0.0128       |\n",
            "|    reward               | -0.0057580345 |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 0.00741       |\n",
            "-------------------------------------------\n",
            "day: 251, episode: 142\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 54389.23\n",
            "total_reward: 4389.23\n",
            "total_cost: 6639.23\n",
            "total_trades: 4614\n",
            "Sharpe: 0.712\n",
            "=================================\n",
            "day: 251, episode: 143\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57884.04\n",
            "total_reward: 7884.04\n",
            "total_cost: 6395.28\n",
            "total_trades: 4520\n",
            "Sharpe: 1.099\n",
            "=================================\n",
            "day: 251, episode: 144\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57278.98\n",
            "total_reward: 7278.98\n",
            "total_cost: 6168.58\n",
            "total_trades: 4481\n",
            "Sharpe: 1.033\n",
            "=================================\n",
            "day: 251, episode: 145\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 65120.03\n",
            "total_reward: 15120.03\n",
            "total_cost: 6827.56\n",
            "total_trades: 4604\n",
            "Sharpe: 2.067\n",
            "=================================\n",
            "day: 251, episode: 146\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 70562.95\n",
            "total_reward: 20562.95\n",
            "total_cost: 8090.84\n",
            "total_trades: 4677\n",
            "Sharpe: 2.538\n",
            "=================================\n",
            "day: 251, episode: 147\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55939.08\n",
            "total_reward: 5939.08\n",
            "total_cost: 7380.94\n",
            "total_trades: 4631\n",
            "Sharpe: 0.872\n",
            "=================================\n",
            "day: 251, episode: 148\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60746.27\n",
            "total_reward: 10746.27\n",
            "total_cost: 7651.10\n",
            "total_trades: 4604\n",
            "Sharpe: 1.506\n",
            "=================================\n",
            "day: 251, episode: 149\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61070.02\n",
            "total_reward: 11070.02\n",
            "total_cost: 6978.54\n",
            "total_trades: 4474\n",
            "Sharpe: 1.447\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 252         |\n",
            "|    ep_rew_mean          | 0.941       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 255         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.04580444  |\n",
            "|    clip_fraction        | 0.362       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | 0.553       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.451      |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00719    |\n",
            "|    reward               | 0.029884826 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.00576     |\n",
            "-----------------------------------------\n",
            "\n",
            "Benchmark results:\n",
            "func_name                   _train_sb3\n",
            "exec_time    0 days 00:00:24.848301859\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 151\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 54827.10\n",
            "total_reward: 4827.10\n",
            "total_cost: 7637.17\n",
            "total_trades: 4619\n",
            "Sharpe: 0.820\n",
            "=================================\n",
            "day: 251, episode: 152\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60070.92\n",
            "total_reward: 10070.92\n",
            "total_cost: 7368.07\n",
            "total_trades: 4591\n",
            "Sharpe: 1.335\n",
            "=================================\n",
            "day: 251, episode: 153\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57748.15\n",
            "total_reward: 7748.15\n",
            "total_cost: 8131.34\n",
            "total_trades: 4655\n",
            "Sharpe: 1.103\n",
            "=================================\n",
            "day: 251, episode: 154\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58227.42\n",
            "total_reward: 8227.42\n",
            "total_cost: 7286.86\n",
            "total_trades: 4631\n",
            "Sharpe: 1.030\n",
            "=================================\n",
            "day: 251, episode: 155\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55244.50\n",
            "total_reward: 5244.50\n",
            "total_cost: 7045.68\n",
            "total_trades: 4601\n",
            "Sharpe: 0.878\n",
            "=================================\n",
            "day: 251, episode: 156\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64291.75\n",
            "total_reward: 14291.75\n",
            "total_cost: 7231.19\n",
            "total_trades: 4592\n",
            "Sharpe: 1.813\n",
            "=================================\n",
            "day: 251, episode: 157\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63825.29\n",
            "total_reward: 13825.29\n",
            "total_cost: 7983.61\n",
            "total_trades: 4675\n",
            "Sharpe: 1.797\n",
            "=================================\n",
            "day: 251, episode: 158\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60190.94\n",
            "total_reward: 10190.94\n",
            "total_cost: 7389.21\n",
            "total_trades: 4590\n",
            "Sharpe: 1.478\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 252          |\n",
            "|    ep_rew_mean          | 0.94         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 1            |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.03727941   |\n",
            "|    clip_fraction        | 0.337        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.3        |\n",
            "|    explained_variance   | 0.472        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.432       |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.0181      |\n",
            "|    reward               | -0.009017029 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.00793      |\n",
            "------------------------------------------\n",
            "day: 251, episode: 159\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 54123.19\n",
            "total_reward: 4123.19\n",
            "total_cost: 7252.53\n",
            "total_trades: 4601\n",
            "Sharpe: 0.638\n",
            "=================================\n",
            "day: 251, episode: 160\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 72870.52\n",
            "total_reward: 22870.52\n",
            "total_cost: 6843.63\n",
            "total_trades: 4571\n",
            "Sharpe: 2.630\n",
            "=================================\n",
            "day: 251, episode: 161\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61819.89\n",
            "total_reward: 11819.89\n",
            "total_cost: 6381.41\n",
            "total_trades: 4528\n",
            "Sharpe: 1.671\n",
            "=================================\n",
            "day: 251, episode: 162\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60840.77\n",
            "total_reward: 10840.77\n",
            "total_cost: 7658.95\n",
            "total_trades: 4578\n",
            "Sharpe: 1.533\n",
            "=================================\n",
            "day: 251, episode: 163\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63202.36\n",
            "total_reward: 13202.36\n",
            "total_cost: 7716.60\n",
            "total_trades: 4633\n",
            "Sharpe: 1.746\n",
            "=================================\n",
            "day: 251, episode: 164\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53034.22\n",
            "total_reward: 3034.22\n",
            "total_cost: 7979.93\n",
            "total_trades: 4657\n",
            "Sharpe: 0.475\n",
            "=================================\n",
            "day: 251, episode: 165\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59932.22\n",
            "total_reward: 9932.22\n",
            "total_cost: 6500.30\n",
            "total_trades: 4583\n",
            "Sharpe: 1.365\n",
            "=================================\n",
            "day: 251, episode: 166\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63365.11\n",
            "total_reward: 13365.11\n",
            "total_cost: 7119.03\n",
            "total_trades: 4633\n",
            "Sharpe: 1.884\n",
            "=================================\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 252        |\n",
            "|    ep_rew_mean          | 1.03       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 296        |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 13         |\n",
            "|    total_timesteps      | 4096       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03904234 |\n",
            "|    clip_fraction        | 0.34       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -42.3      |\n",
            "|    explained_variance   | 0.49       |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.421     |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.012     |\n",
            "|    reward               | 0.04132311 |\n",
            "|    std                  | 1.04       |\n",
            "|    value_loss           | 0.00841    |\n",
            "----------------------------------------\n",
            "day: 251, episode: 167\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62879.83\n",
            "total_reward: 12879.83\n",
            "total_cost: 6960.36\n",
            "total_trades: 4631\n",
            "Sharpe: 1.644\n",
            "=================================\n",
            "day: 251, episode: 168\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53724.35\n",
            "total_reward: 3724.35\n",
            "total_cost: 6969.76\n",
            "total_trades: 4552\n",
            "Sharpe: 0.582\n",
            "=================================\n",
            "day: 251, episode: 169\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 72287.54\n",
            "total_reward: 22287.54\n",
            "total_cost: 6974.82\n",
            "total_trades: 4605\n",
            "Sharpe: 2.360\n",
            "=================================\n",
            "day: 251, episode: 170\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63723.70\n",
            "total_reward: 13723.70\n",
            "total_cost: 6575.33\n",
            "total_trades: 4600\n",
            "Sharpe: 1.615\n",
            "=================================\n",
            "day: 251, episode: 171\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63881.81\n",
            "total_reward: 13881.81\n",
            "total_cost: 7460.78\n",
            "total_trades: 4621\n",
            "Sharpe: 1.840\n",
            "=================================\n",
            "day: 251, episode: 172\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56864.32\n",
            "total_reward: 6864.32\n",
            "total_cost: 6851.66\n",
            "total_trades: 4582\n",
            "Sharpe: 0.897\n",
            "=================================\n",
            "day: 251, episode: 173\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62049.13\n",
            "total_reward: 12049.13\n",
            "total_cost: 8229.18\n",
            "total_trades: 4604\n",
            "Sharpe: 1.481\n",
            "=================================\n",
            "day: 251, episode: 174\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59131.70\n",
            "total_reward: 9131.70\n",
            "total_cost: 6553.51\n",
            "total_trades: 4594\n",
            "Sharpe: 1.344\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 252         |\n",
            "|    ep_rew_mean          | 1.08        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 291         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.041381873 |\n",
            "|    clip_fraction        | 0.364       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.4       |\n",
            "|    explained_variance   | 0.415       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.426      |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0147     |\n",
            "|    reward               | 0.021826524 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.00995     |\n",
            "-----------------------------------------\n",
            "\n",
            "Benchmark results:\n",
            "func_name                   _train_sb3\n",
            "exec_time    0 days 00:00:22.103066622\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 176\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66366.39\n",
            "total_reward: 16366.39\n",
            "total_cost: 7212.51\n",
            "total_trades: 4568\n",
            "Sharpe: 2.108\n",
            "=================================\n",
            "day: 251, episode: 177\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58605.77\n",
            "total_reward: 8605.77\n",
            "total_cost: 6660.77\n",
            "total_trades: 4546\n",
            "Sharpe: 1.215\n",
            "=================================\n",
            "day: 251, episode: 178\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60703.29\n",
            "total_reward: 10703.29\n",
            "total_cost: 7339.44\n",
            "total_trades: 4615\n",
            "Sharpe: 1.589\n",
            "=================================\n",
            "day: 251, episode: 179\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56445.40\n",
            "total_reward: 6445.40\n",
            "total_cost: 7127.94\n",
            "total_trades: 4553\n",
            "Sharpe: 0.976\n",
            "=================================\n",
            "day: 251, episode: 180\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64651.69\n",
            "total_reward: 14651.69\n",
            "total_cost: 7284.94\n",
            "total_trades: 4611\n",
            "Sharpe: 1.754\n",
            "=================================\n",
            "day: 251, episode: 181\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60121.72\n",
            "total_reward: 10121.72\n",
            "total_cost: 7086.27\n",
            "total_trades: 4611\n",
            "Sharpe: 1.417\n",
            "=================================\n",
            "day: 251, episode: 182\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59318.46\n",
            "total_reward: 9318.46\n",
            "total_cost: 7092.61\n",
            "total_trades: 4629\n",
            "Sharpe: 1.220\n",
            "=================================\n",
            "day: 251, episode: 183\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 68387.23\n",
            "total_reward: 18387.23\n",
            "total_cost: 6787.47\n",
            "total_trades: 4524\n",
            "Sharpe: 2.238\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 252          |\n",
            "|    ep_rew_mean          | 1.19         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 315          |\n",
            "|    iterations           | 1            |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.033997804  |\n",
            "|    clip_fraction        | 0.336        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.5        |\n",
            "|    explained_variance   | 0.527        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.425       |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.0182      |\n",
            "|    reward               | -0.010027319 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.011        |\n",
            "------------------------------------------\n",
            "day: 251, episode: 184\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63421.59\n",
            "total_reward: 13421.59\n",
            "total_cost: 7106.85\n",
            "total_trades: 4604\n",
            "Sharpe: 1.670\n",
            "=================================\n",
            "day: 251, episode: 185\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64336.08\n",
            "total_reward: 14336.08\n",
            "total_cost: 6430.42\n",
            "total_trades: 4466\n",
            "Sharpe: 1.935\n",
            "=================================\n",
            "day: 251, episode: 186\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60407.83\n",
            "total_reward: 10407.83\n",
            "total_cost: 6393.85\n",
            "total_trades: 4497\n",
            "Sharpe: 1.459\n",
            "=================================\n",
            "day: 251, episode: 187\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 69255.09\n",
            "total_reward: 19255.09\n",
            "total_cost: 7977.57\n",
            "total_trades: 4670\n",
            "Sharpe: 2.489\n",
            "=================================\n",
            "day: 251, episode: 188\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58691.95\n",
            "total_reward: 8691.95\n",
            "total_cost: 7184.88\n",
            "total_trades: 4550\n",
            "Sharpe: 1.104\n",
            "=================================\n",
            "day: 251, episode: 189\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62574.82\n",
            "total_reward: 12574.82\n",
            "total_cost: 6680.84\n",
            "total_trades: 4590\n",
            "Sharpe: 1.601\n",
            "=================================\n",
            "day: 251, episode: 190\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58721.91\n",
            "total_reward: 8721.91\n",
            "total_cost: 6339.89\n",
            "total_trades: 4508\n",
            "Sharpe: 1.197\n",
            "=================================\n",
            "day: 251, episode: 191\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 67637.51\n",
            "total_reward: 17637.51\n",
            "total_cost: 7211.76\n",
            "total_trades: 4579\n",
            "Sharpe: 2.128\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 252         |\n",
            "|    ep_rew_mean          | 1.26        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 294         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.04755534  |\n",
            "|    clip_fraction        | 0.383       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.573       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.435      |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00986    |\n",
            "|    reward               | 0.014497125 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.00803     |\n",
            "-----------------------------------------\n",
            "day: 251, episode: 192\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63388.88\n",
            "total_reward: 13388.88\n",
            "total_cost: 6561.98\n",
            "total_trades: 4587\n",
            "Sharpe: 1.688\n",
            "=================================\n",
            "day: 251, episode: 193\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 68754.46\n",
            "total_reward: 18754.46\n",
            "total_cost: 7859.41\n",
            "total_trades: 4712\n",
            "Sharpe: 2.422\n",
            "=================================\n",
            "day: 251, episode: 194\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 70329.65\n",
            "total_reward: 20329.65\n",
            "total_cost: 6300.61\n",
            "total_trades: 4570\n",
            "Sharpe: 2.139\n",
            "=================================\n",
            "day: 251, episode: 195\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64551.27\n",
            "total_reward: 14551.27\n",
            "total_cost: 6562.78\n",
            "total_trades: 4569\n",
            "Sharpe: 1.623\n",
            "=================================\n",
            "day: 251, episode: 196\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64698.81\n",
            "total_reward: 14698.81\n",
            "total_cost: 7044.99\n",
            "total_trades: 4629\n",
            "Sharpe: 1.773\n",
            "=================================\n",
            "day: 251, episode: 197\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66855.08\n",
            "total_reward: 16855.08\n",
            "total_cost: 7198.81\n",
            "total_trades: 4609\n",
            "Sharpe: 2.016\n",
            "=================================\n",
            "day: 251, episode: 198\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62329.89\n",
            "total_reward: 12329.89\n",
            "total_cost: 7011.19\n",
            "total_trades: 4588\n",
            "Sharpe: 1.571\n",
            "=================================\n",
            "day: 251, episode: 199\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 72162.31\n",
            "total_reward: 22162.31\n",
            "total_cost: 6927.57\n",
            "total_trades: 4636\n",
            "Sharpe: 2.465\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 252         |\n",
            "|    ep_rew_mean          | 1.4         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 288         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.055609714 |\n",
            "|    clip_fraction        | 0.368       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.611       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.461      |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0149     |\n",
            "|    reward               | 0.012198136 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.00874     |\n",
            "-----------------------------------------\n",
            "\n",
            "Benchmark results:\n",
            "func_name                   _train_sb3\n",
            "exec_time    0 days 00:00:22.106573465\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 201\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 69638.55\n",
            "total_reward: 19638.55\n",
            "total_cost: 6516.68\n",
            "total_trades: 4557\n",
            "Sharpe: 2.273\n",
            "=================================\n",
            "day: 251, episode: 202\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 68325.16\n",
            "total_reward: 18325.16\n",
            "total_cost: 7005.06\n",
            "total_trades: 4572\n",
            "Sharpe: 2.070\n",
            "=================================\n",
            "day: 251, episode: 203\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61237.22\n",
            "total_reward: 11237.22\n",
            "total_cost: 6806.05\n",
            "total_trades: 4559\n",
            "Sharpe: 1.425\n",
            "=================================\n",
            "day: 251, episode: 204\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 71214.95\n",
            "total_reward: 21214.95\n",
            "total_cost: 6632.76\n",
            "total_trades: 4596\n",
            "Sharpe: 2.399\n",
            "=================================\n",
            "day: 251, episode: 205\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 77192.77\n",
            "total_reward: 27192.77\n",
            "total_cost: 7737.26\n",
            "total_trades: 4653\n",
            "Sharpe: 3.072\n",
            "=================================\n",
            "day: 251, episode: 206\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 67163.34\n",
            "total_reward: 17163.34\n",
            "total_cost: 7378.15\n",
            "total_trades: 4605\n",
            "Sharpe: 1.958\n",
            "=================================\n",
            "day: 251, episode: 207\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 71847.93\n",
            "total_reward: 21847.93\n",
            "total_cost: 6804.36\n",
            "total_trades: 4544\n",
            "Sharpe: 2.588\n",
            "=================================\n",
            "day: 251, episode: 208\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66137.65\n",
            "total_reward: 16137.65\n",
            "total_cost: 6787.81\n",
            "total_trades: 4593\n",
            "Sharpe: 2.007\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 252          |\n",
            "|    ep_rew_mean          | 1.92         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 299          |\n",
            "|    iterations           | 1            |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0376814    |\n",
            "|    clip_fraction        | 0.334        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.6        |\n",
            "|    explained_variance   | 0.691        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.426       |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.015       |\n",
            "|    reward               | -0.005108096 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.00777      |\n",
            "------------------------------------------\n",
            "day: 251, episode: 209\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61370.48\n",
            "total_reward: 11370.48\n",
            "total_cost: 6090.91\n",
            "total_trades: 4541\n",
            "Sharpe: 1.410\n",
            "=================================\n",
            "day: 251, episode: 210\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66548.59\n",
            "total_reward: 16548.59\n",
            "total_cost: 6928.61\n",
            "total_trades: 4652\n",
            "Sharpe: 2.145\n",
            "=================================\n",
            "day: 251, episode: 211\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 71221.71\n",
            "total_reward: 21221.71\n",
            "total_cost: 6238.17\n",
            "total_trades: 4511\n",
            "Sharpe: 2.247\n",
            "=================================\n",
            "day: 251, episode: 212\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 74655.88\n",
            "total_reward: 24655.88\n",
            "total_cost: 6925.02\n",
            "total_trades: 4587\n",
            "Sharpe: 2.735\n",
            "=================================\n",
            "day: 251, episode: 213\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 70942.70\n",
            "total_reward: 20942.70\n",
            "total_cost: 7146.54\n",
            "total_trades: 4566\n",
            "Sharpe: 2.469\n",
            "=================================\n",
            "day: 251, episode: 214\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 69384.02\n",
            "total_reward: 19384.02\n",
            "total_cost: 7413.29\n",
            "total_trades: 4558\n",
            "Sharpe: 2.134\n",
            "=================================\n",
            "day: 251, episode: 215\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63468.06\n",
            "total_reward: 13468.06\n",
            "total_cost: 5766.60\n",
            "total_trades: 4552\n",
            "Sharpe: 1.584\n",
            "=================================\n",
            "day: 251, episode: 216\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60129.88\n",
            "total_reward: 10129.88\n",
            "total_cost: 6675.74\n",
            "total_trades: 4511\n",
            "Sharpe: 1.338\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 252           |\n",
            "|    ep_rew_mean          | 1.82          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 295           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 13            |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.042288445   |\n",
            "|    clip_fraction        | 0.331         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -42.6         |\n",
            "|    explained_variance   | 0.727         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.437        |\n",
            "|    n_updates            | 250           |\n",
            "|    policy_gradient_loss | -0.0109       |\n",
            "|    reward               | -0.0007569779 |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 0.00911       |\n",
            "-------------------------------------------\n",
            "day: 251, episode: 217\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 71827.01\n",
            "total_reward: 21827.01\n",
            "total_cost: 7132.15\n",
            "total_trades: 4516\n",
            "Sharpe: 2.270\n",
            "=================================\n",
            "day: 251, episode: 218\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64670.74\n",
            "total_reward: 14670.74\n",
            "total_cost: 7502.26\n",
            "total_trades: 4671\n",
            "Sharpe: 1.998\n",
            "=================================\n",
            "day: 251, episode: 219\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 71817.84\n",
            "total_reward: 21817.84\n",
            "total_cost: 6839.82\n",
            "total_trades: 4607\n",
            "Sharpe: 2.500\n",
            "=================================\n",
            "day: 251, episode: 220\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 74449.38\n",
            "total_reward: 24449.38\n",
            "total_cost: 7114.69\n",
            "total_trades: 4572\n",
            "Sharpe: 2.689\n",
            "=================================\n",
            "day: 251, episode: 221\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63383.42\n",
            "total_reward: 13383.42\n",
            "total_cost: 7167.65\n",
            "total_trades: 4589\n",
            "Sharpe: 1.828\n",
            "=================================\n",
            "day: 251, episode: 222\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63182.09\n",
            "total_reward: 13182.09\n",
            "total_cost: 6772.26\n",
            "total_trades: 4553\n",
            "Sharpe: 1.557\n",
            "=================================\n",
            "day: 251, episode: 223\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 65892.48\n",
            "total_reward: 15892.48\n",
            "total_cost: 7203.24\n",
            "total_trades: 4546\n",
            "Sharpe: 1.880\n",
            "=================================\n",
            "day: 251, episode: 224\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62671.86\n",
            "total_reward: 12671.86\n",
            "total_cost: 6787.24\n",
            "total_trades: 4499\n",
            "Sharpe: 1.434\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 252          |\n",
            "|    ep_rew_mean          | 1.79         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 279          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.041852355  |\n",
            "|    clip_fraction        | 0.323        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.7        |\n",
            "|    explained_variance   | 0.719        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.419       |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.0142      |\n",
            "|    reward               | -0.007928947 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.00996      |\n",
            "------------------------------------------\n",
            "\n",
            "Benchmark results:\n",
            "func_name                   _train_sb3\n",
            "exec_time    0 days 00:00:22.786396313\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 226\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 67165.46\n",
            "total_reward: 17165.46\n",
            "total_cost: 7028.04\n",
            "total_trades: 4611\n",
            "Sharpe: 2.070\n",
            "=================================\n",
            "day: 251, episode: 227\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 70496.11\n",
            "total_reward: 20496.11\n",
            "total_cost: 7697.58\n",
            "total_trades: 4620\n",
            "Sharpe: 2.496\n",
            "=================================\n",
            "day: 251, episode: 228\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 71240.62\n",
            "total_reward: 21240.62\n",
            "total_cost: 6844.27\n",
            "total_trades: 4529\n",
            "Sharpe: 2.618\n",
            "=================================\n",
            "day: 251, episode: 229\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66362.19\n",
            "total_reward: 16362.19\n",
            "total_cost: 6067.89\n",
            "total_trades: 4444\n",
            "Sharpe: 1.984\n",
            "=================================\n",
            "day: 251, episode: 230\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66514.93\n",
            "total_reward: 16514.93\n",
            "total_cost: 6856.16\n",
            "total_trades: 4585\n",
            "Sharpe: 2.041\n",
            "=================================\n",
            "day: 251, episode: 231\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62387.49\n",
            "total_reward: 12387.49\n",
            "total_cost: 6180.34\n",
            "total_trades: 4467\n",
            "Sharpe: 1.414\n",
            "=================================\n",
            "day: 251, episode: 232\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 73582.72\n",
            "total_reward: 23582.72\n",
            "total_cost: 7174.11\n",
            "total_trades: 4568\n",
            "Sharpe: 2.573\n",
            "=================================\n",
            "day: 251, episode: 233\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 69273.39\n",
            "total_reward: 19273.39\n",
            "total_cost: 5389.04\n",
            "total_trades: 4459\n",
            "Sharpe: 2.216\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 252         |\n",
            "|    ep_rew_mean          | 1.85        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 346         |\n",
            "|    iterations           | 1           |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 2048        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.045604177 |\n",
            "|    clip_fraction        | 0.347       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.7       |\n",
            "|    explained_variance   | 0.711       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.447      |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    reward               | 0.018735083 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.0101      |\n",
            "-----------------------------------------\n",
            "day: 251, episode: 234\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 65995.07\n",
            "total_reward: 15995.07\n",
            "total_cost: 6803.13\n",
            "total_trades: 4582\n",
            "Sharpe: 2.056\n",
            "=================================\n",
            "day: 251, episode: 235\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 68816.60\n",
            "total_reward: 18816.60\n",
            "total_cost: 7031.00\n",
            "total_trades: 4537\n",
            "Sharpe: 2.244\n",
            "=================================\n",
            "day: 251, episode: 236\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 77907.93\n",
            "total_reward: 27907.93\n",
            "total_cost: 6498.06\n",
            "total_trades: 4543\n",
            "Sharpe: 3.039\n",
            "=================================\n",
            "day: 251, episode: 237\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64754.44\n",
            "total_reward: 14754.44\n",
            "total_cost: 6695.82\n",
            "total_trades: 4555\n",
            "Sharpe: 1.688\n",
            "=================================\n",
            "day: 251, episode: 238\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59182.19\n",
            "total_reward: 9182.19\n",
            "total_cost: 5502.30\n",
            "total_trades: 4545\n",
            "Sharpe: 1.322\n",
            "=================================\n",
            "day: 251, episode: 239\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 76535.03\n",
            "total_reward: 26535.03\n",
            "total_cost: 7160.27\n",
            "total_trades: 4613\n",
            "Sharpe: 2.673\n",
            "=================================\n",
            "day: 251, episode: 240\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 75340.02\n",
            "total_reward: 25340.02\n",
            "total_cost: 7708.05\n",
            "total_trades: 4525\n",
            "Sharpe: 2.883\n",
            "=================================\n",
            "day: 251, episode: 241\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 74876.59\n",
            "total_reward: 24876.59\n",
            "total_cost: 5732.60\n",
            "total_trades: 4486\n",
            "Sharpe: 2.437\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 252          |\n",
            "|    ep_rew_mean          | 1.95         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 295          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.03497846   |\n",
            "|    clip_fraction        | 0.327        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.7        |\n",
            "|    explained_variance   | 0.778        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.456       |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    reward               | -0.015802756 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.00797      |\n",
            "------------------------------------------\n",
            "day: 251, episode: 242\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64368.32\n",
            "total_reward: 14368.32\n",
            "total_cost: 6407.35\n",
            "total_trades: 4543\n",
            "Sharpe: 1.713\n",
            "=================================\n",
            "day: 251, episode: 243\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 69299.67\n",
            "total_reward: 19299.67\n",
            "total_cost: 7021.08\n",
            "total_trades: 4542\n",
            "Sharpe: 2.411\n",
            "=================================\n",
            "day: 251, episode: 244\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 68016.43\n",
            "total_reward: 18016.43\n",
            "total_cost: 6536.88\n",
            "total_trades: 4513\n",
            "Sharpe: 2.214\n",
            "=================================\n",
            "day: 251, episode: 245\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 65976.65\n",
            "total_reward: 15976.65\n",
            "total_cost: 5800.28\n",
            "total_trades: 4497\n",
            "Sharpe: 1.962\n",
            "=================================\n",
            "day: 251, episode: 246\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 69798.60\n",
            "total_reward: 19798.60\n",
            "total_cost: 5833.39\n",
            "total_trades: 4477\n",
            "Sharpe: 2.398\n",
            "=================================\n",
            "day: 251, episode: 247\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 78977.83\n",
            "total_reward: 28977.83\n",
            "total_cost: 6714.86\n",
            "total_trades: 4608\n",
            "Sharpe: 2.895\n",
            "=================================\n",
            "day: 251, episode: 248\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 69924.48\n",
            "total_reward: 19924.48\n",
            "total_cost: 5478.41\n",
            "total_trades: 4454\n",
            "Sharpe: 2.198\n",
            "=================================\n",
            "day: 251, episode: 249\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66111.09\n",
            "total_reward: 16111.09\n",
            "total_cost: 6524.07\n",
            "total_trades: 4628\n",
            "Sharpe: 1.856\n",
            "=================================\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 252          |\n",
            "|    ep_rew_mean          | 1.94         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 298          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.045592636  |\n",
            "|    clip_fraction        | 0.361        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.7        |\n",
            "|    explained_variance   | 0.727        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.465       |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.0111      |\n",
            "|    reward               | 0.0046555134 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0121       |\n",
            "------------------------------------------\n",
            "\n",
            "Benchmark results:\n",
            "func_name                   _train_sb3\n",
            "exec_time    0 days 00:00:21.441205664\n",
            "Name: benchmark_results, dtype: object\n",
            "22.7 s ± 1.18 s per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 1 -r 5 _train_sb3(5_120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CDJpaWdhVCsP",
        "outputId": "8a9ae85a-a590-4677-825a-acbbc025516a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-24 16:27:44,545\tWARNING algorithm_config.py:4702 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 291\n",
            "Initializing env with initial amount: 50000\n",
            "Stock Dimension: 29, State Space: 291\n",
            "Initializing env with initial amount: 50000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-24 16:27:44,908\tWARNING algorithm_config.py:4702 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "2025-01-24 16:27:45,121\tWARNING rl_module.py:419 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
            "2025-01-24 16:27:45,182\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
          ]
        }
      ],
      "source": [
        "#@title Train RLlib model\n",
        "\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "\n",
        "from pathlib import Path\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "import torch\n",
        "\n",
        "# 1. Configure the algorithm,\n",
        "config = (\n",
        "    PPOConfig()\n",
        "    .environment(\n",
        "        env=\"stock_trading_env\",\n",
        "        env_config={\"df\": train, \"sweep_config\": sweep_config},\n",
        "    )\n",
        "    .env_runners(\n",
        "        num_env_runners=0,\n",
        "        num_envs_per_env_runner=2\n",
        "    )\n",
        "    .training(\n",
        "        train_batch_size=2048,\n",
        "        num_epochs=10,\n",
        "        minibatch_size=128,\n",
        "    )\n",
        "    .callbacks(MetricsLoggerCallback)\n",
        "    .resources(\n",
        "        num_gpus=1 if torch.cuda.is_available() else None\n",
        "    )\n",
        ")\n",
        "\n",
        "# 2. build the algorithm ..\n",
        "algo = config.build()\n",
        "\n",
        "# 3. .. train it ..\n",
        "from math import ceil\n",
        "\n",
        "@benchmark_exec_time\n",
        "def _train_rllib(total_timesteps=200_000):\n",
        "    total_batches = ceil(total_timesteps / algo.config.train_batch_size)\n",
        "    for _ in range(total_batches):\n",
        "        result = algo.train()\n",
        "\n",
        "# _train_rllib(4096)\n",
        "\n",
        "# model_name = 'ppo'\n",
        "# ckpt_path = (Path(TRAINED_MODEL_DIR) / model_name).resolve()\n",
        "# algo.save(ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QKi7TQGXd6m",
        "outputId": "cebce638-e599-413b-d1cc-fa2f8eda13e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:130: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:418: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
            "  gym.logger.warn(\"Casting input x to numpy array.\")\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:130: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day: 251, episode: 1\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57031.83\n",
            "total_reward: 7031.83\n",
            "total_cost: 7658.01\n",
            "total_trades: 4263\n",
            "Sharpe: 1.016\n",
            "=================================\n",
            "day: 251, episode: 1\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 50721.52\n",
            "total_reward: 721.52\n",
            "total_cost: 6636.93\n",
            "total_trades: 4330\n",
            "Sharpe: 0.174\n",
            "=================================\n",
            "day: 251, episode: 2\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56112.19\n",
            "total_reward: 6112.19\n",
            "total_cost: 7245.20\n",
            "total_trades: 4415\n",
            "Sharpe: 0.907\n",
            "=================================\n",
            "day: 251, episode: 2\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55631.13\n",
            "total_reward: 5631.13\n",
            "total_cost: 7593.81\n",
            "total_trades: 4310\n",
            "Sharpe: 0.797\n",
            "=================================\n",
            "day: 251, episode: 3\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59814.17\n",
            "total_reward: 9814.17\n",
            "total_cost: 7887.69\n",
            "total_trades: 4427\n",
            "Sharpe: 1.359\n",
            "=================================\n",
            "day: 251, episode: 3\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59074.36\n",
            "total_reward: 9074.36\n",
            "total_cost: 7656.52\n",
            "total_trades: 4320\n",
            "Sharpe: 1.136\n",
            "=================================\n",
            "day: 251, episode: 4\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53821.15\n",
            "total_reward: 3821.15\n",
            "total_cost: 7353.28\n",
            "total_trades: 4366\n",
            "Sharpe: 0.595\n",
            "=================================\n",
            "day: 251, episode: 4\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56280.79\n",
            "total_reward: 6280.79\n",
            "total_cost: 7655.37\n",
            "total_trades: 4291\n",
            "Sharpe: 0.882\n",
            "=================================\n",
            "day: 251, episode: 5\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 52789.88\n",
            "total_reward: 2789.88\n",
            "total_cost: 7300.86\n",
            "total_trades: 4376\n",
            "Sharpe: 0.437\n",
            "=================================\n",
            "day: 251, episode: 5\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55372.60\n",
            "total_reward: 5372.60\n",
            "total_cost: 6350.39\n",
            "total_trades: 4306\n",
            "Sharpe: 0.742\n",
            "=================================\n",
            "day: 251, episode: 6\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58431.21\n",
            "total_reward: 8431.21\n",
            "total_cost: 7200.93\n",
            "total_trades: 4286\n",
            "Sharpe: 1.140\n",
            "=================================\n",
            "day: 251, episode: 6\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63062.44\n",
            "total_reward: 13062.44\n",
            "total_cost: 8044.08\n",
            "total_trades: 4427\n",
            "Sharpe: 1.879\n",
            "=================================\n",
            "day: 251, episode: 7\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58570.84\n",
            "total_reward: 8570.84\n",
            "total_cost: 7598.39\n",
            "total_trades: 4334\n",
            "Sharpe: 1.234\n",
            "=================================\n",
            "day: 251, episode: 7\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59868.17\n",
            "total_reward: 9868.17\n",
            "total_cost: 7394.12\n",
            "total_trades: 4329\n",
            "Sharpe: 1.292\n",
            "=================================\n",
            "day: 251, episode: 8\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55322.27\n",
            "total_reward: 5322.27\n",
            "total_cost: 6263.13\n",
            "total_trades: 4219\n",
            "Sharpe: 0.833\n",
            "=================================\n",
            "day: 251, episode: 8\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 51832.36\n",
            "total_reward: 1832.36\n",
            "total_cost: 6679.66\n",
            "total_trades: 4249\n",
            "Sharpe: 0.313\n",
            "=================================\n",
            "day: 251, episode: 9\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53257.57\n",
            "total_reward: 3257.57\n",
            "total_cost: 7394.80\n",
            "total_trades: 4337\n",
            "Sharpe: 0.519\n",
            "=================================\n",
            "day: 251, episode: 9\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 48732.94\n",
            "total_reward: -1267.06\n",
            "total_cost: 6744.16\n",
            "total_trades: 4253\n",
            "Sharpe: -0.119\n",
            "=================================\n",
            "day: 251, episode: 10\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57511.85\n",
            "total_reward: 7511.85\n",
            "total_cost: 6451.77\n",
            "total_trades: 4267\n",
            "Sharpe: 1.079\n",
            "=================================\n",
            "day: 251, episode: 10\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55427.83\n",
            "total_reward: 5427.83\n",
            "total_cost: 6655.89\n",
            "total_trades: 4315\n",
            "Sharpe: 0.809\n",
            "=================================\n",
            "day: 251, episode: 11\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 66429.21\n",
            "total_reward: 16429.21\n",
            "total_cost: 7307.77\n",
            "total_trades: 4278\n",
            "Sharpe: 2.108\n",
            "=================================\n",
            "day: 251, episode: 11\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 51333.69\n",
            "total_reward: 1333.69\n",
            "total_cost: 7364.24\n",
            "total_trades: 4247\n",
            "Sharpe: 0.255\n",
            "=================================\n",
            "day: 251, episode: 12\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55396.29\n",
            "total_reward: 5396.29\n",
            "total_cost: 7120.66\n",
            "total_trades: 4322\n",
            "Sharpe: 0.805\n",
            "=================================\n",
            "day: 251, episode: 12\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53870.53\n",
            "total_reward: 3870.53\n",
            "total_cost: 7434.15\n",
            "total_trades: 4326\n",
            "Sharpe: 0.567\n",
            "=================================\n",
            "\n",
            "Benchmark results:\n",
            "func_name                 _train_rllib\n",
            "exec_time    0 days 00:00:22.767201437\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 13\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53262.86\n",
            "total_reward: 3262.86\n",
            "total_cost: 6440.52\n",
            "total_trades: 4292\n",
            "Sharpe: 0.537\n",
            "=================================\n",
            "day: 251, episode: 13\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62257.77\n",
            "total_reward: 12257.77\n",
            "total_cost: 7829.60\n",
            "total_trades: 4408\n",
            "Sharpe: 1.643\n",
            "=================================\n",
            "day: 251, episode: 14\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 49602.92\n",
            "total_reward: -397.08\n",
            "total_cost: 6915.91\n",
            "total_trades: 4283\n",
            "Sharpe: 0.021\n",
            "=================================\n",
            "day: 251, episode: 14\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60339.38\n",
            "total_reward: 10339.38\n",
            "total_cost: 7230.22\n",
            "total_trades: 4315\n",
            "Sharpe: 1.416\n",
            "=================================\n",
            "day: 251, episode: 15\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 47543.50\n",
            "total_reward: -2456.50\n",
            "total_cost: 6441.72\n",
            "total_trades: 4247\n",
            "Sharpe: -0.283\n",
            "=================================\n",
            "day: 251, episode: 15\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58088.65\n",
            "total_reward: 8088.65\n",
            "total_cost: 6555.96\n",
            "total_trades: 4300\n",
            "Sharpe: 1.111\n",
            "=================================\n",
            "day: 251, episode: 16\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53369.70\n",
            "total_reward: 3369.70\n",
            "total_cost: 7294.44\n",
            "total_trades: 4206\n",
            "Sharpe: 0.571\n",
            "=================================\n",
            "day: 251, episode: 16\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 50987.30\n",
            "total_reward: 987.30\n",
            "total_cost: 6857.91\n",
            "total_trades: 4318\n",
            "Sharpe: 0.203\n",
            "=================================\n",
            "day: 251, episode: 17\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 49634.75\n",
            "total_reward: -365.25\n",
            "total_cost: 6594.95\n",
            "total_trades: 4315\n",
            "Sharpe: 0.030\n",
            "=================================\n",
            "day: 251, episode: 17\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56519.34\n",
            "total_reward: 6519.34\n",
            "total_cost: 6853.79\n",
            "total_trades: 4258\n",
            "Sharpe: 0.930\n",
            "=================================\n",
            "day: 251, episode: 18\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 49811.26\n",
            "total_reward: -188.74\n",
            "total_cost: 6882.88\n",
            "total_trades: 4236\n",
            "Sharpe: 0.049\n",
            "=================================\n",
            "day: 251, episode: 18\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58894.23\n",
            "total_reward: 8894.23\n",
            "total_cost: 4696.05\n",
            "total_trades: 4092\n",
            "Sharpe: 1.297\n",
            "=================================\n",
            "day: 251, episode: 19\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55944.09\n",
            "total_reward: 5944.09\n",
            "total_cost: 6852.67\n",
            "total_trades: 4266\n",
            "Sharpe: 0.898\n",
            "=================================\n",
            "day: 251, episode: 19\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53951.67\n",
            "total_reward: 3951.67\n",
            "total_cost: 6379.18\n",
            "total_trades: 4336\n",
            "Sharpe: 0.631\n",
            "=================================\n",
            "day: 251, episode: 20\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 54615.86\n",
            "total_reward: 4615.86\n",
            "total_cost: 7072.99\n",
            "total_trades: 4297\n",
            "Sharpe: 0.653\n",
            "=================================\n",
            "day: 251, episode: 20\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57798.67\n",
            "total_reward: 7798.67\n",
            "total_cost: 6879.67\n",
            "total_trades: 4265\n",
            "Sharpe: 1.133\n",
            "=================================\n",
            "day: 251, episode: 21\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60194.62\n",
            "total_reward: 10194.62\n",
            "total_cost: 6984.55\n",
            "total_trades: 4353\n",
            "Sharpe: 1.394\n",
            "=================================\n",
            "day: 251, episode: 21\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 47450.19\n",
            "total_reward: -2549.81\n",
            "total_cost: 6747.62\n",
            "total_trades: 4244\n",
            "Sharpe: -0.308\n",
            "=================================\n",
            "day: 251, episode: 22\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58835.72\n",
            "total_reward: 8835.72\n",
            "total_cost: 7015.84\n",
            "total_trades: 4237\n",
            "Sharpe: 1.296\n",
            "=================================\n",
            "day: 251, episode: 22\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59307.63\n",
            "total_reward: 9307.63\n",
            "total_cost: 7562.78\n",
            "total_trades: 4345\n",
            "Sharpe: 1.304\n",
            "=================================\n",
            "day: 251, episode: 23\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60112.93\n",
            "total_reward: 10112.93\n",
            "total_cost: 7094.67\n",
            "total_trades: 4401\n",
            "Sharpe: 1.404\n",
            "=================================\n",
            "day: 251, episode: 23\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58987.35\n",
            "total_reward: 8987.35\n",
            "total_cost: 6419.36\n",
            "total_trades: 4236\n",
            "Sharpe: 1.245\n",
            "=================================\n",
            "day: 251, episode: 24\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55913.73\n",
            "total_reward: 5913.73\n",
            "total_cost: 7358.99\n",
            "total_trades: 4279\n",
            "Sharpe: 0.841\n",
            "=================================\n",
            "day: 251, episode: 24\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58718.57\n",
            "total_reward: 8718.57\n",
            "total_cost: 6255.69\n",
            "total_trades: 4258\n",
            "Sharpe: 1.312\n",
            "=================================\n",
            "\n",
            "Benchmark results:\n",
            "func_name                 _train_rllib\n",
            "exec_time    0 days 00:00:22.502103832\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 25\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56692.01\n",
            "total_reward: 6692.01\n",
            "total_cost: 7956.73\n",
            "total_trades: 4297\n",
            "Sharpe: 0.915\n",
            "=================================\n",
            "day: 251, episode: 25\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55818.15\n",
            "total_reward: 5818.15\n",
            "total_cost: 6972.14\n",
            "total_trades: 4280\n",
            "Sharpe: 0.830\n",
            "=================================\n",
            "day: 251, episode: 26\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53366.17\n",
            "total_reward: 3366.17\n",
            "total_cost: 6619.67\n",
            "total_trades: 4355\n",
            "Sharpe: 0.572\n",
            "=================================\n",
            "day: 251, episode: 26\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53660.20\n",
            "total_reward: 3660.20\n",
            "total_cost: 6678.69\n",
            "total_trades: 4301\n",
            "Sharpe: 0.625\n",
            "=================================\n",
            "day: 251, episode: 27\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 48864.95\n",
            "total_reward: -1135.05\n",
            "total_cost: 7000.14\n",
            "total_trades: 4292\n",
            "Sharpe: -0.097\n",
            "=================================\n",
            "day: 251, episode: 27\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 52559.45\n",
            "total_reward: 2559.45\n",
            "total_cost: 6984.15\n",
            "total_trades: 4345\n",
            "Sharpe: 0.383\n",
            "=================================\n",
            "day: 251, episode: 28\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61223.35\n",
            "total_reward: 11223.35\n",
            "total_cost: 8067.01\n",
            "total_trades: 4375\n",
            "Sharpe: 1.564\n",
            "=================================\n",
            "day: 251, episode: 28\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58203.53\n",
            "total_reward: 8203.53\n",
            "total_cost: 5294.00\n",
            "total_trades: 4078\n",
            "Sharpe: 1.157\n",
            "=================================\n",
            "day: 251, episode: 29\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59718.32\n",
            "total_reward: 9718.32\n",
            "total_cost: 5646.55\n",
            "total_trades: 4173\n",
            "Sharpe: 1.477\n",
            "=================================\n",
            "day: 251, episode: 29\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 63584.02\n",
            "total_reward: 13584.02\n",
            "total_cost: 7823.62\n",
            "total_trades: 4341\n",
            "Sharpe: 1.798\n",
            "=================================\n",
            "day: 251, episode: 30\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55761.69\n",
            "total_reward: 5761.69\n",
            "total_cost: 5655.53\n",
            "total_trades: 4219\n",
            "Sharpe: 0.905\n",
            "=================================\n",
            "day: 251, episode: 30\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57669.24\n",
            "total_reward: 7669.24\n",
            "total_cost: 6367.89\n",
            "total_trades: 4280\n",
            "Sharpe: 1.113\n",
            "=================================\n",
            "day: 251, episode: 31\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62402.52\n",
            "total_reward: 12402.52\n",
            "total_cost: 7355.76\n",
            "total_trades: 4414\n",
            "Sharpe: 1.602\n",
            "=================================\n",
            "day: 251, episode: 31\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 51904.19\n",
            "total_reward: 1904.19\n",
            "total_cost: 6033.53\n",
            "total_trades: 4243\n",
            "Sharpe: 0.326\n",
            "=================================\n",
            "day: 251, episode: 32\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61507.95\n",
            "total_reward: 11507.95\n",
            "total_cost: 7547.41\n",
            "total_trades: 4368\n",
            "Sharpe: 1.572\n",
            "=================================\n",
            "day: 251, episode: 32\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55879.13\n",
            "total_reward: 5879.13\n",
            "total_cost: 6757.63\n",
            "total_trades: 4263\n",
            "Sharpe: 0.850\n",
            "=================================\n",
            "day: 251, episode: 33\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59856.11\n",
            "total_reward: 9856.11\n",
            "total_cost: 7432.54\n",
            "total_trades: 4299\n",
            "Sharpe: 1.473\n",
            "=================================\n",
            "day: 251, episode: 33\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57282.06\n",
            "total_reward: 7282.06\n",
            "total_cost: 7868.64\n",
            "total_trades: 4442\n",
            "Sharpe: 0.988\n",
            "=================================\n",
            "day: 251, episode: 34\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57381.35\n",
            "total_reward: 7381.35\n",
            "total_cost: 6974.33\n",
            "total_trades: 4248\n",
            "Sharpe: 1.069\n",
            "=================================\n",
            "day: 251, episode: 34\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60569.97\n",
            "total_reward: 10569.97\n",
            "total_cost: 7692.17\n",
            "total_trades: 4256\n",
            "Sharpe: 1.399\n",
            "=================================\n",
            "day: 251, episode: 35\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60489.12\n",
            "total_reward: 10489.12\n",
            "total_cost: 6909.17\n",
            "total_trades: 4357\n",
            "Sharpe: 1.368\n",
            "=================================\n",
            "day: 251, episode: 35\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59447.97\n",
            "total_reward: 9447.97\n",
            "total_cost: 7250.86\n",
            "total_trades: 4320\n",
            "Sharpe: 1.505\n",
            "=================================\n",
            "day: 251, episode: 36\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57744.46\n",
            "total_reward: 7744.46\n",
            "total_cost: 5405.46\n",
            "total_trades: 4105\n",
            "Sharpe: 1.125\n",
            "=================================\n",
            "day: 251, episode: 36\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55560.41\n",
            "total_reward: 5560.41\n",
            "total_cost: 6797.02\n",
            "total_trades: 4280\n",
            "Sharpe: 0.809\n",
            "=================================\n",
            "\n",
            "Benchmark results:\n",
            "func_name                 _train_rllib\n",
            "exec_time    0 days 00:00:22.876140994\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 37\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60136.75\n",
            "total_reward: 10136.75\n",
            "total_cost: 7853.54\n",
            "total_trades: 4302\n",
            "Sharpe: 1.271\n",
            "=================================\n",
            "day: 251, episode: 37\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56004.81\n",
            "total_reward: 6004.81\n",
            "total_cost: 6131.15\n",
            "total_trades: 4171\n",
            "Sharpe: 0.944\n",
            "=================================\n",
            "day: 251, episode: 38\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53145.53\n",
            "total_reward: 3145.53\n",
            "total_cost: 6764.40\n",
            "total_trades: 4350\n",
            "Sharpe: 0.508\n",
            "=================================\n",
            "day: 251, episode: 38\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 50655.45\n",
            "total_reward: 655.45\n",
            "total_cost: 7096.96\n",
            "total_trades: 4290\n",
            "Sharpe: 0.162\n",
            "=================================\n",
            "day: 251, episode: 39\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59684.70\n",
            "total_reward: 9684.70\n",
            "total_cost: 5969.40\n",
            "total_trades: 4263\n",
            "Sharpe: 1.328\n",
            "=================================\n",
            "day: 251, episode: 39\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 49177.57\n",
            "total_reward: -822.43\n",
            "total_cost: 6614.75\n",
            "total_trades: 4219\n",
            "Sharpe: -0.054\n",
            "=================================\n",
            "day: 251, episode: 40\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53746.15\n",
            "total_reward: 3746.15\n",
            "total_cost: 6733.27\n",
            "total_trades: 4360\n",
            "Sharpe: 0.557\n",
            "=================================\n",
            "day: 251, episode: 40\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 65628.96\n",
            "total_reward: 15628.96\n",
            "total_cost: 7044.43\n",
            "total_trades: 4269\n",
            "Sharpe: 2.064\n",
            "=================================\n",
            "day: 251, episode: 41\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 54063.87\n",
            "total_reward: 4063.87\n",
            "total_cost: 6651.04\n",
            "total_trades: 4240\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 251, episode: 41\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55985.80\n",
            "total_reward: 5985.80\n",
            "total_cost: 6750.70\n",
            "total_trades: 4181\n",
            "Sharpe: 0.861\n",
            "=================================\n",
            "day: 251, episode: 42\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57400.15\n",
            "total_reward: 7400.15\n",
            "total_cost: 7719.53\n",
            "total_trades: 4310\n",
            "Sharpe: 1.062\n",
            "=================================\n",
            "day: 251, episode: 42\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57577.98\n",
            "total_reward: 7577.98\n",
            "total_cost: 7267.36\n",
            "total_trades: 4366\n",
            "Sharpe: 1.081\n",
            "=================================\n",
            "day: 251, episode: 43\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64678.27\n",
            "total_reward: 14678.27\n",
            "total_cost: 6743.75\n",
            "total_trades: 4242\n",
            "Sharpe: 1.966\n",
            "=================================\n",
            "day: 251, episode: 43\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61894.21\n",
            "total_reward: 11894.21\n",
            "total_cost: 7352.54\n",
            "total_trades: 4308\n",
            "Sharpe: 1.610\n",
            "=================================\n",
            "day: 251, episode: 44\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 47869.55\n",
            "total_reward: -2130.45\n",
            "total_cost: 7086.59\n",
            "total_trades: 4295\n",
            "Sharpe: -0.258\n",
            "=================================\n",
            "day: 251, episode: 44\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53701.15\n",
            "total_reward: 3701.15\n",
            "total_cost: 6830.60\n",
            "total_trades: 4255\n",
            "Sharpe: 0.570\n",
            "=================================\n",
            "day: 251, episode: 45\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60035.58\n",
            "total_reward: 10035.58\n",
            "total_cost: 6324.19\n",
            "total_trades: 4308\n",
            "Sharpe: 1.397\n",
            "=================================\n",
            "day: 251, episode: 45\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 65458.43\n",
            "total_reward: 15458.43\n",
            "total_cost: 7868.92\n",
            "total_trades: 4384\n",
            "Sharpe: 2.064\n",
            "=================================\n",
            "day: 251, episode: 46\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 59956.81\n",
            "total_reward: 9956.81\n",
            "total_cost: 6543.06\n",
            "total_trades: 4349\n",
            "Sharpe: 1.353\n",
            "=================================\n",
            "day: 251, episode: 46\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56910.42\n",
            "total_reward: 6910.42\n",
            "total_cost: 7537.17\n",
            "total_trades: 4385\n",
            "Sharpe: 0.963\n",
            "=================================\n",
            "day: 251, episode: 47\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60615.72\n",
            "total_reward: 10615.72\n",
            "total_cost: 6312.27\n",
            "total_trades: 4241\n",
            "Sharpe: 1.433\n",
            "=================================\n",
            "day: 251, episode: 47\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61576.74\n",
            "total_reward: 11576.74\n",
            "total_cost: 6721.38\n",
            "total_trades: 4242\n",
            "Sharpe: 1.530\n",
            "=================================\n",
            "day: 251, episode: 48\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53433.79\n",
            "total_reward: 3433.79\n",
            "total_cost: 6140.80\n",
            "total_trades: 4130\n",
            "Sharpe: 0.543\n",
            "=================================\n",
            "day: 251, episode: 48\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60650.68\n",
            "total_reward: 10650.68\n",
            "total_cost: 6995.46\n",
            "total_trades: 4246\n",
            "Sharpe: 1.563\n",
            "=================================\n",
            "\n",
            "Benchmark results:\n",
            "func_name                 _train_rllib\n",
            "exec_time    0 days 00:00:22.418687802\n",
            "Name: benchmark_results, dtype: object\n",
            "day: 251, episode: 49\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58931.08\n",
            "total_reward: 8931.08\n",
            "total_cost: 6944.93\n",
            "total_trades: 4216\n",
            "Sharpe: 1.349\n",
            "=================================\n",
            "day: 251, episode: 49\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53082.57\n",
            "total_reward: 3082.57\n",
            "total_cost: 6895.07\n",
            "total_trades: 4258\n",
            "Sharpe: 0.493\n",
            "=================================\n",
            "day: 251, episode: 50\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 65295.87\n",
            "total_reward: 15295.87\n",
            "total_cost: 7778.07\n",
            "total_trades: 4344\n",
            "Sharpe: 1.964\n",
            "=================================\n",
            "day: 251, episode: 50\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58757.87\n",
            "total_reward: 8757.87\n",
            "total_cost: 6911.09\n",
            "total_trades: 4304\n",
            "Sharpe: 1.122\n",
            "=================================\n",
            "day: 251, episode: 51\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 49887.21\n",
            "total_reward: -112.79\n",
            "total_cost: 6566.12\n",
            "total_trades: 4181\n",
            "Sharpe: 0.051\n",
            "=================================\n",
            "day: 251, episode: 51\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61235.21\n",
            "total_reward: 11235.21\n",
            "total_cost: 6424.22\n",
            "total_trades: 4244\n",
            "Sharpe: 1.432\n",
            "=================================\n",
            "day: 251, episode: 52\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57309.09\n",
            "total_reward: 7309.09\n",
            "total_cost: 6362.34\n",
            "total_trades: 4270\n",
            "Sharpe: 1.070\n",
            "=================================\n",
            "day: 251, episode: 52\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58288.56\n",
            "total_reward: 8288.56\n",
            "total_cost: 5215.91\n",
            "total_trades: 4135\n",
            "Sharpe: 1.045\n",
            "=================================\n",
            "day: 251, episode: 53\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57511.16\n",
            "total_reward: 7511.16\n",
            "total_cost: 6878.08\n",
            "total_trades: 4324\n",
            "Sharpe: 1.073\n",
            "=================================\n",
            "day: 251, episode: 53\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58792.15\n",
            "total_reward: 8792.15\n",
            "total_cost: 5806.93\n",
            "total_trades: 4187\n",
            "Sharpe: 1.372\n",
            "=================================\n",
            "day: 251, episode: 54\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62139.00\n",
            "total_reward: 12139.00\n",
            "total_cost: 7855.40\n",
            "total_trades: 4344\n",
            "Sharpe: 1.716\n",
            "=================================\n",
            "day: 251, episode: 54\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 61193.50\n",
            "total_reward: 11193.50\n",
            "total_cost: 7586.08\n",
            "total_trades: 4301\n",
            "Sharpe: 1.511\n",
            "=================================\n",
            "day: 251, episode: 55\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 60683.72\n",
            "total_reward: 10683.72\n",
            "total_cost: 6634.83\n",
            "total_trades: 4284\n",
            "Sharpe: 1.527\n",
            "=================================\n",
            "day: 251, episode: 55\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 55018.59\n",
            "total_reward: 5018.59\n",
            "total_cost: 6742.77\n",
            "total_trades: 4299\n",
            "Sharpe: 0.781\n",
            "=================================\n",
            "day: 251, episode: 56\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 56833.84\n",
            "total_reward: 6833.84\n",
            "total_cost: 6811.89\n",
            "total_trades: 4292\n",
            "Sharpe: 1.009\n",
            "=================================\n",
            "day: 251, episode: 56\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 62135.73\n",
            "total_reward: 12135.73\n",
            "total_cost: 7053.45\n",
            "total_trades: 4301\n",
            "Sharpe: 1.729\n",
            "=================================\n",
            "day: 251, episode: 57\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53481.42\n",
            "total_reward: 3481.42\n",
            "total_cost: 6159.87\n",
            "total_trades: 4267\n",
            "Sharpe: 0.571\n",
            "=================================\n",
            "day: 251, episode: 57\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 51637.89\n",
            "total_reward: 1637.89\n",
            "total_cost: 6687.46\n",
            "total_trades: 4285\n",
            "Sharpe: 0.294\n",
            "=================================\n",
            "day: 251, episode: 58\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53878.46\n",
            "total_reward: 3878.46\n",
            "total_cost: 6660.05\n",
            "total_trades: 4190\n",
            "Sharpe: 0.549\n",
            "=================================\n",
            "day: 251, episode: 58\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 53894.65\n",
            "total_reward: 3894.65\n",
            "total_cost: 6592.00\n",
            "total_trades: 4305\n",
            "Sharpe: 0.595\n",
            "=================================\n",
            "day: 251, episode: 59\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58398.34\n",
            "total_reward: 8398.34\n",
            "total_cost: 5899.98\n",
            "total_trades: 4158\n",
            "Sharpe: 1.290\n",
            "=================================\n",
            "day: 251, episode: 59\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57156.96\n",
            "total_reward: 7156.96\n",
            "total_cost: 6375.83\n",
            "total_trades: 4117\n",
            "Sharpe: 1.057\n",
            "=================================\n",
            "day: 251, episode: 60\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 52401.72\n",
            "total_reward: 2401.72\n",
            "total_cost: 6304.21\n",
            "total_trades: 4284\n",
            "Sharpe: 0.384\n",
            "=================================\n",
            "day: 251, episode: 60\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 57361.04\n",
            "total_reward: 7361.04\n",
            "total_cost: 6309.74\n",
            "total_trades: 4249\n",
            "Sharpe: 0.960\n",
            "=================================\n",
            "\n",
            "Benchmark results:\n",
            "func_name                 _train_rllib\n",
            "exec_time    0 days 00:00:21.018369772\n",
            "Name: benchmark_results, dtype: object\n",
            "22.3 s ± 670 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 1 -r 5 _train_rllib(5_120)\n",
        "# %timeit -n 1 -r 1 _train_rllib(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk0_pf5m9s_M",
        "outputId": "fc58db7e-d486-4814-b7e5-3a0eeb62107f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 29, State Space: 291\n",
            "Initializing env with initial amount: 50000\n",
            "day: 61, episode: 1\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 41218.33\n",
            "total_reward: -8781.67\n",
            "total_cost: 201.05\n",
            "total_trades: 935\n",
            "Sharpe: -0.898\n",
            "=================================\n"
          ]
        }
      ],
      "source": [
        "#@title Evaluate RLlib model\n",
        "from ray.rllib.algorithms.algorithm import Algorithm\n",
        "from ray.rllib.core.columns import Columns\n",
        "from ray.rllib.utils.numpy import convert_to_numpy, softmax\n",
        "# from ray.rllib.models.torch.torch_distributions import TorchDiagGaussian\n",
        "\n",
        "import torch\n",
        "\n",
        "# Create the testing environment\n",
        "test_env = create_stock_trading_env(dict(df=val, sweep_config=sweep_config))\n",
        "state, info  = test_env.reset()\n",
        "episode_returns = []\n",
        "episode_total_assets  = [test_env.initial_amount]\n",
        "done = False\n",
        "\n",
        "# Perform inference using the trained RLlib agent\n",
        "rl_module = algo.env_runner.module\n",
        "while not done:\n",
        "    # Compute action using the RLlib trained agent\n",
        "    input_dict = {Columns.OBS: torch.Tensor(state).unsqueeze(0)}\n",
        "    rl_module_out = rl_module.forward_inference(input_dict)\n",
        "    logits = rl_module_out[Columns.ACTION_DIST_INPUTS]\n",
        "\n",
        "    # Take mean of multivariate Gaussian distribution\n",
        "    mean, log_std = logits[0, :29], logits[0, 29:]\n",
        "\n",
        "    # action_distribution = TorchDiagGaussian.from_logits(logits)\n",
        "    # action_distribution = action_distribution.to_deterministic()\n",
        "    # assert np.allclose(mean, action_distribution.loc)\n",
        "    # assert np.allclose(log_std.exp(), action_distribution._dist.scale)\n",
        "    # action = action_distribution.sample()\n",
        "\n",
        "    action = mean.detach().numpy().squeeze()\n",
        "\n",
        "    # Clip the action to ensure it's within the action space bounds\n",
        "    action = np.clip(action, test_env.action_space.low, test_env.action_space.high)\n",
        "\n",
        "    # Perform action\n",
        "    state, reward, terminated, truncated, _ = test_env.step(action)\n",
        "    done = terminated or truncated\n",
        "\n",
        "account_memory = test_env.save_asset_memory()\n",
        "action_memory = test_env.save_asset_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN7rj2Z18tWH",
        "outputId": "5e7ff733-49ad-4f49-d7b7-dc970fddc6c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-24 11:35:47,589\tINFO worker.py:1841 -- Started a local Ray instance.\n"
          ]
        }
      ],
      "source": [
        "# ray.shutdown()\n",
        "# ray.init()\n",
        "# register_env(\"stock_trading_env\", create_stock_trading_env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lhnlTLit5Bb1",
        "outputId": "283e1187-c0c6-467c-e2c2-305d27dd667b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-24 12:13:44,008\tWARNING algorithm_config.py:4702 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "2025-01-24 12:13:44,013\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 29, State Space: 291\n",
            "Initializing env with initial amount: 50000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-24 12:13:45,595\tWARNING algorithm_config.py:4702 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "2025-01-24 12:13:45,598\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "2025-01-24 12:13:46,782\tWARNING rl_module.py:419 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
            "2025-01-24 12:13:46,800\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:130: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:418: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
            "  gym.logger.warn(\"Casting input x to numpy array.\")\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/utils/passive_env_checker.py:130: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 251, episode: 1\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64057.15\n",
            "total_reward: 14057.15\n",
            "total_cost: 6573.89\n",
            "total_trades: 4501\n",
            "Sharpe: 1.874\n",
            "=================================\n",
            "day: 251, episode: 2\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 64879.41\n",
            "total_reward: 14879.41\n",
            "total_cost: 6988.99\n",
            "total_trades: 4623\n",
            "Sharpe: 1.916\n",
            "=================================\n",
            "day: 251, episode: 3\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58901.10\n",
            "total_reward: 8901.10\n",
            "total_cost: 7086.17\n",
            "total_trades: 4567\n",
            "Sharpe: 1.229\n",
            "=================================\n",
            "day: 251, episode: 4\n",
            "begin_total_asset: 50000.00\n",
            "end_total_asset: 58418.39\n",
            "total_reward: 8418.39\n",
            "total_cost: 7416.53\n",
            "total_trades: 4586\n",
            "Sharpe: 1.126\n",
            "=================================\n",
            "\n",
            "Benchmark results:\n",
            "func_name                       _train\n",
            "exec_time    0 days 00:00:12.592046097\n",
            "Name: benchmark_results, dtype: object\n",
            "CPU times: user 14.8 s, sys: 264 ms, total: 15 s\n",
            "Wall time: 15.4 s\n"
          ]
        }
      ],
      "source": [
        "#@title train_models\n",
        "%%time\n",
        "\n",
        "from pathlib import Path\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "from ray.rllib.algorithms.sac import SACConfig\n",
        "\n",
        "# model_name = 'ppo'\n",
        "model_name = 'sac'\n",
        "\n",
        "#############################\n",
        "\n",
        "MODEL_CONFIGS = {\n",
        "    'ppo': PPOConfig,\n",
        "    'sac': SACConfig,\n",
        "}\n",
        "\n",
        "# 1. Configure the algorithm,\n",
        "model_config = (\n",
        "    MODEL_CONFIGS[model_name]()\n",
        "    .env_runners(\n",
        "        num_env_runners=0,\n",
        "        num_envs_per_env_runner=1\n",
        "    )\n",
        "    .environment(\n",
        "        env=\"stock_trading_env\",\n",
        "        env_config={\"df\": train, \"sweep_config\": sweep_config},\n",
        "    )\n",
        "    .training(\n",
        "        train_batch_size=2048\n",
        "        num_epochs=10,\n",
        "        minibatch_size=128,\n",
        "    )\n",
        "    .callbacks(MetricsLoggerCallback)\n",
        ")\n",
        "\n",
        "# 2. build the algorithm ..\n",
        "algo = model_config.build()\n",
        "\n",
        "# 3. .. train it ..\n",
        "@benchmark_exec_time\n",
        "def _train():\n",
        "    for _ in range(10):\n",
        "        result = algo.train()\n",
        "\n",
        "_train()\n",
        "\n",
        "# ckpt_path = (Path(TRAINED_MODEL_DIR) / model_name).resolve()\n",
        "# algo.save(ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TLDeH1lN2XAS"
      },
      "outputs": [],
      "source": [
        "#@title FUNC: train_models\n",
        "\n",
        "\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "\n",
        "def train_models(config, e_train_gym, e_val_gym=None, model_list = AVAILABLE_MODELS):\n",
        "    assert set(model_list).issubset(AVAILABLE_MODELS)\n",
        "    check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "\n",
        "    for model_name in model_list:\n",
        "        if config[f\"if_using_{model_name}\"]:\n",
        "            print(f\"Training {model_name.upper()} agent\")\n",
        "            train_model(config, model_name, e_train_gym, e_val_gym=e_val_gym)\n",
        "        else:\n",
        "            print(f\"Skipping {model_name.upper()} agent\")\n",
        "\n",
        "def train_model(config, model_name, e_train_gym, e_val_gym=None):\n",
        "    model_results_dir = f\"{RESULTS_DIR}/{model_name}\"\n",
        "    trained_model_path = f\"{TRAINED_MODEL_DIR}/agent_{model_name}\"\n",
        "\n",
        "    MODEL_CONFIGS = {\n",
        "        'ppo': PPOConfig\n",
        "    }\n",
        "\n",
        "    # 1. Configure the algorithm,\n",
        "    config = (\n",
        "        MODEL_CONFIGS[model_name]()\n",
        "        .env_runners(\n",
        "            num_env_runners=1,\n",
        "        )\n",
        "        .environment(\n",
        "            env=\"stock_trading_env\",\n",
        "            env_config={\"df\": train, \"sweep_config\": sweep_config},\n",
        "        )\n",
        "        .callbacks(MetricsLoggerCallback)\n",
        "    )\n",
        "\n",
        "    # 2. build the algorithm ..\n",
        "    algo = config.build()\n",
        "\n",
        "    # 3. .. train it ..\n",
        "    for _ in range(config['model_name']['steps']):\n",
        "        result = algo.train()\n",
        "\n",
        "    ckpt_path = (Path(TRAINED_MODEL_DIR) / model_name).resolve()\n",
        "    algo.save(ckpt_path)\n",
        "\n",
        "    return algo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKw-_nYZ58_o"
      },
      "source": [
        "\n",
        "## Train StockTradingEnv_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBYzLTe27rfm"
      },
      "outputs": [],
      "source": [
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "\n",
        "TRAIN_START_DATE = \"2015-10-01\"\n",
        "TRAIN_END_DATE = \"2016-01-01\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ouDd0so9SFz"
      },
      "outputs": [],
      "source": [
        "CACHE_DIR = './cache/'\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGIkkWTD6K9Q"
      },
      "outputs": [],
      "source": [
        "from finrl.meta.data_processor import DataProcessor\n",
        "from types import SimpleNamespace\n",
        "import hashlib\n",
        "\n",
        "def stable_hash(data):\n",
        "    return hashlib.sha256(str(data).encode()).hexdigest()\n",
        "\n",
        "def get_env(\n",
        "    start_date,\n",
        "    end_date,\n",
        "    ticker_list,\n",
        "    data_source,\n",
        "    time_interval,\n",
        "    technical_indicator_list,\n",
        "    drl_lib,\n",
        "    env,\n",
        "    model_name,\n",
        "    if_vix=True,\n",
        "    **kwargs,\n",
        "):\n",
        "\n",
        "    data_hash = stable_hash(tuple(sorted(ticker_list) + sorted(technical_indicator_list)))\n",
        "    file_path = Path(CACHE_DIR) / f\"{start_date}_{end_date}_{time_interval}_{data_hash}.csv\"\n",
        "    dp = DataProcessor(data_source, tech_indicator=technical_indicator_list, vix=if_vix, **kwargs)\n",
        "    if os.path.isfile(file_path):\n",
        "        print(f\"Using cached data: {file_path}\")\n",
        "        data = pd.read_csv(file_path, index_col=0)\n",
        "    else:\n",
        "        print(\"Creating new data.\")\n",
        "        data = dp.download_data(ticker_list, start_date, end_date, time_interval)\n",
        "        data = dp.clean_data(data)\n",
        "        data = dp.add_technical_indicator(data, technical_indicator_list)\n",
        "        if if_vix:\n",
        "            data = dp.add_vix(data)\n",
        "        data.to_csv(file_path)\n",
        "\n",
        "    price_array, tech_array, turbulence_array = dp.df_to_array(data, if_vix)\n",
        "    env_config = {\n",
        "        \"price_array\": price_array,\n",
        "        \"tech_array\": tech_array,\n",
        "        \"turbulence_array\": turbulence_array,\n",
        "        \"if_train\": True,\n",
        "    }\n",
        "    env_instance = env(config=env_config)\n",
        "    return env_instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb1GLLFL8nnd"
      },
      "outputs": [],
      "source": [
        "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
        "\n",
        "args = SimpleNamespace()\n",
        "args.model_name = 'ppo'\n",
        "args.time_interval = '1d'\n",
        "args.total_episodes = 1\n",
        "\n",
        "env_config = dict(\n",
        "    start_date=TRAIN_START_DATE,\n",
        "    end_date=TRAIN_END_DATE,\n",
        "    ticker_list=DOW_30_TICKER,\n",
        "    data_source=\"yahoofinance\",\n",
        "    time_interval=args.time_interval,\n",
        "    technical_indicator_list=INDICATORS,\n",
        "    drl_lib=\"rllib\",\n",
        "    env=StockTradingEnv,\n",
        "    model_name=args.model_name,\n",
        "    cwd=f\"./test_{args.model_name}\",\n",
        "    # rllib_params=RLlib_PARAMS,\n",
        "    total_episodes=args.total_episodes, # default: 30\n",
        ")\n",
        "\n",
        "def create_stock_trading_env(env_config):\n",
        "    env = get_env(**env_config)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UamoNQGabYyu"
      },
      "outputs": [],
      "source": [
        "def print_result(result):\n",
        "    filter_keys = [\n",
        "        'episode_return_mean',\n",
        "        'episode_return_min',\n",
        "        'episode_return_max',\n",
        "    ]\n",
        "\n",
        "    print()\n",
        "    for key in filter_keys:\n",
        "        print(f\"{key}: {result['env_runners'][key]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEjHk2nA_bVF",
        "outputId": "60e38605-2ea9-4bae-c22c-5affc8b1689c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-22 08:06:59,114\tINFO worker.py:1821 -- Started a local Ray instance.\n",
            "2025-01-22 08:07:02,083\tWARNING algorithm_config.py:4355 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation doesn't occur automatically with each call to `Algorithm.train()`. Instead, you have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
            "2025-01-22 08:07:02,094\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "\u001b[36m(pid=12168)\u001b[0m 2025-01-22 08:07:03.374643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=12168)\u001b[0m 2025-01-22 08:07:03.416874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=12168)\u001b[0m 2025-01-22 08:07:03.429809: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=12168)\u001b[0m 2025-01-22 08:07:05.320026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(SingleAgentEnvRunner pid=12168)\u001b[0m Using cached data: cache/2015-10-01_2016-01-01_1d_27efcb16e570e962e2bc737bc60d8622859af4aa72ead85f4298e9b4c41ba6a2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(SingleAgentEnvRunner pid=12168)\u001b[0m 2025-01-22 08:07:14,960\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cached data: cache/2015-10-01_2016-01-01_1d_27efcb16e570e962e2bc737bc60d8622859af4aa72ead85f4298e9b4c41ba6a2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-22 08:07:16,101\tWARNING algorithm_config.py:4355 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation doesn't occur automatically with each call to `Algorithm.train()`. Instead, you have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
            "2025-01-22 08:07:16,104\tWARNING ppo.py:295 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
            "\u001b[36m(pid=12169)\u001b[0m 2025-01-22 08:07:16.917833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=12169)\u001b[0m 2025-01-22 08:07:16.961020: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=12169)\u001b[0m 2025-01-22 08:07:16.973028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=12169)\u001b[0m 2025-01-22 08:07:19.061276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(SingleAgentEnvRunner pid=12169)\u001b[0m Using cached data: cache/2015-10-01_2016-01-01_1d_27efcb16e570e962e2bc737bc60d8622859af4aa72ead85f4298e9b4c41ba6a2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:642: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "\u001b[36m(SingleAgentEnvRunner pid=12169)\u001b[0m 2025-01-22 08:07:29,223\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cached data: cache/2015-10-01_2016-01-01_1d_27efcb16e570e962e2bc737bc60d8622859af4aa72ead85f4298e9b4c41ba6a2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-22 08:07:30,792\tWARNING rl_module.py:427 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. Some algos already use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
            "2025-01-22 08:07:30,989\tINFO trainable.py:161 -- Trainable.setup took 28.867 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "2025-01-22 08:07:30,992\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode_return_mean: -0.029089480742363307\n",
            "episode_return_min: -0.06043808462835684\n",
            "episode_return_max: 0.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 1270},\n",
              "  'num_episodes': 10,\n",
              "  'episode_len_max': 127,\n",
              "  'num_agent_steps_sampled': {'default_agent': 1270},\n",
              "  'num_env_steps_sampled_lifetime': 1270,\n",
              "  'sample': 1.6036235290002878,\n",
              "  'episode_len_mean': 127.0,\n",
              "  'episode_len_min': 127,\n",
              "  'episode_return_min': -0.06043808462835684,\n",
              "  'episode_return_mean': -0.03463195878782255,\n",
              "  'agent_episode_returns_mean': {'default_agent': -0.03463195878782255},\n",
              "  'episode_duration_sec_mean': 0.15635733309991337,\n",
              "  'weights_seq_no': 1.0,\n",
              "  'num_module_steps_sampled_lifetime': {'default_policy': 1270},\n",
              "  'episode_return_max': -0.008634017574568744,\n",
              "  'num_module_steps_sampled': {'default_policy': 1270},\n",
              "  'module_episode_returns_mean': {'default_policy': -0.03463195878782255},\n",
              "  'num_env_steps_sampled': 1270,\n",
              "  'num_episodes_lifetime': 10}}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "from ray.rllib.connectors.env_to_module import FlattenObservations\n",
        "from ray.tune.registry import register_env\n",
        "\n",
        "ray.shutdown()\n",
        "ray.init()\n",
        "\n",
        "register_env(\"stock_trading_env\", create_stock_trading_env)\n",
        "\n",
        "# 1. Configure the algorithm,\n",
        "config = (\n",
        "    PPOConfig()\n",
        "    .environment(\n",
        "        env=\"stock_trading_env\",\n",
        "        env_config=env_config\n",
        "    )\n",
        "    .env_runners(\n",
        "        num_env_runners=1,\n",
        "        env_to_module_connector=lambda env: FlattenObservations(),\n",
        "    )\n",
        "    .evaluation(evaluation_num_env_runners=1)\n",
        ")\n",
        "\n",
        "# 2. build the algorithm ..\n",
        "algo = config.build()\n",
        "\n",
        "# 3. .. train it ..\n",
        "for _ in range(5):\n",
        "    result = algo.train()\n",
        "    print_result(result)\n",
        "\n",
        "# 4. .. and evaluate it.\n",
        "algo.evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y-J5mD_PTar9",
        "oWn4ZCwkvtN3",
        "Op7oS8Jw1pgx",
        "LHIfVohUTAsG",
        "_BZTsxX0tkDZ",
        "uKw-_nYZ58_o"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOVrTzjMbw3cZXnK8mPlmdq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}